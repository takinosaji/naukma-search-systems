last_date = `git log --pretty=format:"%ad" -1`
puts data.gsub('$Date$', '$Date: ' + last_date.to_s + '$')
All the script does is get the latest commit date from the git log command,
stick that into any $Date$ strings it sees in stdin, and print the results – it
should be simple to do in whatever language you’re most comfortable in. You
can name this file expand_date and put it in your path. Now, you need to set
up a filter in Git (call it dater) and tell it to use your expand_date filter to
smudge the files on checkout. You’ll use a Perl expression to clean that up on
commit:
$ git config filter.dater.smudge expand_date
$ git config filter.dater.clean 'perl -pe "s/\\\$Date[^\\\$]*\\\$/\\\$Date\\\$/"'
This Perl snippet strips out anything it sees in a $Date$ string, to get back to
where you started. Now that your filter is ready, you can test it by setting up a
Git attribute for that file that engages the new filter and creating a file with your
$Date$ keyword:
date*.txt filter=dater
$ echo '# $Date$' > date_test.txt
If you commit those changes and check out the file again, you see the keyword properly substituted:
$ git add date_test.txt .gitattributes
$ git commit -m "Testing date expansion in Git"
Git Attributes
399$ rm date_test.txt
$ git checkout date_test.txt
$ cat date_test.txt
# $Date: Tue Apr 21 07:26:52 2009 -0700$
You can see how powerful this technique can be for customized applications. You have to be careful, though, because the .gitattributes file is committed and passed around with the project, but the driver (in this case, dater)
isn’t, so it won’t work everywhere. When you design these filters, they should
be able to fail gracefully and have the project still work properly.
Exporting Your Repository
Git attribute data also allows you to do some interesting things when exporting
an archive of your project.
EXPORT-IGNORE
You can tell Git not to export certain files or directories when generating an
archive. If there is a subdirectory or file that you don’t want to include in your
archive file but that you do want checked into your project, you can determine
those files via the export-ignore attribute.
For example, say you have some test files in a test/ subdirectory, and it
doesn’t make sense to include them in the tarball export of your project. You
can add the following line to your Git attributes file:
test/ export-ignore
Now, when you run git archive to create a tarball of your project, that directory won’t be included in the archive.
EXPORT-SUBST
When exporting files for deployment you can apply git log’s formatting and
keyword-expansion processing to selected portions of files marked with the
export-subst attribute.
For instance, if you want to include a file named LAST_COMMIT in your
project, and have metadata about the last commit automatically injected into it
when git archive runs, you can for example set up your .gitattributes
and LAST_COMMIT files like this:
LAST_COMMIT export-subst
CHAPTER 8: Customizing Git
400$ echo 'Last commit date: $Format:%cd by %aN$' > LAST_COMMIT
$ git add LAST_COMMIT .gitattributes
$ git commit -am 'adding LAST_COMMIT file for archives'
When you run git archive, the contents of the archived file will look like
this:
$ git archive HEAD | tar xCf ../deployment-testing -
$ cat ../deployment-testing/LAST_COMMIT
Last commit date: Tue Apr 21 08:38:48 2009 -0700 by Scott Chacon
The substitutions can include for example the commit message and any git
notes, and git log can do simple word wrapping:
$ echo '$Format:Last commit: %h by %aN at %cd%n%+w(76,6,9)%B$' > LAST_COMMIT
$ git commit -am 'export-subst uses git log's custom formatter
git archive uses git log's `pretty=format:` processor
directly, and strips the surrounding `$Format:` and `$`
markup from the output.
' $
git archive @ | tar xfO - LAST_COMMIT
Last commit: 312ccc8 by Jim Hill at Fri May 8 09:14:04 2015 -0700
export-subst uses git log's custom formatter
git archive uses git log's `pretty=format:` processor directly, and
strips the surrounding `$Format:` and `$` markup from the output.
The resulting archive is suitable for deployment work, but like any exported
archive it isn’t suitable for further development work.
Merge Strategies
You can also use Git attributes to tell Git to use different merge strategies for
specific files in your project. One very useful option is to tell Git to not try to
merge specific files when they have conflicts, but rather to use your side of the
merge over someone else’s.
This is helpful if a branch in your project has diverged or is specialized, but
you want to be able to merge changes back in from it, and you want to ignore
certain files. Say you have a database settings file called database.xml that is
Git Attributes
401different in two branches, and you want to merge in your other branch without
messing up the database file. You can set up an attribute like this:
database.xml merge=ours
And then define a dummy ours merge strategy with:
$ git config --global merge.ours.driver true
If you merge in the other branch, instead of having merge conflicts with the
database.xml file, you see something like this:
$ git merge topic
Auto-merging database.xml
Merge made by recursive.
In this case, database.xml stays at whatever version you originally had.
Git Hooks
Like many other Version Control Systems, Git has a way to fire off custom
scripts when certain important actions occur. There are two groups of these
hooks: client-side and server-side. Client-side hooks are triggered by operations
such as committing and merging, while server-side hooks run on network operations such as receiving pushed commits. You can use these hooks for all sorts
of reasons.
Installing a Hook
The hooks are all stored in the hooks subdirectory of the Git directory. In most
projects, that’s .git/hooks. When you initialize a new repository with git
init, Git populates the hooks directory with a bunch of example scripts, many
of which are useful by themselves; but they also document the input values of
each script. All the examples are written as shell scripts, with some Perl thrown
in, but any properly named executable scripts will work fine – you can write
them in Ruby or Python or what have you. If you want to use the bundled hook
scripts, you’ll have to rename them; their file names all end with .sample.
To enable a hook script, put a file in the hooks subdirectory of your .git directory that is named appropriately (without any extension) and is executable.
CHAPTER 8: Customizing Git
402From that point forward, it should be called. We’ll cover most of the major hook
filenames here.
Client-Side Hooks
There are a lot of client-side hooks. This section splits them into committingworkflow hooks, email-workflow scripts, and everything else.
It’s important to note that client-side hooks are not copied when you
clone a repository. If your intent with these scripts is to enforce a policy,
you’ll probably want to do that on the server side; see the example in
“An Example Git-Enforced Policy”.
COMMITTING-WORKFLOW HOOKS
The first four hooks have to do with the committing process.
The pre-commit hook is run first, before you even type in a commit message. It’s used to inspect the snapshot that’s about to be committed, to see if
you’ve forgotten something, to make sure tests run, or to examine whatever
you need to inspect in the code. Exiting non-zero from this hook aborts the
commit, although you can bypass it with git commit --no-verify. You can
do things like check for code style (run lint or something equivalent), check
for trailing whitespace (the default hook does exactly this), or check for appropriate documentation on new methods.
The prepare-commit-msg hook is run before the commit message editor is
fired up but after the default message is created. It lets you edit the default
message before the commit author sees it. This hook takes a few parameters:
the path to the file that holds the commit message so far, the type of commit,
and the commit SHA-1 if this is an amended commit. This hook generally isn’t
useful for normal commits; rather, it’s good for commits where the default message is auto-generated, such as templated commit messages, merge commits,
squashed commits, and amended commits. You may use it in conjunction with
a commit template to programmatically insert information.
The commit-msg hook takes one parameter, which again is the path to a
temporary file that contains the commit message written by the developer. If
this script exits non-zero, Git aborts the commit process, so you can use it to
validate your project state or commit message before allowing a commit to go
through. In the last section of this chapter, We’ll demonstrate using this hook to
check that your commit message is conformant to a required pattern.
After the entire commit process is completed, the post-commit hook runs.
It doesn’t take any parameters, but you can easily get the last commit by runGit Hooks
403ning git log -1 HEAD. Generally, this script is used for notification or something similar.
EMAIL WORKFLOW HOOKS
You can set up three client-side hooks for an email-based workflow. They’re all
invoked by the git am command, so if you aren’t using that command in your
workflow, you can safely skip to the next section. If you’re taking patches over
email prepared by git format-patch, then some of these may be helpful to
you.
The first hook that is run is applypatch-msg. It takes a single argument: the
name of the temporary file that contains the proposed commit message. Git
aborts the patch if this script exits non-zero. You can use this to make sure a
commit message is properly formatted, or to normalize the message by having
the script edit it in place.
The next hook to run when applying patches via git am is preapplypatch. Somewhat confusingly, it is run after the patch is applied but before a commit is made, so you can use it to inspect the snapshot before making
the commit. You can run tests or otherwise inspect the working tree with this
script. If something is missing or the tests don’t pass, exiting non-zero aborts
the git am script without committing the patch.
The last hook to run during a git am operation is post-applypatch, which
runs after the commit is made. You can use it to notify a group or the author of
the patch you pulled in that you’ve done so. You can’t stop the patching process
with this script.
OTHER CLIENT HOOKS
The pre-rebase hook runs before you rebase anything and can halt the process by exiting non-zero. You can use this hook to disallow rebasing any commits that have already been pushed. The example pre-rebase hook that Git
installs does this, although it makes some assumptions that may not match
with your workflow.
The post-rewrite hook is run by commands that replace commits, such as
git commit --amend and git rebase (though not by git filterbranch). Its single argument is which command triggered the rewrite, and it receives a list of rewrites on stdin. This hook has many of the same uses as the
post-checkout and post-merge hooks.
After you run a successful git checkout, the post-checkout hook runs;
you can use it to set up your working directory properly for your project environment. This may mean moving in large binary files that you don’t want
CHAPTER 8: Customizing Git
404source controlled, auto-generating documentation, or something along those
lines.
The post-merge hook runs after a successful merge command. You can use
it to restore data in the working tree that Git can’t track, such as permissions
data. This hook can likewise validate the presence of files external to Git control
that you may want copied in when the working tree changes.
The pre-push hook runs during git push, after the remote refs have been
updated but before any objects have been transferred. It receives the name and
location of the remote as parameters, and a list of to-be-updated refs through
stdin. You can use it to validate a set of ref updates before a push occurs (a
non-zero exit code will abort the push).
Git occasionally does garbage collection as part of its normal operation, by
invoking git gc --auto. The pre-auto-gc hook is invoked just before the
garbage collection takes place, and can be used to notify you that this is happening, or to abort the collection if now isn’t a good time.
Server-Side Hooks
In addition to the client-side hooks, you can use a couple of important serverside hooks as a system administrator to enforce nearly any kind of policy for
your project. These scripts run before and after pushes to the server. The pre
hooks can exit non-zero at any time to reject the push as well as print an error
message back to the client; you can set up a push policy that’s as complex as
you wish.
PRE-RECEIVE
The first script to run when handling a push from a client is pre-receive. It
takes a list of references that are being pushed from stdin; if it exits non-zero,
none of them are accepted. You can use this hook to do things like make sure
none of the updated references are non-fast-forwards, or to do access control
for all the refs and files they’re modifying with the push.
UPDATE
The update script is very similar to the pre-receive script, except that it’s run
once for each branch the pusher is trying to update. If the pusher is trying to
push to multiple branches, pre-receive runs only once, whereas update runs
once per branch they’re pushing to. Instead of reading from stdin, this script
takes three arguments: the name of the reference (branch), the SHA-1 that reference pointed to before the push, and the SHA-1 the user is trying to push. If
Git Hooks
405the update script exits non-zero, only that reference is rejected; other references can still be updated.
POST-RECEIVE
The post-receive hook runs after the entire process is completed and can be
used to update other services or notify users. It takes the same stdin data as the
pre-receive hook. Examples include emailing a list, notifying a continuous integration server, or updating a ticket-tracking system – you can even parse the
commit messages to see if any tickets need to be opened, modified, or closed.
This script can’t stop the push process, but the client doesn’t disconnect until it
has completed, so be careful if you try to do anything that may take a long time.
An Example Git-Enforced Policy
In this section, you’ll use what you’ve learned to establish a Git workflow that
checks for a custom commit message format, and allows only certain users to
modify certain subdirectories in a project. You’ll build client scripts that help
the developer know if their push will be rejected and server scripts that actually
enforce the policies.
The scripts we’ll show are written in Ruby; partly because of our intellectual
inertia, but also because Ruby is easy to read, even if you can’t necessarily write
it. However, any language will work – all the sample hook scripts distributed
with Git are in either Perl or Bash, so you can also see plenty of examples of
hooks in those languages by looking at the samples.
Server-Side Hook
All the server-side work will go into the update file in your hooks directory. The
update hook runs once per branch being pushed and takes three arguments:
• The name of the reference being pushed to
• The old revision where that branch was
• The new revision being pushed
You also have access to the user doing the pushing if the push is being run
over SSH. If you’ve allowed everyone to connect with a single user (like “git”)
via public-key authentication, you may have to give that user a shell wrapper
that determines which user is connecting based on the public key, and set an
environment variable accordingly. Here we’ll assume the connecting user is in
CHAPTER 8: Customizing Git
406the $USER environment variable, so your update script begins by gathering all
the information you need:
#!/usr/bin/env ruby
$refname = ARGV[0]
$oldrev = ARGV[1]
$newrev = ARGV[2]
$user = ENV['USER']
puts "Enforcing Policies..."
puts "(#{$refname}) (#{$oldrev[0,6]}) (#{$newrev[0,6]})"
Yes, those are global variables. Don’t judge – it’s easier to demonstrate this
way.
ENFORCING A SPECIFIC COMMIT-MESSAGE FORMAT
Your first challenge is to enforce that each commit message adheres to a particular format. Just to have a target, assume that each message has to include a
string that looks like “ref: 1234” because you want each commit to link to a
work item in your ticketing system. You must look at each commit being pushed up, see if that string is in the commit message, and, if the string is absent
from any of the commits, exit non-zero so the push is rejected.
You can get a list of the SHA-1 values of all the commits that are being pushed by taking the $newrev and $oldrev values and passing them to a Git
plumbing command called git rev-list. This is basically the git log command, but by default it prints out only the SHA-1 values and no other information. So, to get a list of all the commit SHA-1s introduced between one commit
SHA-1 and another, you can run something like this:
$ git rev-list 538c33..d14fc7
d14fc7c847ab946ec39590d87783c69b031bdfb7
9f585da4401b0a3999e84113824d15245c13f0be
234071a1be950e2a8d078e6141f5cd20c1e61ad3
dfa04c9ef3d5197182f13fb5b9b1fb7717d2222a
17716ec0f1ff5c77eff40b7fe912f9f6cfd0e475
You can take that output, loop through each of those commit SHA-1s, grab
the message for it, and test that message against a regular expression that
looks for a pattern.
You have to figure out how to get the commit message from each of these
commits to test. To get the raw commit data, you can use another plumbing
An Example Git-Enforced Policy
407command called git cat-file. We’ll go over all these plumbing commands
in detail in Chapter 10; but for now, here’s what that command gives you:
$ git cat-file commit ca82a6
tree cfda3bf379e4f8dba8717dee55aab78aef7f4daf
parent 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7
author Scott Chacon <schacon@gmail.com> 1205815931 -0700
committer Scott Chacon <schacon@gmail.com> 1240030591 -0700
changed the version number
A simple way to get the commit message from a commit when you have the
SHA-1 value is to go to the first blank line and take everything after that. You
can do so with the sed command on Unix systems:
$ git cat-file commit ca82a6 | sed '1,/^$/d'
changed the version number
You can use that incantation to grab the commit message from each commit
that is trying to be pushed and exit if you see anything that doesn’t match. To
exit the script and reject the push, exit non-zero. The whole method looks like
this:
$regex = /\[ref: (\d+)\]/
# enforced custom commit message format
def check_message_format
missed_revs = `git rev-list #{$oldrev}..#{$newrev}`.split("\n")
missed_revs.each do |rev|
message = `git cat-file commit #{rev} | sed '1,/^$/d'`
if !$regex.match(message)
puts "[POLICY] Your message is not formatted correctly"
exit 1
end
end
end
check_message_format
Putting that in your update script will reject updates that contain commits
that have messages that don’t adhere to your rule.
CHAPTER 8: Customizing Git
408ENFORCING A USER-BASED ACL SYSTEM
Suppose you want to add a mechanism that uses an access control list (ACL)
that specifies which users are allowed to push changes to which parts of your
projects. Some people have full access, and others can only push changes to
certain subdirectories or specific files. To enforce this, you’ll write those rules to
a file named acl that lives in your bare Git repository on the server. You’ll have
the update hook look at those rules, see what files are being introduced for all
the commits being pushed, and determine whether the user doing the push has
access to update all those files.
The first thing you’ll do is write your ACL. Here you’ll use a format very much
like the CVS ACL mechanism: it uses a series of lines, where the first field is
avail or unavail, the next field is a comma-delimited list of the users to which
the rule applies, and the last field is the path to which the rule applies (blank
meaning open access). All of these fields are delimited by a pipe (|) character.
In this case, you have a couple of administrators, some documentation writers with access to the doc directory, and one developer who only has access to
the lib and tests directories, and your ACL file looks like this:
avail|nickh,pjhyett,defunkt,tpw
avail|usinclair,cdickens,ebronte|doc
avail|schacon|lib
avail|schacon|tests
You begin by reading this data into a structure that you can use. In this case,
to keep the example simple, you’ll only enforce the avail directives. Here is a
method that gives you an associative array where the key is the user name and
the value is an array of paths to which the user has write access:
def get_acl_access_data(acl_file)
# read in ACL data
acl_file = File.read(acl_file).split("\n").reject { |line| line == '' }
access = {}
acl_file.each do |line|
avail, users, path = line.split('|')
next unless avail == 'avail'
users.split(',').each do |user|
access[user] ||= []
access[user] << path
end
end
access
end
An Example Git-Enforced Policy
409On the ACL file you looked at earlier, this get_acl_access_data method
returns a data structure that looks like this:
{"defunkt"=>[nil],
"tpw"=>[nil],
"nickh"=>[nil],
"pjhyett"=>[nil],
"schacon"=>["lib", "tests"],
"cdickens"=>["doc"],
"usinclair"=>["doc"],
"ebronte"=>["doc"]}
Now that you have the permissions sorted out, you need to determine what
paths the commits being pushed have modified, so you can make sure the user
who’s pushing has access to all of them.
You can pretty easily see what files have been modified in a single commit
with the --name-only option to the git log command (mentioned briefly in
Chapter 2):
$ git log -1 --name-only --pretty=format:'' 9f585d
README
lib/test.rb
If you use the ACL structure returned from the get_acl_access_data
method and check it against the listed files in each of the commits, you can determine whether the user has access to push all of their commits:
# only allows certain users to modify certain subdirectories in a project
def check_directory_perms
access = get_acl_access_data('acl')
# see if anyone is trying to push something they can't
new_commits = `git rev-list #{$oldrev}..#{$newrev}`.split("\n")
new_commits.each do |rev|
files_modified = `git log -1 --name-only --pretty=format:'' #{rev}`.split("\n")
files_modified.each do |path|
next if path.size == 0
has_file_access = false
access[$user].each do |access_path|
if !access_path # user has access to everything
|| (path.start_with? access_path) # access to this path
has_file_access = true
end
end
if !has_file_access
CHAPTER 8: Customizing Git
410puts "[POLICY] You do not have access to push to #{path}"
exit 1
end
end
end
end
check_directory_perms
You get a list of new commits being pushed to your server with git revlist. Then, for each of those commits, you find which files are modified and
make sure the user who’s pushing has access to all the paths being modified.
Now your users can’t push any commits with badly formed messages or with
modified files outside of their designated paths.
TESTING IT OUT
If you run chmod u+x .git/hooks/update, which is the file into which you
should have put all this code, and then try to push a commit with a noncompliant message, you get something like this:
$ git push -f origin master
Counting objects: 5, done.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 323 bytes, done.
Total 3 (delta 1), reused 0 (delta 0)
Unpacking objects: 100% (3/3), done.
Enforcing Policies...
(refs/heads/master) (8338c5) (c5b616)
[POLICY] Your message is not formatted correctly
error: hooks/update exited with error code 1
error: hook declined to update refs/heads/master
To git@gitserver:project.git
! [remote rejected] master -> master (hook declined)
error: failed to push some refs to 'git@gitserver:project.git'
There are a couple of interesting things here. First, you see this where the
hook starts running.
Enforcing Policies...
(refs/heads/master) (fb8c72) (c56860)
Remember that you printed that out at the very beginning of your update
script. Anything your script echoes to stdout will be transferred to the client.
An Example Git-Enforced Policy
411The next thing you’ll notice is the error message.
[POLICY] Your message is not formatted correctly
error: hooks/update exited with error code 1
error: hook declined to update refs/heads/master
The first line was printed out by you, the other two were Git telling you that
the update script exited non-zero and that is what is declining your push. Lastly, you have this:
To git@gitserver:project.git
! [remote rejected] master -> master (hook declined)
error: failed to push some refs to 'git@gitserver:project.git'
You’ll see a remote rejected message for each reference that your hook declined, and it tells you that it was declined specifically because of a hook failure.
Furthermore, if someone tries to edit a file they don’t have access to and
push a commit containing it, they will see something similar. For instance, if a
documentation author tries to push a commit modifying something in the lib
directory, they see
[POLICY] You do not have access to push to lib/test.rb
From now on, as long as that update script is there and executable, your
repository will never have a commit message without your pattern in it, and
your users will be sandboxed.
Client-Side Hooks
The downside to this approach is the whining that will inevitably result when
your users’ commit pushes are rejected. Having their carefully crafted work rejected at the last minute can be extremely frustrating and confusing; and furthermore, they will have to edit their history to correct it, which isn’t always for
the faint of heart.
The answer to this dilemma is to provide some client-side hooks that users
can run to notify them when they’re doing something that the server is likely to
reject. That way, they can correct any problems before committing and before
those issues become more difficult to fix. Because hooks aren’t transferred with
a clone of a project, you must distribute these scripts some other way and then
CHAPTER 8: Customizing Git
412have your users copy them to their .git/hooks directory and make them executable. You can distribute these hooks within the project or in a separate
project, but Git won’t set them up automatically.
To begin, you should check your commit message just before each commit is
recorded, so you know the server won’t reject your changes due to badly formatted commit messages. To do this, you can add the commit-msg hook. If you
have it read the message from the file passed as the first argument and compare that to the pattern, you can force Git to abort the commit if there is no
match:
#!/usr/bin/env ruby
message_file = ARGV[0]
message = File.read(message_file)
$regex = /\[ref: (\d+)\]/
if !$regex.match(message)
puts "[POLICY] Your message is not formatted correctly"
exit 1
end
If that script is in place (in .git/hooks/commit-msg) and executable, and
you commit with a message that isn’t properly formatted, you see this:
$ git commit -am 'test'
[POLICY] Your message is not formatted correctly
No commit was completed in that instance. However, if your message contains the proper pattern, Git allows you to commit:
$ git commit -am 'test [ref: 132]'
[master e05c914] test [ref: 132]
1 file changed, 1 insertions(+), 0 deletions(-)
Next, you want to make sure you aren’t modifying files that are outside your
ACL scope. If your project’s .git directory contains a copy of the ACL file you
used previously, then the following pre-commit script will enforce those constraints for you:
#!/usr/bin/env ruby
$user = ENV['USER']
An Example Git-Enforced Policy
413# [ insert acl_access_data method from above ]
# only allows certain users to modify certain subdirectories in a project
def check_directory_perms
access = get_acl_access_data('.git/acl')
files_modified = `git diff-index --cached --name-only HEAD`.split("\n")
files_modified.each do |path|
next if path.size == 0
has_file_access = false
access[$user].each do |access_path|
if !access_path || (path.index(access_path) == 0)
has_file_access = true
end
if !has_file_access
puts "[POLICY] You do not have access to push to #{path}"
exit 1
end
end
end
check_directory_perms
This is roughly the same script as the server-side part, but with two important differences. First, the ACL file is in a different place, because this script runs
from your working directory, not from your .git directory. You have to change
the path to the ACL file from this
access = get_acl_access_data('acl')
to this:
access = get_acl_access_data('.git/acl')
The other important difference is the way you get a listing of the files that
have been changed. Because the server-side method looks at the log of commits, and, at this point, the commit hasn’t been recorded yet, you must get your
file listing from the staging area instead. Instead of
files_modified = `git log -1 --name-only --pretty=format:'' #{ref}`
you have to use
files_modified = `git diff-index --cached --name-only HEAD`
But those are the only two differences – otherwise, the script works the
same way. One caveat is that it expects you to be running locally as the same
CHAPTER 8: Customizing Git
414user you push as to the remote machine. If that is different, you must set the
$user variable manually.
One other thing we can do here is make sure the user doesn’t push non-fastforwarded references. To get a reference that isn’t a fast-forward, you either
have to rebase past a commit you’ve already pushed up or try pushing a different local branch up to the same remote branch.
Presumably, the server is already configured with receive.denyDeletes
and receive.denyNonFastForwards to enforce this policy, so the only accidental thing you can try to catch is rebasing commits that have already been
pushed.
Here is an example pre-rebase script that checks for that. It gets a list of all
the commits you’re about to rewrite and checks whether they exist in any of
your remote references. If it sees one that is reachable from one of your remote
references, it aborts the rebase.
#!/usr/bin/env ruby
base_branch = ARGV[0]
if ARGV[1]
topic_branch = ARGV[1]
else
topic_branch = "HEAD"
end
target_shas = `git rev-list #{base_branch}..#{topic_branch}`.split("\n")
remote_refs = `git branch -r`.split("\n").map { |r| r.strip }
target_shas.each do |sha|
remote_refs.each do |remote_ref|
shas_pushed = `git rev-list ^#{sha}^@ refs/remotes/#{remote_ref}`
if shas_pushed.split("\n").include?(sha)
puts "[POLICY] Commit #{sha} has already been pushed to #{remote_ref}"
exit 1
end
end
end
This script uses a syntax that wasn’t covered in “Revision Selection”. You
get a list of commits that have already been pushed up by running this:
`git rev-list ^#{sha}^@ refs/remotes/#{remote_ref}`
The SHA^@ syntax resolves to all the parents of that commit. You’re looking
for any commit that is reachable from the last commit on the remote and that
An Example Git-Enforced Policy
415isn’t reachable from any parent of any of the SHA-1s you’re trying to push up –
meaning it’s a fast-forward.
The main drawback to this approach is that it can be very slow and is often
unnecessary – if you don’t try to force the push with -f, the server will warn you
and not accept the push. However, it’s an interesting exercise and can in theory
help you avoid a rebase that you might later have to go back and fix.
Summary
We’ve covered most of the major ways that you can customize your Git client
and server to best fit your workflow and projects. You’ve learned about all sorts
of configuration settings, file-based attributes, and event hooks, and you’ve
built an example policy-enforcing server. You should now be able to make Git fit
nearly any workflow you can dream up.
CHAPTER 8: Customizing Git
416Git and Other Systems
The world isn’t perfect. Usually, you can’t immediately switch every project you
come in contact with to Git. Sometimes you’re stuck on a project using another
VCS, and wish it was Git. We’ll spend the first part of this chapter learning about
ways to use Git as a client when the project you’re working on is hosted in a
different system.
At some point, you may want to convert your existing project to Git. The second part of this chapter covers how to migrate your project into Git from several
specific systems, as well as a method that will work if no pre-built import tool
exists.
Git as a Client
Git provides such a nice experience for developers that many people have figured out how to use it on their workstation, even if the rest of their team is using an entirely different VCS. There are a number of these adapters, called
“bridges,” available. Here we’ll cover the ones you’re most likely to run into in
the wild.
Git and Subversion
A large fraction of open source development projects and a good number of
corporate projects use Subversion to manage their source code. It’s been
around for more than a decade, and for most of that time was the de facto VCS
choice for open-source projects. It’s also very similar in many ways to CVS,
which was the big boy of the source-control world before that.
One of Git’s great features is a bidirectional bridge to Subversion called git
svn. This tool allows you to use Git as a valid client to a Subversion server, so
you can use all the local features of Git and then push to a Subversion server as
if you were using Subversion locally. This means you can do local branching
and merging, use the staging area, use rebasing and cherry-picking, and so on,
417
9while your collaborators continue to work in their dark and ancient ways. It’s a
good way to sneak Git into the corporate environment and help your fellow developers become more efficient while you lobby to get the infrastructure
changed to support Git fully. The Subversion bridge is the gateway drug to the
DVCS world.
GIT SVN
The base command in Git for all the Subversion bridging commands is git
svn. It takes quite a few commands, so we’ll show the most common while going through a few simple workflows.
It’s important to note that when you’re using git svn, you’re interacting
with Subversion, which is a system that works very differently from Git. Although you can do local branching and merging, it’s generally best to keep your
history as linear as possible by rebasing your work, and avoiding doing things
like simultaneously interacting with a Git remote repository.
Don’t rewrite your history and try to push again, and don’t push to a parallel
Git repository to collaborate with fellow Git developers at the same time. Subversion can have only a single linear history, and confusing it is very easy. If
you’re working with a team, and some are using SVN and others are using Git,
make sure everyone is using the SVN server to collaborate – doing so will make
your life easier.
SETTING UP
To demonstrate this functionality, you need a typical SVN repository that you
have write access to. If you want to copy these examples, you’ll have to make a
writeable copy of my test repository. In order to do that easily, you can use a
tool called svnsync that comes with Subversion. For these tests, we created a
new Subversion repository on Google Code that was a partial copy of the protobuf project, which is a tool that encodes structured data for network transmission.
To follow along, you first need to create a new local Subversion repository:
$ mkdir /tmp/test-svn
$ svnadmin create /tmp/test-svn
Then, enable all users to change revprops – the easy way is to add a prerevprop-change script that always exits 0:
CHAPTER 9: Git and Other Systems
418$ cat /tmp/test-svn/hooks/pre-revprop-change
#!/bin/sh
exit 0;
$ chmod +x /tmp/test-svn/hooks/pre-revprop-change
You can now sync this project to your local machine by calling svnsync init with the to and from repositories.
$ svnsync init file:///tmp/test-svn \
http://progit-example.googlecode.com/svn/
This sets up the properties to run the sync. You can then clone the code by
running
$ svnsync sync file:///tmp/test-svn
Committed revision 1.
Copied properties for revision 1.
Transmitting file data .............................[...]
Committed revision 2.
Copied properties for revision 2.
[…]
Although this operation may take only a few minutes, if you try to copy the
original repository to another remote repository instead of a local one, the process will take nearly an hour, even though there are fewer than 100 commits.
Subversion has to clone one revision at a time and then push it back into another repository – it’s ridiculously inefficient, but it’s the only easy way to do this.
GETTING STARTED
Now that you have a Subversion repository to which you have write access, you
can go through a typical workflow. You’ll start with the git svn clone command, which imports an entire Subversion repository into a local Git repository.
Remember that if you’re importing from a real hosted Subversion repository,
you should replace the file:///tmp/test-svn here with the URL of your
Subversion repository:
$ git svn clone file:///tmp/test-svn -T trunk -b branches -t tags
Initialized empty Git repository in /private/tmp/progit/test-svn/.git/
r1 = dcbfb5891860124cc2e8cc616cded42624897125 (refs/remotes/origin/trunk)
A m4/acx_pthread.m4
Git as a Client
419A m4/stl_hash.m4
A java/src/test/java/com/google/protobuf/UnknownFieldSetTest.java
A java/src/test/java/com/google/protobuf/WireFormatTest.java
…
r75 = 556a3e1e7ad1fde0a32823fc7e4d046bcfd86dae (refs/remotes/origin/trunk)
Found possible branch point: file:///tmp/test-svn/trunk => file:///tmp/test-svn/br
Found branch parent: (refs/remotes/origin/my-calc-branch) 556a3e1e7ad1fde0a32823fc
Following parent with do_switch
Successfully followed parent
r76 = 0fb585761df569eaecd8146c71e58d70147460a2 (refs/remotes/origin/my-calc-branch
Checked out HEAD:
file:///tmp/test-svn/trunk r75
This runs the equivalent of two commands – git svn init followed by git
svn fetch – on the URL you provide. This can take a while. The test project
has only about 75 commits and the codebase isn’t that big, but Git has to check
out each version, one at a time, and commit it individually. For a project with
hundreds or thousands of commits, this can literally take hours or even days to
finish.
The -T trunk -b branches -t tags part tells Git that this Subversion
repository follows the basic branching and tagging conventions. If you name
your trunk, branches, or tags differently, you can change these options. Because this is so common, you can replace this entire part with -s, which means
standard layout and implies all those options. The following command is equivalent:
$ git svn clone file:///tmp/test-svn -s
At this point, you should have a valid Git repository that has imported your
branches and tags:
$ git branch -a
* master
remotes/origin/my-calc-branch
remotes/origin/tags/2.0.2
remotes/origin/tags/release-2.0.1
remotes/origin/tags/release-2.0.2
remotes/origin/tags/release-2.0.2rc1
remotes/origin/trunk
Note how this tool manages Subversion tags as remote refs. Let’s take a closer look with the Git plumbing command show-ref:
CHAPTER 9: Git and Other Systems
420$ git show-ref
556a3e1e7ad1fde0a32823fc7e4d046bcfd86dae refs/heads/master
0fb585761df569eaecd8146c71e58d70147460a2 refs/remotes/origin/my-calc-branch
bfd2d79303166789fc73af4046651a4b35c12f0b refs/remotes/origin/tags/2.0.2
285c2b2e36e467dd4d91c8e3c0c0e1750b3fe8ca refs/remotes/origin/tags/release-2.0.1
cbda99cb45d9abcb9793db1d4f70ae562a969f1e refs/remotes/origin/tags/release-2.0.2
a9f074aa89e826d6f9d30808ce5ae3ffe711feda refs/remotes/origin/tags/release-2.0.2rc1
556a3e1e7ad1fde0a32823fc7e4d046bcfd86dae refs/remotes/origin/trunk
Git doesn’t do this when it clones from a Git server; here’s what a repository
with tags looks like after a fresh clone:
$ git show-ref
c3dcbe8488c6240392e8a5d7553bbffcb0f94ef0 refs/remotes/origin/master
32ef1d1c7cc8c603ab78416262cc421b80a8c2df refs/remotes/origin/branch-1
75f703a3580a9b81ead89fe1138e6da858c5ba18 refs/remotes/origin/branch-2
23f8588dde934e8f33c263c6d8359b2ae095f863 refs/tags/v0.1.0
7064938bd5e7ef47bfd79a685a62c1e2649e2ce7 refs/tags/v0.2.0
6dcb09b5b57875f334f61aebed695e2e4193db5e refs/tags/v1.0.0
Git fetches the tags directly into refs/tags, rather than treating them remote branches.
COMMITTING BACK TO SUBVERSION
Now that you have a working repository, you can do some work on the project
and push your commits back upstream, using Git effectively as a SVN client. If
you edit one of the files and commit it, you have a commit that exists in Git locally that doesn’t exist on the Subversion server:
$ git commit -am 'Adding git-svn instructions to the README'
[master 4af61fd] Adding git-svn instructions to the README
1 file changed, 5 insertions(+)
Next, you need to push your change upstream. Notice how this changes the
way you work with Subversion – you can do several commits offline and then
push them all at once to the Subversion server. To push to a Subversion server,
you run the git svn dcommit command:
$ git svn dcommit
Committing to file:///tmp/test-svn/trunk ...
M README.txt
Git as a Client
421Committed r77
M README.txt
r77 = 95e0222ba6399739834380eb10afcd73e0670bc5 (refs/remotes/origin/trunk)
No changes between 4af61fd05045e07598c553167e0f31c84fd6ffe1 and refs/remotes/origi
Resetting to the latest refs/remotes/origin/trunk
This takes all the commits you’ve made on top of the Subversion server
code, does a Subversion commit for each, and then rewrites your local Git commit to include a unique identifier. This is important because it means that all
the SHA-1 checksums for your commits change. Partly for this reason, working
with Git-based remote versions of your projects concurrently with a Subversion
server isn’t a good idea. If you look at the last commit, you can see the new
git-svn-id that was added:
$ git log -1
commit 95e0222ba6399739834380eb10afcd73e0670bc5
Author: ben <ben@0b684db3-b064-4277-89d1-21af03df0a68>
Date: Thu Jul 24 03:08:36 2014 +0000
Adding git-svn instructions to the README
git-svn-id: file:///tmp/test-svn/trunk@77 0b684db3-b064-4277-89d1-21af03df0a68
Notice that the SHA-1 checksum that originally started with 4af61fd when
you committed now begins with 95e0222. If you want to push to both a Git
server and a Subversion server, you have to push (dcommit) to the Subversion
server first, because that action changes your commit data.
PULLING IN NEW CHANGES
If you’re working with other developers, then at some point one of you will
push, and then the other one will try to push a change that conflicts. That
change will be rejected until you merge in their work. In git svn, it looks like
this:
$ git svn dcommit
Committing to file:///tmp/test-svn/trunk ...
ERROR from SVN:
Transaction is out of date: File '/trunk/README.txt' is out of date
W: d5837c4b461b7c0e018b49d12398769d2bfc240a and refs/remotes/origin/trunk differ,
:100644 100644 f414c433af0fd6734428cf9d2a9fd8ba00ada145 c80b6127dd04f5fcda218730dd
Current branch master is up to date.
CHAPTER 9: Git and Other Systems
422ERROR: Not all changes have been committed into SVN, however the committed
ones (if any) seem to be successfully integrated into the working tree.
Please see the above messages for details.
To resolve this situation, you can run git svn rebase, which pulls down
any changes on the server that you don’t have yet and rebases any work you
have on top of what is on the server:
$ git svn rebase
Committing to file:///tmp/test-svn/trunk ...
ERROR from SVN:
Transaction is out of date: File '/trunk/README.txt' is out of date
W: eaa029d99f87c5c822c5c29039d19111ff32ef46 and refs/remotes/origin/trunk differ, using reba
:100644 100644 65536c6e30d263495c17d781962cfff12422693a b34372b25ccf4945fe5658fa381b075045e7
First, rewinding head to replay your work on top of it...
Applying: update foo
Using index info to reconstruct a base tree...
M README.txt
Falling back to patching base and 3-way merge...
Auto-merging README.txt
ERROR: Not all changes have been committed into SVN, however the committed
ones (if any) seem to be successfully integrated into the working tree.
Please see the above messages for details.
Now, all your work is on top of what is on the Subversion server, so you can
successfully dcommit:
$ git svn dcommit
Committing to file:///tmp/test-svn/trunk ...
M README.txt
Committed r85
M README.txt
r85 = 9c29704cc0bbbed7bd58160cfb66cb9191835cd8 (refs/remotes/origin/trunk)
No changes between 5762f56732a958d6cfda681b661d2a239cc53ef5 and refs/remotes/origin/trunk
Resetting to the latest refs/remotes/origin/trunk
Note that unlike Git, which requires you to merge upstream work you don’t
yet have locally before you can push, git svn makes you do that only if the
changes conflict (much like how Subversion works). If someone else pushes a
change to one file and then you push a change to another file, your dcommit
will work fine:
Git as a Client
423$ git svn dcommit
Committing to file:///tmp/test-svn/trunk ...
M configure.ac
Committed r87
M autogen.sh
r86 = d8450bab8a77228a644b7dc0e95977ffc61adff7 (refs/remotes/origin/trunk)
M configure.ac
r87 = f3653ea40cb4e26b6281cec102e35dcba1fe17c4 (refs/remotes/origin/trunk)
W: a0253d06732169107aa020390d9fefd2b1d92806 and refs/remotes/origin/trunk differ,
:100755 100755 efa5a59965fbbb5b2b0a12890f1b351bb5493c18 e757b59a9439312d80d5d43bb6
First, rewinding head to replay your work on top of it...
This is important to remember, because the outcome is a project state that
didn’t exist on either of your computers when you pushed. If the changes are
incompatible but don’t conflict, you may get issues that are difficult to diagnose. This is different than using a Git server – in Git, you can fully test the state
on your client system before publishing it, whereas in SVN, you can’t ever be
certain that the states immediately before commit and after commit are identical.
You should also run this command to pull in changes from the Subversion
server, even if you’re not ready to commit yourself. You can run git svn
fetch to grab the new data, but git svn rebase does the fetch and then updates your local commits.
$ git svn rebase
M autogen.sh
r88 = c9c5f83c64bd755368784b444bc7a0216cc1e17b (refs/remotes/origin/trunk)
First, rewinding head to replay your work on top of it...
Fast-forwarded master to refs/remotes/origin/trunk.
Running git svn rebase every once in a while makes sure your code is always up to date. You need to be sure your working directory is clean when you
run this, though. If you have local changes, you must either stash your work or
temporarily commit it before running git svn rebase – otherwise, the command will stop if it sees that the rebase will result in a merge conflict.
GIT BRANCHING ISSUES
When you’ve become comfortable with a Git workflow, you’ll likely create topic
branches, do work on them, and then merge them in. If you’re pushing to a
Subversion server via git svn, you may want to rebase your work onto a single branch each time instead of merging branches together. The reason to preCHAPTER 9: Git and Other Systems
424fer rebasing is that Subversion has a linear history and doesn’t deal with merges like Git does, so git svn follows only the first parent when converting the
snapshots into Subversion commits.
Suppose your history looks like the following: you created an experiment
branch, did two commits, and then merged them back into master. When you
dcommit, you see output like this:
$ git svn dcommit
Committing to file:///tmp/test-svn/trunk ...
M CHANGES.txt
Committed r89
M CHANGES.txt
r89 = 89d492c884ea7c834353563d5d913c6adf933981 (refs/remotes/origin/trunk)
M COPYING.txt
M INSTALL.txt
Committed r90
M INSTALL.txt
M COPYING.txt
r90 = cb522197870e61467473391799148f6721bcf9a0 (refs/remotes/origin/trunk)
No changes between 71af502c214ba13123992338569f4669877f55fd and refs/remotes/origin/trunk
Resetting to the latest refs/remotes/origin/trunk
Running dcommit on a branch with merged history works fine, except that
when you look at your Git project history, it hasn’t rewritten either of the commits you made on the experiment branch – instead, all those changes appear
in the SVN version of the single merge commit.
When someone else clones that work, all they see is the merge commit with
all the work squashed into it, as though you ran git merge --squash; they
don’t see the commit data about where it came from or when it was committed.
SUBVERSION BRANCHING
Branching in Subversion isn’t the same as branching in Git; if you can avoid using it much, that’s probably best. However, you can create and commit to
branches in Subversion using git svn.
CREATING A NEW SVN BRANCH
To create a new branch in Subversion, you run git svn branch [branchname]:
Git as a Client
425$ git svn branch opera
Copying file:///tmp/test-svn/trunk at r90 to file:///tmp/test-svn/branches/opera..
Found possible branch point: file:///tmp/test-svn/trunk => file:///tmp/test-svn/br
Found branch parent: (refs/remotes/origin/opera) cb522197870e61467473391799148f672
Following parent with do_switch
Successfully followed parent
r91 = f1b64a3855d3c8dd84ee0ef10fa89d27f1584302 (refs/remotes/origin/opera)
This does the equivalent of the svn copy trunk branches/opera command in Subversion and operates on the Subversion server. It’s important to
note that it doesn’t check you out into that branch; if you commit at this point,
that commit will go to trunk on the server, not opera.
SWITCHING ACTIVE BRANCHES
Git figures out what branch your dcommits go to by looking for the tip of any of
your Subversion branches in your history – you should have only one, and it
should be the last one with a git-svn-id in your current branch history.
If you want to work on more than one branch simultaneously, you can set up
local branches to dcommit to specific Subversion branches by starting them at
the imported Subversion commit for that branch. If you want an opera branch
that you can work on separately, you can run
$ git branch opera remotes/origin/opera
Now, if you want to merge your opera branch into trunk (your master
branch), you can do so with a normal git merge. But you need to provide a
descriptive commit message (via -m), or the merge will say “Merge branch opera” instead of something useful.
Remember that although you’re using git merge to do this operation, and
the merge likely will be much easier than it would be in Subversion (because Git
will automatically detect the appropriate merge base for you), this isn’t a normal Git merge commit. You have to push this data back to a Subversion server
that can’t handle a commit that tracks more than one parent; so, after you push
it up, it will look like a single commit that squashed in all the work of another
branch under a single commit. After you merge one branch into another, you
can’t easily go back and continue working on that branch, as you normally can
in Git. The dcommit command that you run erases any information that says
what branch was merged in, so subsequent merge-base calculations will be
wrong – the dcommit makes your git merge result look like you ran git
CHAPTER 9: Git and Other Systems
426merge --squash. Unfortunately, there’s no good way to avoid this situation –
Subversion can’t store this information, so you’ll always be crippled by its limitations while you’re using it as your server. To avoid issues, you should delete
the local branch (in this case, opera) after you merge it into trunk.
SUBVERSION COMMANDS
The git svn toolset provides a number of commands to help ease the transition to Git by providing some functionality that’s similar to what you had in
Subversion. Here are a few commands that give you what Subversion used to.
SVN Style History
If you’re used to Subversion and want to see your history in SVN output
style, you can run git svn log to view your commit history in SVN formatting:
$ git svn log
------------------------------------------------------------------------
r87 | schacon | 2014-05-02 16:07:37 -0700 (Sat, 02 May 2014) | 2 lines
autogen change
------------------------------------------------------------------------
r86 | schacon | 2014-05-02 16:00:21 -0700 (Sat, 02 May 2014) | 2 lines
Merge branch 'experiment'
------------------------------------------------------------------------
r85 | schacon | 2014-05-02 16:00:09 -0700 (Sat, 02 May 2014) | 2 lines
updated the changelog
You should know two important things about git svn log. First, it works
offline, unlike the real svn log command, which asks the Subversion server for
the data. Second, it only shows you commits that have been committed up to
the Subversion server. Local Git commits that you haven’t dcommited don’t
show up; neither do commits that people have made to the Subversion server
in the meantime. It’s more like the last known state of the commits on the Subversion server.
SVN Annotation
Much as the git svn log command simulates the svn log command offline, you can get the equivalent of svn annotate by running git svn blame
[FILE]. The output looks like this:
Git as a Client
427$ git svn blame README.txt
2 temporal Protocol Buffers - Google's data interchange format
2 temporal Copyright 2008 Google Inc.
2 temporal http://code.google.com/apis/protocolbuffers/
2 temporal
22 temporal C++ Installation - Unix
22 temporal =======================
2 temporal
79 schacon Committing in git-svn.
78 schacon
2 temporal To build and install the C++ Protocol Buffer runtime and the Protoco
2 temporal Buffer compiler (protoc) execute the following:
2 temporal
Again, it doesn’t show commits that you did locally in Git or that have been
pushed to Subversion in the meantime.
SVN Server Information
You can also get the same sort of information that svn info gives you by
running git svn info:
$ git svn info
Path: .
URL: https://schacon-test.googlecode.com/svn/trunk
Repository Root: https://schacon-test.googlecode.com/svn
Repository UUID: 4c93b258-373f-11de-be05-5f7a86268029
Revision: 87
Node Kind: directory
Schedule: normal
Last Changed Author: schacon
Last Changed Rev: 87
Last Changed Date: 2009-05-02 16:07:37 -0700 (Sat, 02 May 2009)
This is like blame and log in that it runs offline and is up to date only as of
the last time you communicated with the Subversion server.
Ignoring What Subversion Ignores
If you clone a Subversion repository that has svn:ignore properties set
anywhere, you’ll likely want to set corresponding .gitignore files so you
don’t accidentally commit files that you shouldn’t. git svn has two commands to help with this issue. The first is git svn create-ignore, which automatically creates corresponding .gitignore files for you so your next commit can include them.
CHAPTER 9: Git and Other Systems
428The second command is git svn show-ignore, which prints to stdout the
lines you need to put in a .gitignore file so you can redirect the output into
your project exclude file:
$ git svn show-ignore > .git/info/exclude
That way, you don’t litter the project with .gitignore files. This is a good
option if you’re the only Git user on a Subversion team, and your teammates
don’t want .gitignore files in the project.
GIT-SVN SUMMARY
The git svn tools are useful if you’re stuck with a Subversion server, or are
otherwise in a development environment that necessitates running a Subversion server. You should consider it crippled Git, however, or you’ll hit issues in
translation that may confuse you and your collaborators. To stay out of trouble,
try to follow these guidelines:
• Keep a linear Git history that doesn’t contain merge commits made by
git merge. Rebase any work you do outside of your mainline branch
back onto it; don’t merge it in.
• Don’t set up and collaborate on a separate Git server. Possibly have one
to speed up clones for new developers, but don’t push anything to it that
doesn’t have a git-svn-id entry. You may even want to add a prereceive hook that checks each commit message for a git-svn-id and
rejects pushes that contain commits without it.
If you follow those guidelines, working with a Subversion server can be more
bearable. However, if it’s possible to move to a real Git server, doing so can gain
your team a lot more.
Git and Mercurial
The DVCS universe is larger than just Git. In fact, there are many other systems
in this space, each with their own angle on how to do distributed version control correctly. Apart from Git, the most popular is Mercurial, and the two are
very similar in many respects.
The good news, if you prefer Git’s client-side behavior but are working with a
project whose source code is controlled with Mercurial, is that there’s a way to
use Git as a client for a Mercurial-hosted repository. Since the way Git talks to
server repositories is through remotes, it should come as no surprise that this
Git as a Client
429bridge is implemented as a remote helper. The project’s name is git-remote-hg,
and it can be found at https://github.com/felipec/git-remote-hg.
GIT-REMOTE-HG
First, you need to install git-remote-hg. This basically entails dropping its file
somewhere in your path, like so:
$ curl -o ~/bin/git-remote-hg \
https://raw.githubusercontent.com/felipec/git-remote-hg/master/git-remote-hg
$ chmod +x ~/bin/git-remote-hg
…assuming ~/bin is in your $PATH. Git-remote-hg has one other dependency: the mercurial library for Python. If you have Python installed, this is as
simple as:
$ pip install mercurial
(If you don’t have Python installed, visit https://www.python.org/ and get it
first.)
The last thing you’ll need is the Mercurial client. Go to http://mercurial.selenic.com/ and install it if you haven’t already.
Now you’re ready to rock. All you need is a Mercurial repository you can push
to. Fortunately, every Mercurial repository can act this way, so we’ll just use the
“hello world” repository everyone uses to learn Mercurial:
$ hg clone http://selenic.com/repo/hello /tmp/hello
GETTING STARTED
Now that we have a suitable “server-side” repository, we can go through a typical workflow. As you’ll see, these two systems are similar enough that there
isn’t much friction.
As always with Git, first we clone:
$ git clone hg::/tmp/hello /tmp/hello-git
$ cd /tmp/hello-git
$ git log --oneline --graph --decorate
CHAPTER 9: Git and Other Systems
430* ac7955c (HEAD, origin/master, origin/branches/default, origin/HEAD, refs/hg/origin/branche
* 65bb417 Create a standard "hello, world" program
You’ll notice that working with a Mercurial repository uses the standard git
clone command. That’s because git-remote-hg is working at a fairly low level,
using a similar mechanism to how Git’s HTTP/S protocol is implemented (remote helpers). Since Git and Mercurial are both designed for every client to
have a full copy of the repository history, this command makes a full clone, including all the project’s history, and does it fairly quickly.
The log command shows two commits, the latest of which is pointed to by a
whole slew of refs. It turns out some of these aren’t actually there. Let’s take a
look at what’s actually in the .git directory:
$ tree .git/refs
.git/refs
├── heads
│ └── master
├── hg
│ └── origin
│ ├── bookmarks
│ │ └── master
│ └── branches
│ └── default
├── notes
│ └── hg
├── remotes
│ └── origin
│ └── HEAD
└── tags
9 directories, 5 files
Git-remote-hg is trying to make things more idiomatically Git-esque, but under the hood it’s managing the conceptual mapping between two slightly different systems. The refs/hg directory is where the actual remote refs are stored.
For example, the refs/hg/origin/branches/default is a Git ref file that
contains the SHA-1 starting with “ac7955c”, which is the commit that master
points to. So the refs/hg directory is kind of like a fake refs/remotes/
origin, but it has the added distinction between bookmarks and branches.
The notes/hg file is the starting point for how git-remote-hg maps Git commit hashes to Mercurial changeset IDs. Let’s explore a bit:
Git as a Client
431$ cat notes/hg
d4c10386...
$ git cat-file -p d4c10386...
tree 1781c96...
author remote-hg <> 1408066400 -0800
committer remote-hg <> 1408066400 -0800
Notes for master
$ git ls-tree 1781c96...
100644 blob ac9117f... 65bb417...
100644 blob 485e178... ac7955c...
$ git cat-file -p ac9117f
0a04b987be5ae354b710cefeba0e2d9de7ad41a9
So refs/notes/hg points to a tree, which in the Git object database is a list
of other objects with names. git ls-tree outputs the mode, type, object
hash, and filename for items inside a tree. Once we dig down to one of the tree
items, we find that inside it is a blob named “ac9117f” (the SHA-1 hash of the
commit pointed to by master), with contents “0a04b98” (which is the ID of the
Mercurial changeset at the tip of the default branch).
The good news is that we mostly don’t have to worry about all of this. The
typical workflow won’t be very different from working with a Git remote.
There’s one more thing we should attend to before we continue: ignores.
Mercurial and Git use a very similar mechanism for this, but it’s likely you don’t
want to actually commit a .gitignore file into a Mercurial repository. Fortunately, Git has a way to ignore files that’s local to an on-disk repository, and the
Mercurial format is compatible with Git, so you just have to copy it over:
$ cp .hgignore .git/info/exclude
The .git/info/exclude file acts just like a .gitignore, but isn’t included
in commits.
WORKFLOW
Let’s assume we’ve done some work and made some commits on the master
branch, and you’re ready to push it to the remote repository. Here’s what our
repository looks like right now:
CHAPTER 9: Git and Other Systems
432$ git log --oneline --graph --decorate
* ba04a2a (HEAD, master) Update makefile
* d25d16f Goodbye
* ac7955c (origin/master, origin/branches/default, origin/HEAD, refs/hg/origin/branches/defa
* 65bb417 Create a standard "hello, world" program
Our master branch is two commits ahead of origin/master, but those two
commits exist only on our local machine. Let’s see if anyone else has been doing important work at the same time:
$ git fetch
From hg::/tmp/hello
ac7955c..df85e87 master -> origin/master
ac7955c..df85e87 branches/default -> origin/branches/default
$ git log --oneline --graph --decorate --all
* 7b07969 (refs/notes/hg) Notes for default
* d4c1038 Notes for master
* df85e87 (origin/master, origin/branches/default, origin/HEAD, refs/hg/origin/branches/defa
| * ba04a2a (HEAD, master) Update makefile
| * d25d16f Goodbye
|/
* ac7955c Create a makefile
* 65bb417 Create a standard "hello, world" program
Since we used the --all flag, we see the “notes” refs that are used internally by git-remote-hg, but we can ignore them. The rest is what we expected;
origin/master has advanced by one commit, and our history has now diverged. Unlike the other systems we work with in this chapter, Mercurial is capable of handling merges, so we’re not going to do anything fancy.
$ git merge origin/master
Auto-merging hello.c
Merge made by the 'recursive' strategy.
hello.c | 2 +-
1 file changed, 1 insertion(+), 1 deletion(-)
$ git log --oneline --graph --decorate
* 0c64627 (HEAD, master) Merge remote-tracking branch 'origin/master'
|\
| * df85e87 (origin/master, origin/branches/default, origin/HEAD, refs/hg/origin/branches/de
* | ba04a2a Update makefile
* | d25d16f Goodbye
|/
* ac7955c Create a makefile
* 65bb417 Create a standard "hello, world" program
Git as a Client
433Perfect. We run the tests and everything passes, so we’re ready to share our
work with the rest of the team:
$ git push
To hg::/tmp/hello
df85e87..0c64627 master -> master
That’s it! If you take a look at the Mercurial repository, you’ll see that this did
what we’d expect:
$ hg log -G --style compact
o 5[tip]:4,2 dc8fa4f932b8 2014-08-14 19:33 -0700 ben
|\ Merge remote-tracking branch 'origin/master'
| |
| o 4 64f27bcefc35 2014-08-14 19:27 -0700 ben
| | Update makefile
| |
| o 3:1 4256fc29598f 2014-08-14 19:27 -0700 ben
| | Goodbye
| |
@ | 2 7db0b4848b3c 2014-08-14 19:30 -0700 ben
|/ Add some documentation
|
o 1 82e55d328c8c 2005-08-26 01:21 -0700 mpm
| Create a makefile
|
o 0 0a04b987be5a 2005-08-26 01:20 -0700 mpm
Create a standard "hello, world" program
The changeset numbered 2 was made by Mercurial, and the changesets
numbered 3 and 4 were made by git-remote-hg, by pushing commits made with
Git.
BRANCHES AND BOOKMARKS
Git has only one kind of branch: a reference that moves when commits are
made. In Mercurial, this kind of a reference is called a “bookmark,” and it behaves in much the same way as a Git branch.
Mercurial’s concept of a “branch” is more heavyweight. The branch that a
changeset is made on is recorded with the changeset, which means it will always be in the repository history. Here’s an example of a commit that was made
on the develop branch:
CHAPTER 9: Git and Other Systems
434$ hg log -l 1
changeset: 6:8f65e5e02793
branch: develop
tag: tip
user: Ben Straub <ben@straub.cc>
date: Thu Aug 14 20:06:38 2014 -0700
summary: More documentation
Note the line that begins with “branch”. Git can’t really replicate this (and
doesn’t need to; both types of branch can be represented as a Git ref), but gitremote-hg needs to understand the difference, because Mercurial cares.
Creating Mercurial bookmarks is as easy as creating Git branches. On the Git
side:
$ git checkout -b featureA
Switched to a new branch 'featureA'
$ git push origin featureA
To hg::/tmp/hello
* [new branch] featureA -> featureA
That’s all there is to it. On the Mercurial side, it looks like this:
$ hg bookmarks
featureA 5:bd5ac26f11f9
$ hg log --style compact -G
@ 6[tip] 8f65e5e02793 2014-08-14 20:06 -0700 ben
| More documentation
|
o 5[featureA]:4,2 bd5ac26f11f9 2014-08-14 20:02 -0700 ben
|\ Merge remote-tracking branch 'origin/master'
| |
| o 4 0434aaa6b91f 2014-08-14 20:01 -0700 ben
| | update makefile
| |
| o 3:1 318914536c86 2014-08-14 20:00 -0700 ben
| | goodbye
| |
o | 2 f098c7f45c4f 2014-08-14 20:01 -0700 ben
|/ Add some documentation
|
o 1 82e55d328c8c 2005-08-26 01:21 -0700 mpm
| Create a makefile
|
Git as a Client
435o 0 0a04b987be5a 2005-08-26 01:20 -0700 mpm
Create a standard "hello, world" program
Note the new [featureA] tag on revision 5. These act exactly like Git
branches on the Git side, with one exception: you can’t delete a bookmark from
the Git side (this is a limitation of remote helpers).
You can work on a “heavyweight” Mercurial branch also: just put a branch in
the branches namespace:
$ git checkout -b branches/permanent
Switched to a new branch 'branches/permanent'
$ vi Makefile
$ git commit -am 'A permanent change'
$ git push origin branches/permanent
To hg::/tmp/hello
* [new branch] branches/permanent -> branches/permanent
Here’s what that looks like on the Mercurial side:
$ hg branches
permanent 7:a4529d07aad4
develop 6:8f65e5e02793
default 5:bd5ac26f11f9 (inactive)
$ hg log -G
o changeset: 7:a4529d07aad4
| branch: permanent
| tag: tip
| parent: 5:bd5ac26f11f9
| user: Ben Straub <ben@straub.cc>
| date: Thu Aug 14 20:21:09 2014 -0700
| summary: A permanent change
|
| @ changeset: 6:8f65e5e02793
|/ branch: develop
| user: Ben Straub <ben@straub.cc>
| date: Thu Aug 14 20:06:38 2014 -0700
| summary: More documentation
|
o changeset: 5:bd5ac26f11f9
|\ bookmark: featureA
| | parent: 4:0434aaa6b91f
| | parent: 2:f098c7f45c4f
| | user: Ben Straub <ben@straub.cc>
| | date: Thu Aug 14 20:02:21 2014 -0700
CHAPTER 9: Git and Other Systems
436| | summary: Merge remote-tracking branch 'origin/master'
[...]
The branch name “permanent” was recorded with the changeset marked 7.
From the Git side, working with either of these branch styles is the same: just
checkout, commit, fetch, merge, pull, and push as you normally would. One
thing you should know is that Mercurial doesn’t support rewriting history, only
adding to it. Here’s what our Mercurial repository looks like after an interactive
rebase and a force-push:
$ hg log --style compact -G
o 10[tip] 99611176cbc9 2014-08-14 20:21 -0700 ben
| A permanent change
|
o 9 f23e12f939c3 2014-08-14 20:01 -0700 ben
| Add some documentation
|
o 8:1 c16971d33922 2014-08-14 20:00 -0700 ben
| goodbye
|
| o 7:5 a4529d07aad4 2014-08-14 20:21 -0700 ben
| | A permanent change
| |
| | @ 6 8f65e5e02793 2014-08-14 20:06 -0700 ben
| |/ More documentation
| |
| o 5[featureA]:4,2 bd5ac26f11f9 2014-08-14 20:02 -0700 ben
| |\ Merge remote-tracking branch 'origin/master'
| | |
| | o 4 0434aaa6b91f 2014-08-14 20:01 -0700 ben
| | | update makefile
| | |
+---o 3:1 318914536c86 2014-08-14 20:00 -0700 ben
| | goodbye
| |
| o 2 f098c7f45c4f 2014-08-14 20:01 -0700 ben
|/ Add some documentation
|
o 1 82e55d328c8c 2005-08-26 01:21 -0700 mpm
| Create a makefile
|
o 0 0a04b987be5a 2005-08-26 01:20 -0700 mpm
Create a standard "hello, world" program
Git as a Client
437Changesets 8, 9, and 10 have been created and belong to the permanent
branch, but the old changesets are still there. This can be very confusing for
your teammates who are using Mercurial, so try to avoid it.
MERCURIAL SUMMARY
Git and Mercurial are similar enough that working across the boundary is fairly
painless. If you avoid changing history that’s left your machine (as is generally
recommended), you may not even be aware that the other end is Mercurial.
Git and Perforce
Perforce is a very popular version-control system in corporate environments.
It’s been around since 1995, which makes it the oldest system covered in this
chapter. As such, it’s designed with the constraints of its day; it assumes you’re
always connected to a single central server, and only one version is kept on the
local disk. To be sure, its features and constraints are well-suited to several specific problems, but there are lots of projects using Perforce where Git would actually work better.
There are two options if you’d like to mix your use of Perforce and Git. The
first one we’ll cover is the “Git Fusion” bridge from the makers of Perforce,
which lets you expose subtrees of your Perforce depot as read-write Git repositories. The second is git-p4, a client-side bridge that lets you use Git as a Perforce client, without requiring any reconfiguration of the Perforce server.
GIT FUSION
Perforce provides a product called Git Fusion (available at http://
www.perforce.com/git-fusion), which synchronizes a Perforce server with Git
repositories on the server side.
Setting Up
For our examples, we’ll be using the easiest installation method for Git Fusion, which is downloading a virtual machine that runs the Perforce daemon
and Git Fusion. You can get the virtual machine image from http://
www.perforce.com/downloads/Perforce/20-User, and once it’s finished downloading, import it into your favorite virtualization software (we’ll use VirtualBox).
Upon first starting the machine, it asks you to customize the password for
three Linux users (root, perforce, and git), and provide an instance name,
which can be used to distinguish this installation from others on the same network. When that has all completed, you’ll see this:
CHAPTER 9: Git and Other Systems
438FIGURE 9-1
The Git Fusion
virtual machine boot
screen.
You should take note of the IP address that’s shown here, we’ll be using it
later on. Next, we’ll create a Perforce user. Select the “Login” option at the bottom and press enter (or SSH to the machine), and log in as root. Then use
these commands to create a user:
$ p4 -p localhost:1666 -u super user -f john
$ p4 -p localhost:1666 -u john passwd
$ exit
The first one will open a VI editor to customize the user, but you can accept
the defaults by typing :wq and hitting enter. The second one will prompt you to
enter a password twice. That’s all we need to do with a shell prompt, so exit out
of the session.
The next thing you’ll need to do to follow along is to tell Git not to verify SSL
certificates. The Git Fusion image comes with a certificate, but it’s for a domain
that won’t match your virtual machine’s IP address, so Git will reject the HTTPS
connection. If this is going to be a permanent installation, consult the Perforce
Git as a Client
439Git Fusion manual to install a different certificate; for our example purposes,
this will suffice:
$ export GIT_SSL_NO_VERIFY=true
Now we can test that everything is working.
$ git clone https://10.0.1.254/Talkhouse
Cloning into 'Talkhouse'...
Username for 'https://10.0.1.254': john
Password for 'https://john@10.0.1.254':
remote: Counting objects: 630, done.
remote: Compressing objects: 100% (581/581), done.
remote: Total 630 (delta 172), reused 0 (delta 0)
Receiving objects: 100% (630/630), 1.22 MiB | 0 bytes/s, done.
Resolving deltas: 100% (172/172), done.
Checking connectivity... done.
The virtual-machine image comes equipped with a sample project that you
can clone. Here we’re cloning over HTTPS, with the john user that we created
above; Git asks for credentials for this connection, but the credential cache will
allow us to skip this step for any subsequent requests.
Fusion Configuration
Once you’ve got Git Fusion installed, you’ll want to tweak the configuration.
This is actually fairly easy to do using your favorite Perforce client; just map
the //.git-fusion directory on the Perforce server into your workspace. The
file structure looks like this:
$ tree
.
├── objects
│ ├── repos
│ │ └── [...]
│ └── trees
│ └── [...]
│
├── p4gf_config
├── repos
│ └── Talkhouse
│ └── p4gf_config
└── users
└── p4gf_usermap
CHAPTER 9: Git and Other Systems
440498 directories, 287 files
The objects directory is used internally by Git Fusion to map Perforce objects to Git and vice versa, you won’t have to mess with anything in there.
There’s a global p4gf_config file in this directory, as well as one for each
repository – these are the configuration files that determine how Git Fusion behaves. Let’s take a look at the file in the root:
[repo-creation]
charset = utf8
[git-to-perforce]
change-owner = author
enable-git-branch-creation = yes
enable-swarm-reviews = yes
enable-git-merge-commits = yes
enable-git-submodules = yes
preflight-commit = none
ignore-author-permissions = no
read-permission-check = none
git-merge-avoidance-after-change-num = 12107
[perforce-to-git]
http-url = none
ssh-url = none
[@features]
imports = False
chunked-push = False
matrix2 = False
parallel-push = False
[authentication]
email-case-sensitivity = no
We won’t go into the meanings of these flags here, but note that this is just
an INI-formatted text file, much like Git uses for configuration. This file specifies
the global options, which can then be overridden by repository-specific configuration files, like repos/Talkhouse/p4gf_config. If you open this file, you’ll
see a [@repo] section with some settings that are different from the global defaults. You’ll also see sections that look like this:
[Talkhouse-master]
git-branch-name = master
view = //depot/Talkhouse/main-dev/... ...
Git as a Client
441This is a mapping between a Perforce branch and a Git branch. The section
can be named whatever you like, so long as the name is unique. git-branchname lets you convert a depot path that would be cumbersome under Git to a
more friendly name. The view setting controls how Perforce files are mapped
into the Git repository, using the standard view mapping syntax. More than one
mapping can be specified, like in this example:
[multi-project-mapping]
git-branch-name = master
view = //depot/project1/main/... project1/...
//depot/project2/mainline/... project2/...
This way, if your normal workspace mapping includes changes in the structure of the directories, you can replicate that with a Git repository.
The last file we’ll discuss is users/p4gf_usermap, which maps Perforce
users to Git users, and which you may not even need. When converting from a
Perforce changeset to a Git commit, Git Fusion’s default behavior is to look up
the Perforce user, and use the email address and full name stored there for the
author/committer field in Git. When converting the other way, the default is to
look up the Perforce user with the email address stored in the Git commit’s author field, and submit the changeset as that user (with permissions applying).
In most cases, this behavior will do just fine, but consider the following mapping file:
john john@example.com "John Doe"
john johnny@appleseed.net "John Doe"
bob employeeX@example.com "Anon X. Mouse"
joe employeeY@example.com "Anon Y. Mouse"
Each line is of the format <user> <email> "<full name>", and creates a
single user mapping. The first two lines map two distinct email addresses to the
same Perforce user account. This is useful if you’ve created Git commits under
several different email addresses (or change email addresses), but want them
to be mapped to the same Perforce user. When creating a Git commit from a
Perforce changeset, the first line matching the Perforce user is used for Git authorship information.
The last two lines mask Bob and Joe’s actual names and email addresses
from the Git commits that are created. This is nice if you want to open-source
an internal project, but don’t want to publish your employee directory to the
entire world. Note that the email addresses and full names should be unique,
unless you want all the Git commits to be attributed to a single fictional author.
CHAPTER 9: Git and Other Systems
442Workflow
Perforce Git Fusion is a two-way bridge between Perforce and Git version
control. Let’s have a look at how it feels to work from the Git side. We’ll assume
we’ve mapped in the “Jam” project using a configuration file as shown above,
which we can clone like this:
$ git clone https://10.0.1.254/Jam
Cloning into 'Jam'...
Username for 'https://10.0.1.254': john
Password for 'https://ben@10.0.1.254':
remote: Counting objects: 2070, done.
remote: Compressing objects: 100% (1704/1704), done.
Receiving objects: 100% (2070/2070), 1.21 MiB | 0 bytes/s, done.
remote: Total 2070 (delta 1242), reused 0 (delta 0)
Resolving deltas: 100% (1242/1242), done.
Checking connectivity... done.
$ git branch -a
* master
remotes/origin/HEAD -> origin/master
remotes/origin/master
remotes/origin/rel2.1
$ git log --oneline --decorate --graph --all
* 0a38c33 (origin/rel2.1) Create Jam 2.1 release branch.
| * d254865 (HEAD, origin/master, origin/HEAD, master) Upgrade to latest metrowerks on Beos
| * bd2f54a Put in fix for jam's NT handle leak.
| * c0f29e7 Fix URL in a jam doc
| * cc644ac Radstone's lynx port.
[...]
The first time you do this, it may take some time. What’s happening is that
Git Fusion is converting all the applicable changesets in the Perforce history into Git commits. This happens locally on the server, so it’s relatively fast, but if
you have a lot of history, it can still take some time. Subsequent fetches do incremental conversion, so it’ll feel more like Git’s native speed.
As you can see, our repository looks exactly like any other Git repository you
might work with. There are three branches, and Git has helpfully created a local
master branch that tracks origin/master. Let’s do a bit of work, and create a
couple of new commits:
# ...
$ git log --oneline --decorate --graph --all
* cfd46ab (HEAD, master) Add documentation for new feature
* a730d77 Whitespace
* d254865 (origin/master, origin/HEAD) Upgrade to latest metrowerks on Beos -- the Intel one
Git as a Client
443* bd2f54a Put in fix for jam's NT handle leak.
[...]
We have two new commits. Now let’s check if anyone else has been working:
$ git fetch
remote: Counting objects: 5, done.
remote: Compressing objects: 100% (3/3), done.
remote: Total 3 (delta 2), reused 0 (delta 0)
Unpacking objects: 100% (3/3), done.
From https://10.0.1.254/Jam
d254865..6afeb15 master -> origin/master
$ git log --oneline --decorate --graph --all
* 6afeb15 (origin/master, origin/HEAD) Update copyright
| * cfd46ab (HEAD, master) Add documentation for new feature
| * a730d77 Whitespace
|/
* d254865 Upgrade to latest metrowerks on Beos -- the Intel one.
* bd2f54a Put in fix for jam's NT handle leak.
[...]
It looks like someone was! You wouldn’t know it from this view, but the
6afeb15 commit was actually created using a Perforce client. It just looks like
another commit from Git’s point of view, which is exactly the point. Let’s see
how the Perforce server deals with a merge commit:
$ git merge origin/master
Auto-merging README
Merge made by the 'recursive' strategy.
README | 2 +-
1 file changed, 1 insertion(+), 1 deletion(-)
$ git push
Counting objects: 9, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (9/9), done.
Writing objects: 100% (9/9), 917 bytes | 0 bytes/s, done.
Total 9 (delta 6), reused 0 (delta 0)
remote: Perforce: 100% (3/3) Loading commit tree into memory...
remote: Perforce: 100% (5/5) Finding child commits...
remote: Perforce: Running git fast-export...
remote: Perforce: 100% (3/3) Checking commits...
remote: Processing will continue even if connection is closed.
remote: Perforce: 100% (3/3) Copying changelists...
remote: Perforce: Submitting new Git commit objects to Perforce: 4
CHAPTER 9: Git and Other Systems
444FIGURE 9-2
Perforce revision
graph resulting from
Git push.
To https://10.0.1.254/Jam
6afeb15..89cba2b master -> master
Git thinks it worked. Let’s take a look at the history of the README file from
Perforce’s point of view, using the revision graph feature of p4v:
If you’ve never seen this view before, it may seem confusing, but it shows the
same concepts as a graphical viewer for Git history. We’re looking at the history
of the README file, so the directory tree at top left only shows that file as it surfaces in various branches. At top right, we have a visual graph of how different
revisions of the file are related, and the big-picture view of this graph is at bottom right. The rest of the view is given to the details view for the selected revision (2 in this case).
One thing to notice is that the graph looks exactly like the one in Git’s history. Perforce didn’t have a named branch to store the 1 and 2 commits, so it
made an “anonymous” branch in the .git-fusion directory to hold it. This
will also happen for named Git branches that don’t correspond to a named Perforce branch (and you can later map them to a Perforce branch using the configuration file).
Most of this happens behind the scenes, but the end result is that one person on a team can be using Git, another can be using Perforce, and neither of
them will know about the other’s choice.
Git as a Client
445Git-Fusion Summary
If you have (or can get) access to your Perforce server, Git Fusion is a great
way to make Git and Perforce talk to each other. There’s a bit of configuration
involved, but the learning curve isn’t very steep. This is one of the few sections
in this chapter where cautions about using Git’s full power will not appear.
That’s not to say that Perforce will be happy with everything you throw at it – if
you try to rewrite history that’s already been pushed, Git Fusion will reject it –
but Git Fusion tries very hard to feel native. You can even use Git submodules
(though they’ll look strange to Perforce users), and merge branches (this will be
recorded as an integration on the Perforce side).
If you can’t convince the administrator of your server to set up Git Fusion,
there is still a way to use these tools together.
GIT-P4
Git-p4 is a two-way bridge between Git and Perforce. It runs entirely inside your
Git repository, so you won’t need any kind of access to the Perforce server (other than user credentials, of course). Git-p4 isn’t as flexible or complete a solution as Git Fusion, but it does allow you to do most of what you’d want to do
without being invasive to the server environment.
You’ll need the p4 tool somewhere in your PATH to work with git-p4. As of
this writing, it is freely available at http://www.perforce.com/downloads/
Perforce/20-User.
Setting Up
For example purposes, we’ll be running the Perforce server from the Git Fusion OVA as shown above, but we’ll bypass the Git Fusion server and go directly
to the Perforce version control.
In order to use the p4 command-line client (which git-p4 depends on), you’ll
need to set a couple of environment variables:
$ export P4PORT=10.0.1.254:1666
$ export P4USER=john
Getting Started
As with anything in Git, the first command is to clone:
$ git p4 clone //depot/www/live www-shallow
Importing from //depot/www/live into www-shallow
CHAPTER 9: Git and Other Systems
446Initialized empty Git repository in /private/tmp/www-shallow/.git/
Doing initial import of //depot/www/live/ from revision #head into refs/remotes/p4/master
This creates what in Git terms is a “shallow” clone; only the very latest Perforce revision is imported into Git; remember, Perforce isn’t designed to give
every revision to every user. This is enough to use Git as a Perforce client, but
for other purposes it’s not enough.
Once it’s finished, we have a fully-functional Git repository:
$ cd myproject
$ git log --oneline --all --graph --decorate
* 70eaf78 (HEAD, p4/master, p4/HEAD, master) Initial import of //depot/www/live/ from the st
Note how there’s a “p4” remote for the Perforce server, but everything else
looks like a standard clone. Actually, that’s a bit misleading; there isn’t actually
a remote there.
$ git remote -v
No remotes exist in this repository at all. Git-p4 has created some refs to represent the state of the server, and they look like remote refs to git log, but
they’re not managed by Git itself, and you can’t push to them.
Workflow
Okay, let’s do some work. Let’s assume you’ve made some progress on a
very important feature, and you’re ready to show it to the rest of your team.
$ git log --oneline --all --graph --decorate
* 018467c (HEAD, master) Change page title
* c0fb617 Update link
* 70eaf78 (p4/master, p4/HEAD) Initial import of //depot/www/live/ from the state at revisio
We’ve made two new commits that we’re ready to submit to the Perforce
server. Let’s check if anyone else was working today:
$ git p4 sync
git p4 sync
Performing incremental import into refs/remotes/p4/master git branch
Depot paths: //depot/www/live/
Import destination: refs/remotes/p4/master
Importing revision 12142 (100%)
$ git log --oneline --all --graph --decorate
Git as a Client
447* 75cd059 (p4/master, p4/HEAD) Update copyright
| * 018467c (HEAD, master) Change page title
| * c0fb617 Update link
|/
* 70eaf78 Initial import of //depot/www/live/ from the state at revision #head
Looks like they were, and master and p4/master have diverged. Perforce’s
branching system is nothing like Git’s, so submitting merge commits doesn’t
make any sense. Git-p4 recommends that you rebase your commits, and even
comes with a shortcut to do so:
$ git p4 rebase
Performing incremental import into refs/remotes/p4/master git branch
Depot paths: //depot/www/live/
No changes to import!
Rebasing the current branch onto remotes/p4/master
First, rewinding head to replay your work on top of it...
Applying: Update link
Applying: Change page title
index.html | 2 +-
1 file changed, 1 insertion(+), 1 deletion(-)
You can probably tell from the output, but git p4 rebase is a shortcut for
git p4 sync followed by git rebase p4/master. It’s a bit smarter than
that, especially when working with multiple branches, but this is a good approximation.
Now our history is linear again, and we’re ready to contribute our changes
back to Perforce. The git p4 submit command will try to create a new Perforce revision for every Git commit between p4/master and master. Running it
drops us into our favorite editor, and the contents of the file look something like
this:
# A Perforce Change Specification.
# #
Change: The change number. 'new' on a new changelist.
# Date: The date this specification was last modified.
# Client: The client on which the changelist was created. Read-only.
# User: The user who created the changelist.
# Status: Either 'pending' or 'submitted'. Read-only.
# Type: Either 'public' or 'restricted'. Default is 'public'.
# Description: Comments about the changelist. Required.
# Jobs: What opened jobs are to be closed by this changelist.
# You may delete jobs from this list. (New changelists only.)
# Files: What opened files from the default changelist are to be added
CHAPTER 9: Git and Other Systems
448# to this changelist. You may delete files from this list.
# (New changelists only.)
Change: new
Client: john_bens-mbp_8487
User: john
Status: new
Description:
Update link
Files:
//depot/www/live/index.html # edit
######## git author ben@straub.cc does not match your p4 account.
######## Use option --preserve-user to modify authorship.
######## Variable git-p4.skipUserNameCheck hides this message.
######## everything below this line is just the diff #######
--- //depot/www/live/index.html 2014-08-31 18:26:05.000000000 0000
+++ /Users/ben/john_bens-mbp_8487/john_bens-mbp_8487/depot/www/live/index.html 2014-08-31
@@ -60,7 +60,7 @@
</td>
<td valign=top>
Source and documentation for
-<a href="http://www.perforce.com/jam/jam.html">
+<a href="jam.html">
Jam/MR</a>,
a software build tool.
</td>
This is mostly the same content you’d see by running p4 submit, except the
stuff at the end which git-p4 has helpfully included. Git-p4 tries to honor your
Git and Perforce settings individually when it has to provide a name for a commit or changeset, but in some cases you want to override it. For example, if the
Git commit you’re importing was written by a contributor who doesn’t have a
Perforce user account, you may still want the resulting changeset to look like
they write it (and not you).
Git-p4 has helpfully imported the message from the Git commit as the content for this Perforce changeset, so all we have to do is save and quit, twice
(once for each commit). The resulting shell output will look something like this:
Git as a Client
449$ git p4 submit
Perforce checkout for depot path //depot/www/live/ located at /Users/ben/john_bens
Synchronizing p4 checkout...
... - file(s) up-to-date.
Applying dbac45b Update link
//depot/www/live/index.html#4 - opened for edit
Change 12143 created with 1 open file(s).
Submitting change 12143.
Locking 1 files ...
edit //depot/www/live/index.html#5
Change 12143 submitted.
Applying 905ec6a Change page title
//depot/www/live/index.html#5 - opened for edit
Change 12144 created with 1 open file(s).
Submitting change 12144.
Locking 1 files ...
edit //depot/www/live/index.html#6
Change 12144 submitted.
All commits applied!
Performing incremental import into refs/remotes/p4/master git branch
Depot paths: //depot/www/live/
Import destination: refs/remotes/p4/master
Importing revision 12144 (100%)
Rebasing the current branch onto remotes/p4/master
First, rewinding head to replay your work on top of it...
$ git log --oneline --all --graph --decorate
* 775a46f (HEAD, p4/master, p4/HEAD, master) Change page title
* 05f1ade Update link
* 75cd059 Update copyright
* 70eaf78 Initial import of //depot/www/live/ from the state at revision #head
The result is as though we just did a git push, which is the closest analogy
to what actually did happen.
Note that during this process every Git commit is turned into a Perforce
changeset; if you want to squash them down into a single changeset, you can
do that with an interactive rebase before running git p4 submit. Also note
that the SHA-1 hashes of all the commits that were submitted as changesets
have changed; this is because git-p4 adds a line to the end of each commit it
converts:
$ git log -1
commit 775a46f630d8b46535fc9983cf3ebe6b9aa53145
Author: John Doe <john@example.com>
Date: Sun Aug 31 10:31:44 2014 -0800
Change page title
CHAPTER 9: Git and Other Systems
450[git-p4: depot-paths = "//depot/www/live/": change = 12144]
What happens if you try to submit a merge commit? Let’s give it a try. Here’s
the situation we’ve gotten ourselves into:
$ git log --oneline --all --graph --decorate
* 3be6fd8 (HEAD, master) Correct email address
* 1dcbf21 Merge remote-tracking branch 'p4/master'
|\
| * c4689fc (p4/master, p4/HEAD) Grammar fix
* | cbacd0a Table borders: yes please
* | b4959b6 Trademark
|/
* 775a46f Change page title
* 05f1ade Update link
* 75cd059 Update copyright
* 70eaf78 Initial import of //depot/www/live/ from the state at revision #head
The Git and Perforce history diverge after 775a46f. The Git side has two commits, then a merge commit with the Perforce head, then another commit. We’re
going to try to submit these on top of a single changeset on the Perforce side.
Let’s see what would happen if we tried to submit now:
$ git p4 submit -n
Perforce checkout for depot path //depot/www/live/ located at /Users/ben/john_bens-mbp_8487/
Would synchronize p4 checkout in /Users/ben/john_bens-mbp_8487/john_bens-mbp_8487/depot/www/
Would apply
b4959b6 Trademark
cbacd0a Table borders: yes please
3be6fd8 Correct email address
The -n flag is short for --dry-run, which tries to report what would happen
if the submit command were run for real. In this case, it looks like we’d be creating three Perforce changesets, which correspond to the three non-merge commits that don’t yet exist on the Perforce server. That sounds like exactly what
we want, let’s see how it turns out:
$ git p4 submit
[…]
$ git log --oneline --all --graph --decorate
* dadbd89 (HEAD, p4/master, p4/HEAD, master) Correct email address
* 1b79a80 Table borders: yes please
Git as a Client
451* 0097235 Trademark
* c4689fc Grammar fix
* 775a46f Change page title
* 05f1ade Update link
* 75cd059 Update copyright
* 70eaf78 Initial import of //depot/www/live/ from the state at revision #head
Our history became linear, just as though we had rebased before submitting
(which is in fact exactly what happened). This means you can be free to create,
work on, throw away, and merge branches on the Git side without fear that
your history will somehow become incompatible with Perforce. If you can rebase it, you can contribute it to a Perforce server.
Branching
If your Perforce project has multiple branches, you’re not out of luck; git-p4
can handle that in a way that makes it feel like Git. Let’s say your Perforce depot
is laid out like this:
//depot
└── project
├── main
└── dev
And let’s say you have a dev branch, which has a view spec that looks like
this:
//depot/project/main/... //depot/project/dev/...
Git-p4 can automatically detect that situation and do the right thing:
$ git p4 clone --detect-branches //depot/project@all
Importing from //depot/project@all into project
Initialized empty Git repository in /private/tmp/project/.git/
Importing revision 20 (50%)
Importing new branch project/dev
Resuming with change 20
Importing revision 22 (100%)
Updated branches: main dev
$ cd project; git log --oneline --all --graph --decorate
* eae77ae (HEAD, p4/master, p4/HEAD, master) main
| * 10d55fb (p4/project/dev) dev
| * a43cfae Populate //depot/project/main/... //depot/project/dev/....
|/
* 2b83451 Project init
CHAPTER 9: Git and Other Systems
452Note the “@all” specifier in the depot path; that tells git-p4 to clone not just
the latest changeset for that subtree, but all changesets that have ever touched
those paths. This is closer to Git’s concept of a clone, but if you’re working on a
project with a long history, it could take a while.
The --detect-branches flag tells git-p4 to use Perforce’s branch specs to
map the branches to Git refs. If these mappings aren’t present on the Perforce
server (which is a perfectly valid way to use Perforce), you can tell git-p4 what
the branch mappings are, and you get the same result:
$ git init project
Initialized empty Git repository in /tmp/project/.git/
$ cd project
$ git config git-p4.branchList main:dev
$ git clone --detect-branches //depot/project@all .
Setting the git-p4.branchList configuration variable to main:dev tells
git-p4 that “main” and “dev” are both branches, and the second one is a child
of the first one.
If we now git checkout -b dev p4/project/dev and make some commits, git-p4 is smart enough to target the right branch when we do git p4
submit. Unfortunately, git-p4 can’t mix shallow clones and multiple branches;
if you have a huge project and want to work on more than one branch, you’ll
have to git p4 clone once for each branch you want to submit to.
For creating or integrating branches, you’ll have to use a Perforce client. Gitp4 can only sync and submit to existing branches, and it can only do it one linear changeset at a time. If you merge two branches in Git and try to submit the
new changeset, all that will be recorded is a bunch of file changes; the metadata about which branches are involved in the integration will be lost.
GIT AND PERFORCE SUMMARY
Git-p4 makes it possible to use a Git workflow with a Perforce server, and it’s
pretty good at it. However, it’s important to remember that Perforce is in charge
of the source, and you’re only using Git to work locally. Just be really careful
about sharing Git commits; if you have a remote that other people use, don’t
push any commits that haven’t already been submitted to the Perforce server.
If you want to freely mix the use of Perforce and Git as clients for source control, and you can convince the server administrator to install it, Git Fusion
makes using Git a first-class version-control client for a Perforce server.
Git as a Client
453Git and TFS
Git is becoming popular with Windows developers, and if you’re writing code on
Windows, there’s a good chance you’re using Microsoft’s Team Foundation
Server (TFS). TFS is a collaboration suite that includes defect and work-item
tracking, process support for Scrum and others, code review, and version control. There’s a bit of confusion ahead: TFS is the server, which supports controlling source code using both Git and their own custom VCS, which they’ve dubbed TFVC (Team Foundation Version Control). Git support is a somewhat new
feature for TFS (shipping with the 2013 version), so all of the tools that predate
that refer to the version-control portion as “TFS”, even though they’re mostly
working with TFVC.
If you find yourself on a team that’s using TFVC but you’d rather use Git as
your version-control client, there’s a project for you.
WHICH TOOL
In fact, there are two: git-tf and git-tfs.
Git-tfs (found at https://github.com/git-tfs/git-tfs) is a .NET project, and (as
of this writing) it only runs on Windows. To work with Git repositories, it uses
the .NET bindings for libgit2, a library-oriented implementation of Git which is
highly performant and allows a lot of flexibility with the guts of a Git repository.
Libgit2 is not a complete implementation of Git, so to cover the difference gittfs will actually call the command-line Git client for some operations, so there
are no artificial limits on what it can do with Git repositories. Its support of
TFVC features is very mature, since it uses the Visual Studio assemblies for operations with servers. This does mean you’ll need access to those assemblies,
which means you need to install a recent version of Visual Studio (any edition
since version 2010, including Express since version 2012), or the Visual Studio
SDK.
Git-tf (whose home is at https://gittf.codeplex.com) is a Java project, and as
such runs on any computer with a Java runtime environment. It interfaces with
Git repositories through JGit (a JVM implementation of Git), which means it has
virtually no limitations in terms of Git functions. However, its support for TFVC
is limited as compared to git-tfs – it does not support branches, for instance.
So each tool has pros and cons, and there are plenty of situations that favor
one over the other. We’ll cover the basic usage of both of them in this book.
CHAPTER 9: Git and Other Systems
454You’ll need access to a TFVC-based repository to follow along with these
instructions. These aren’t as plentiful in the wild as Git or Subversion repositories, so you may need to create one of your own. Codeplex (https://
www.codeplex.com) or Visual Studio Online (http://www.visualstudio.com)
are both good choices for this.
GETTING STARTED: GIT-TF
The first thing you do, just as with any Git project, is clone. Here’s what that
looks like with git-tf:
$ git tf clone https://tfs.codeplex.com:443/tfs/TFS13 $/myproject/Main project_git
The first argument is the URL of a TFVC collection, the second is of the form
$/project/branch, and the third is the path to the local Git repository that is
to be created (this last one is optional). Git-tf can only work with one branch at
a time; if you want to make checkins on a different TFVC branch, you’ll have to
make a new clone from that branch.
This creates a fully functional Git repository:
$ cd project_git
$ git log --all --oneline --decorate
512e75a (HEAD, tag: TFS_C35190, origin_tfs/tfs, master) Checkin message
This is called a shallow clone, meaning that only the latest changeset has
been downloaded. TFVC isn’t designed for each client to have a full copy of the
history, so git-tf defaults to only getting the latest version, which is much faster.
If you have some time, it’s probably worth it to clone the entire project history, using the --deep option:
$ git tf clone https://tfs.codeplex.com:443/tfs/TFS13 $/myproject/Main \
project_git --deep
Username: domain\user
Password:
Connecting to TFS...
Cloning $/myproject into /tmp/project_git: 100%, done.
Cloned 4 changesets. Cloned last changeset 35190 as d44b17a
$ cd project_git
$ git log --all --oneline --decorate
d44b17a (HEAD, tag: TFS_C35190, origin_tfs/tfs, master) Goodbye
126aa7b (tag: TFS_C35189)
8f77431 (tag: TFS_C35178) FIRST
Git as a Client
4550745a25 (tag: TFS_C35177) Created team project folder $/tfvctest via the \
Team Project Creation Wizard
Notice the tags with names like TFS_C35189; this is a feature that helps you
know which Git commits are associated with TFVC changesets. This is a nice
way to represent it, since you can see with a simple log command which of your
commits is associated with a snapshot that also exists in TFVC. They aren’t necessary (and in fact you can turn them off with git config git-tf.tag
false) – git-tf keeps the real commit-changeset mappings in the .git/git-tf
file.
GETTING STARTED: GIT-TFS
Git-tfs cloning behaves a bit differently. Observe:
PS> git tfs clone --with-branches \
https://username.visualstudio.com/DefaultCollection \
$/project/Trunk project_git
Initialized empty Git repository in C:/Users/ben/project_git/.git/
C15 = b75da1aba1ffb359d00e85c52acb261e4586b0c9
C16 = c403405f4989d73a2c3c119e79021cb2104ce44a
Tfs branches found:
- $/tfvc-test/featureA
The name of the local branch will be : featureA
C17 = d202b53f67bde32171d5078968c644e562f1c439
C18 = 44cd729d8df868a8be20438fdeeefb961958b674
Notice the --with-branches flag. Git-tfs is capable of mapping TFVC
branches to Git branches, and this flag tells it to set up a local Git branch for
every TFVC branch. This is highly recommended if you’ve ever branched or
merged in TFS, but it won’t work with a server older than TFS 2010 – before that
release, “branches” were just folders, so git-tfs can’t tell them from regular folders.
Let’s take a look at the resulting Git repository:
PS> git log --oneline --graph --decorate --all
* 44cd729 (tfs/featureA, featureA) Goodbye
* d202b53 Branched from $/tfvc-test/Trunk
* c403405 (HEAD, tfs/default, master) Hello
* b75da1a New project
PS> git log -1
commit c403405f4989d73a2c3c119e79021cb2104ce44a
Author: Ben Straub <ben@straub.cc>
Date: Fri Aug 1 03:41:59 2014 +0000
CHAPTER 9: Git and Other Systems
456Hello
git-tfs-id: [https://username.visualstudio.com/DefaultCollection]$/myproject/Trunk;C16
There are two local branches, master and featureA, which represent the
initial starting point of the clone (Trunk in TFVC) and a child branch (featureA
in TFVC). You can also see that the tfs “remote” has a couple of refs too: default and featureA, which represent TFVC branches. Git-tfs maps the branch
you cloned from to tfs/default, and others get their own names.
Another thing to notice is the git-tfs-id: lines in the commit messages.
Instead of tags, git-tfs uses these markers to relate TFVC changesets to Git commits. This has the implication that your Git commits will have a different SHA-1
hash before and after they have been pushed to TFVC.
GIT-TF[S] WORKFLOW
Regardless of which tool you’re using, you should set a couple of Git configuration values to avoid running into issues.
$ git config set --local core.ignorecase=true
$ git config set --local core.autocrlf=false
The obvious next thing you’re going to want to do is work on the project.
TFVC and TFS have several features that may add complexity to your workflow:
1. Feature branches that aren’t represented in TFVC add a bit of complexity.
This has to do with the very different ways that TFVC and Git represent
branches.
2. Be aware that TFVC allows users to “checkout” files from the server, locking them so nobody else can edit them. This obviously won’t stop you
from editing them in your local repository, but it could get in the way
when it comes time to push your changes up to the TFVC server.
3. TFS has the concept of “gated” checkins, where a TFS build-test cycle has
to complete successfully before the checkin is allowed. This uses the
“shelve” function in TFVC, which we don’t cover in detail here. You can
fake this in a manual fashion with git-tf, and git-tfs provides the checkintool command which is gate-aware.
In the interest of brevity, what we’ll cover here is the happy path, which sidesteps or avoids most of these issues.
Git as a Client
457WORKFLOW: GIT-TF
Let’s say you’ve done some work, made a couple of Git commits on master,
and you’re ready to share your progress on the TFVC server. Here’s our Git
repository:
$ git log --oneline --graph --decorate --all
* 4178a82 (HEAD, master) update code
* 9df2ae3 update readme
* d44b17a (tag: TFS_C35190, origin_tfs/tfs) Goodbye
* 126aa7b (tag: TFS_C35189)
* 8f77431 (tag: TFS_C35178) FIRST
* 0745a25 (tag: TFS_C35177) Created team project folder $/tfvctest via the \
Team Project Creation Wizard
We want to take the snapshot that’s in the 4178a82 commit and push it up
to the TFVC server. First things first: let’s see if any of our teammates did anything since we last connected:
$ git tf fetch
Username: domain\user
Password:
Connecting to TFS...
Fetching $/myproject at latest changeset: 100%, done.
Downloaded changeset 35320 as commit 8ef06a8. Updated FETCH_HEAD.
$ git log --oneline --graph --decorate --all
* 8ef06a8 (tag: TFS_C35320, origin_tfs/tfs) just some text
| * 4178a82 (HEAD, master) update code
| * 9df2ae3 update readme
|/
* d44b17a (tag: TFS_C35190) Goodbye
* 126aa7b (tag: TFS_C35189)
* 8f77431 (tag: TFS_C35178) FIRST
* 0745a25 (tag: TFS_C35177) Created team project folder $/tfvctest via the \
Team Project Creation Wizard
Looks like someone else is working, too, and now we have divergent history.
This is where Git shines, but we have two choices of how to proceed:
1. Making a merge commit feels natural as a Git user (after all, that’s what
git pull does), and git-tf can do this for you with a simple git tf
pull. Be aware, however, that TFVC doesn’t think this way, and if you
push merge commits your history will start to look different on both
CHAPTER 9: Git and Other Systems
458sides, which can be confusing. However, if you plan on submitting all of
your changes as one changeset, this is probably the easiest choice.
2. Rebasing makes our commit history linear, which means we have the option of converting each of our Git commits into a TFVC changeset. Since
this leaves the most options open, we recommend you do it this way; gittf even makes it easy for you with git tf pull --rebase.
The choice is yours. For this example, we’ll be rebasing:
$ git rebase FETCH_HEAD
First, rewinding head to replay your work on top of it...
Applying: update readme
Applying: update code
$ git log --oneline --graph --decorate --all
* 5a0e25e (HEAD, master) update code
* 6eb3eb5 update readme
* 8ef06a8 (tag: TFS_C35320, origin_tfs/tfs) just some text
* d44b17a (tag: TFS_C35190) Goodbye
* 126aa7b (tag: TFS_C35189)
* 8f77431 (tag: TFS_C35178) FIRST
* 0745a25 (tag: TFS_C35177) Created team project folder $/tfvctest via the \
Team Project Creation Wizard
Now we’re ready to make a checkin to the TFVC server. Git-tf gives you the
choice of making a single changeset that represents all the changes since the
last one (--shallow, which is the default) and creating a new changeset for
each Git commit (--deep). For this example, we’ll just create one changeset:
$ git tf checkin -m 'Updating readme and code'
Username: domain\user
Password:
Connecting to TFS...
Checking in to $/myproject: 100%, done.
Checked commit 5a0e25e in as changeset 35348
$ git log --oneline --graph --decorate --all
* 5a0e25e (HEAD, tag: TFS_C35348, origin_tfs/tfs, master) update code
* 6eb3eb5 update readme
* 8ef06a8 (tag: TFS_C35320) just some text
* d44b17a (tag: TFS_C35190) Goodbye
* 126aa7b (tag: TFS_C35189)
* 8f77431 (tag: TFS_C35178) FIRST
* 0745a25 (tag: TFS_C35177) Created team project folder $/tfvctest via the \
Team Project Creation Wizard
Git as a Client
459There’s a new TFS_C35348 tag, indicating that TFVC is storing the exact
same snapshot as the 5a0e25e commit. It’s important to note that not every
Git commit needs to have an exact counterpart in TFVC; the 6eb3eb5 commit,
for example, doesn’t exist anywhere on the server.
That’s the main workflow. There are a couple of other considerations you’ll
want to keep in mind:
• There is no branching. Git-tf can only create Git repositories from one
TFVC branch at a time.
• Collaborate using either TFVC or Git, but not both. Different git-tf clones
of the same TFVC repository may have different commit SHA-1 hashes,
which will cause no end of headaches.
• If your team’s workflow includes collaborating in Git and syncing periodically with TFVC, only connect to TFVC with one of the Git repositories.
WORKFLOW: GIT-TFS
Let’s walk through the same scenario using git-tfs. Here are the new commits
we’ve made to the master branch in our Git repository:
PS> git log --oneline --graph --all --decorate
* c3bd3ae (HEAD, master) update code
* d85e5a2 update readme
| * 44cd729 (tfs/featureA, featureA) Goodbye
| * d202b53 Branched from $/tfvc-test/Trunk
|/
* c403405 (tfs/default) Hello
* b75da1a New project
Now let’s see if anyone else has done work while we were hacking away:
PS> git tfs fetch
C19 = aea74a0313de0a391940c999e51c5c15c381d91d
PS> git log --all --oneline --graph --decorate
* aea74a0 (tfs/default) update documentation
| * c3bd3ae (HEAD, master) update code
| * d85e5a2 update readme
|/
| * 44cd729 (tfs/featureA, featureA) Goodbye
| * d202b53 Branched from $/tfvc-test/Trunk
|/
* c403405 Hello
* b75da1a New project
CHAPTER 9: Git and Other Systems
460Yes, it turns out our coworker has added a new TFVC changeset, which
shows up as the new aea74a0 commit, and the tfs/default remote branch
has moved.
As with git-tf, we have two fundamental options for how to resolve this divergent history:
1. Rebase to preserve a linear history.
2. Merge to preserve what actually happened.
In this case, we’re going to do a “deep” checkin, where every Git commit becomes a TFVC changeset, so we want to rebase.
PS> git rebase tfs/default
First, rewinding head to replay your work on top of it...
Applying: update readme
Applying: update code
PS> git log --all --oneline --graph --decorate
* 10a75ac (HEAD, master) update code
* 5cec4ab update readme
* aea74a0 (tfs/default) update documentation
| * 44cd729 (tfs/featureA, featureA) Goodbye
| * d202b53 Branched from $/tfvc-test/Trunk
|/
* c403405 Hello
* b75da1a New project
Now we’re ready to complete our contribution by checking in our code to the
TFVC server. We’ll use the rcheckin command here to create a TFVC changeset
for each Git commit in the path from HEAD to the first tfs remote branch found
(the checkin command would only create one changeset, sort of like squashing Git commits).
PS> git tfs rcheckin
Working with tfs remote: default
Fetching changes from TFS to minimize possibility of late conflict...
Starting checkin of 5cec4ab4 'update readme'
add README.md
C20 = 71a5ddce274c19f8fdc322b4f165d93d89121017
Done with 5cec4ab4b213c354341f66c80cd650ab98dcf1ed, rebasing tail onto new TFS-commit...
Rebase done successfully.
Starting checkin of b1bf0f99 'update code'
edit .git\tfs\default\workspace\ConsoleApplication1/ConsoleApplication1/Program.cs
C21 = ff04e7c35dfbe6a8f94e782bf5e0031cee8d103b
Done with b1bf0f9977b2d48bad611ed4a03d3738df05ea5d, rebasing tail onto new TFS-commit...
Rebase done successfully.
No more to rcheckin.
PS> git log --all --oneline --graph --decorate
Git as a Client
461FIGURE 9-3
The git-tfs checkin
tool.
* ff04e7c (HEAD, tfs/default, master) update code
* 71a5ddc update readme
* aea74a0 update documentation
| * 44cd729 (tfs/featureA, featureA) Goodbye
| * d202b53 Branched from $/tfvc-test/Trunk
|/
* c403405 Hello
* b75da1a New project
Notice how after every successful checkin to the TFVC server, git-tfs is rebasing the remaining work onto what it just did. That’s because it’s adding the
git-tfs-id field to the bottom of the commit messages, which changes the
SHA-1 hashes. This is exactly as designed, and there’s nothing to worry about,
but you should be aware that it’s happening, especially if you’re sharing Git
commits with others.
TFS has many features that integrate with its version control system, such as
work items, designated reviewers, gated checkins, and so on. It can be cumbersome to work with these features using only a command-line tool, but fortunately git-tfs lets you launch a graphical checkin tool very easily:
PS> git tfs checkintool
PS> git tfs ct
It looks a bit like this:
CHAPTER 9: Git and Other Systems
462This will look familiar to TFS users, as it’s the same dialog that’s launched
from within Visual Studio.
Git-tfs also lets you control TFVC branches from your Git repository. As an example, let’s create one:
PS> git tfs branch $/tfvc-test/featureBee
The name of the local branch will be : featureBee
C26 = 1d54865c397608c004a2cadce7296f5edc22a7e5
PS> git log --oneline --graph --decorate --all
* 1d54865 (tfs/featureBee) Creation branch $/myproject/featureBee
* ff04e7c (HEAD, tfs/default, master) update code
* 71a5ddc update readme
* aea74a0 update documentation
| * 44cd729 (tfs/featureA, featureA) Goodbye
| * d202b53 Branched from $/tfvc-test/Trunk
|/
* c403405 Hello
* b75da1a New project
Creating a branch in TFVC means adding a changeset where that branch now
exists, and this is projected as a Git commit. Note also that git-tfs created the
tfs/featureBee remote branch, but HEAD is still pointing to master. If you
want to work on the newly-minted branch, you’ll want to base your new commits on the 1d54865 commit, perhaps by creating a topic branch from that
commit.
GIT AND TFS SUMMARY
Git-tf and Git-tfs are both great tools for interfacing with a TFVC server. They allow you to use the power of Git locally, avoid constantly having to round-trip to
the central TFVC server, and make your life as a developer much easier, without
forcing your entire team to migrate to Git. If you’re working on Windows (which
is likely if your team is using TFS), you’ll probably want to use git-tfs, since its
feature set is more complete, but if you’re working on another platform, you’ll
be using git-tf, which is more limited. As with most of the tools in this chapter,
you should choose one of these version-control systems to be canonical, and
use the other one in a subordinate fashion – either Git or TFVC should be the
center of collaboration, but not both.
Migrating to Git
If you have an existing codebase in another VCS but you’ve decided to start using Git, you must migrate your project one way or another. This section goes
Migrating to Git
463over some importers for common systems, and then demonstrates how to develop your own custom importer. You’ll learn how to import data from several
of the bigger professionally used SCM systems, because they make up the majority of users who are switching, and because high-quality tools for them are
easy to come by.
Subversion
If you read the previous section about using git svn, you can easily use those
instructions to git svn clone a repository; then, stop using the Subversion
server, push to a new Git server, and start using that. If you want the history,
you can accomplish that as quickly as you can pull the data out of the Subversion server (which may take a while).
However, the import isn’t perfect; and because it will take so long, you may
as well do it right. The first problem is the author information. In Subversion,
each person committing has a user on the system who is recorded in the commit information. The examples in the previous section show schacon in some
places, such as the blame output and the git svn log. If you want to map
this to better Git author data, you need a mapping from the Subversion users to
the Git authors. Create a file called users.txt that has this mapping in a format like this:
schacon = Scott Chacon <schacon@geemail.com>
selse = Someo Nelse <selse@geemail.com>
To get a list of the author names that SVN uses, you can run this:
$ svn log --xml | grep author | sort -u | \
perl -pe 's/.*>(.*?)<.*/$1 = /'
That generates the log output in XML format, then keeps only the lines with
author information, discards duplicates, strips out the XML tags. (Obviously this
only works on a machine with grep, sort, and perl installed.) Then, redirect
that output into your users.txt file so you can add the equivalent Git user data next to each entry.
You can provide this file to git svn to help it map the author data more accurately. You can also tell git svn not to include the metadata that Subversion
normally imports, by passing --no-metadata to the clone or init command
(though if you want to keep the synchronisation-metadata, feel free to omit this
parameter). This makes your import command look like this:
CHAPTER 9: Git and Other Systems
464$ git svn clone http://my-project.googlecode.com/svn/ \
--authors-file=users.txt --no-metadata -s my_project
Now you should have a nicer Subversion import in your my_project directory. Instead of commits that look like this
commit 37efa680e8473b615de980fa935944215428a35a
Author: schacon <schacon@4c93b258-373f-11de-be05-5f7a86268029>
Date: Sun May 3 00:12:22 2009 +0000
fixed install - go to trunk
git-svn-id: https://my-project.googlecode.com/svn/trunk@94 4c93b258-373f-11debe05-5f7a86268029
they look like this:
commit 03a8785f44c8ea5cdb0e8834b7c8e6c469be2ff2
Author: Scott Chacon <schacon@geemail.com>
Date: Sun May 3 00:12:22 2009 +0000
fixed install - go to trunk
Not only does the Author field look a lot better, but the git-svn-id is no
longer there, either.
You should also do a bit of post-import cleanup. For one thing, you should
clean up the weird references that git svn set up. First you’ll move the tags so
they’re actual tags rather than strange remote branches, and then you’ll move
the rest of the branches so they’re local.
To move the tags to be proper Git tags, run:
$ cp -Rf .git/refs/remotes/origin/tags/* .git/refs/tags/
$ rm -Rf .git/refs/remotes/origin/tags
This takes the references that were remote branches that started with remotes/origin/tags/ and makes them real (lightweight) tags.
Next, move the rest of the references under refs/remotes to be local
branches:
$ cp -Rf .git/refs/remotes/origin/* .git/refs/heads/
$ rm -Rf .git/refs/remotes/origin
Migrating to Git
465It may happen that you’ll see some extra branches which are suffixed by
@xxx (where xxx is a number), while in Subversion you only see one branch.
This is actually a Subversion feature called “peg-revisions”, which is something
that Git simply has no syntactical counterpart for. Hence, git svn simply adds
the svn version number to the branch name just in the same way as you would
have written it in svn to address the peg-revision of that branch. If you do not
care anymore about the peg-revisions, simply remove them using git branch
-d.
Now all the old branches are real Git branches and all the old tags are real
Git tags.
There’s one last thing to clean up. Unfortunately, git svn creates an extra
branch named trunk, which maps to Subversion’s default branch, but the
trunk ref points to the same place as master. Since master is more idiomatically Git, here’s how to remove the extra branch:
$ git branch -d trunk
The last thing to do is add your new Git server as a remote and push to it.
Here is an example of adding your server as a remote:
$ git remote add origin git@my-git-server:myrepository.git
Because you want all your branches and tags to go up, you can now run this:
$ git push origin --all
$ git push origin --tags
All your branches and tags should be on your new Git server in a nice, clean
import.
Mercurial
Since Mercurial and Git have fairly similar models for representing versions, and
since Git is a bit more flexible, converting a repository from Mercurial to Git is
fairly straightforward, using a tool called “hg-fast-export”, which you’ll need a
copy of:
$ git clone http://repo.or.cz/r/fast-export.git /tmp/fast-export
CHAPTER 9: Git and Other Systems
466The first step in the conversion is to get a full clone of the Mercurial repository you want to convert:
$ hg clone <remote repo URL> /tmp/hg-repo
The next step is to create an author mapping file. Mercurial is a bit more forgiving than Git for what it will put in the author field for changesets, so this is a
good time to clean house. Generating this is a one-line command in a bash
shell:
$ cd /tmp/hg-repo
$ hg log | grep user: | sort | uniq | sed 's/user: *//' > ../authors
This will take a few seconds, depending on how long your project’s history is,
and afterwards the /tmp/authors file will look something like this:
bob
bob@localhost
bob <bob@company.com>
bob jones <bob <AT> company <DOT> com>
Bob Jones <bob@company.com>
Joe Smith <joe@company.com>
In this example, the same person (Bob) has created changesets under four
different names, one of which actually looks correct, and one of which would
be completely invalid for a Git commit. Hg-fast-export lets us fix this by adding
={new name and email address} at the end of every line we want to
change, and removing the lines for any usernames that we want to leave alone.
If all the usernames look fine, we won’t need this file at all. In this example, we
want our file to look like this:
bob=Bob Jones <bob@company.com>
bob@localhost=Bob Jones <bob@company.com>
bob <bob@company.com>=Bob Jones <bob@company.com>
bob jones <bob <AT> company <DOT> com>=Bob Jones <bob@company.com>
The next step is to create our new Git repository, and run the export script:
$ git init /tmp/converted
$ cd /tmp/converted
$ /tmp/fast-export/hg-fast-export.sh -r /tmp/hg-repo -A /tmp/authors
Migrating to Git
467The -r flag tells hg-fast-export where to find the Mercurial repository we
want to convert, and the -A flag tells it where to find the author-mapping file.
The script parses Mercurial changesets and converts them into a script for Git’s
“fast-import” feature (which we’ll discuss in detail a bit later on). This takes a
bit (though it’s much faster than it would be over the network), and the output
is fairly verbose:
$ /tmp/fast-export/hg-fast-export.sh -r /tmp/hg-repo -A /tmp/authors
Loaded 4 authors
master: Exporting full revision 1/22208 with 13/0/0 added/changed/removed files
master: Exporting simple delta revision 2/22208 with 1/1/0 added/changed/removed f
master: Exporting simple delta revision 3/22208 with 0/1/0 added/changed/removed f
[…]
master: Exporting simple delta revision 22206/22208 with 0/4/0 added/changed/remov
master: Exporting simple delta revision 22207/22208 with 0/2/0 added/changed/remov
master: Exporting thorough delta revision 22208/22208 with 3/213/0 added/changed/r
Exporting tag [0.4c] at [hg r9] [git :10]
Exporting tag [0.4d] at [hg r16] [git :17]
[…]
Exporting tag [3.1-rc] at [hg r21926] [git :21927]
Exporting tag [3.1] at [hg r21973] [git :21974]
Issued 22315 commands
git-fast-import statistics:
---------------------------------------------------------------------
Alloc'd objects: 120000
Total objects: 115032 ( 208171 duplicates )
blobs : 40504 ( 205320 duplicates 26117 deltas of 39602
trees : 52320 ( 2851 duplicates 47467 deltas of 47599
commits: 22208 ( 0 duplicates 0 deltas of 0
tags : 0 ( 0 duplicates 0 deltas of 0
Total branches: 109 ( 2 loads )
marks: 1048576 ( 22208 unique )
atoms: 1952
Memory total: 7860 KiB
pools: 2235 KiB
objects: 5625 KiB
---------------------------------------------------------------------
pack_report: getpagesize() = 4096
pack_report: core.packedGitWindowSize = 1073741824
pack_report: core.packedGitLimit = 8589934592
pack_report: pack_used_ctr = 90430
pack_report: pack_mmap_calls = 46771
pack_report: pack_open_windows = 1 / 1
pack_report: pack_mapped = 340852700 / 340852700
---------------------------------------------------------------------
$ git shortlog -sn
CHAPTER 9: Git and Other Systems
468369 Bob Jones
365 Joe Smith
That’s pretty much all there is to it. All of the Mercurial tags have been converted to Git tags, and Mercurial branches and bookmarks have been converted
to Git branches. Now you’re ready to push the repository up to its new serverside home:
$ git remote add origin git@my-git-server:myrepository.git
$ git push origin --all
Perforce
The next system you’ll look at importing from is Perforce. As we discussed
above, there are two ways to let Git and Perforce talk to each other: git-p4 and
Perforce Git Fusion.
PERFORCE GIT FUSION
Git Fusion makes this process fairly painless. Just configure your project settings, user mappings, and branches using a configuration file (as discussed in
“Git Fusion”), and clone the repository. Git Fusion leaves you with what looks
like a native Git repository, which is then ready to push to a native Git host if
you desire. You could even use Perforce as your Git host if you like.
GIT-P4
Git-p4 can also act as an import tool. As an example, we’ll import the Jam
project from the Perforce Public Depot. To set up your client, you must export
the P4PORT environment variable to point to the Perforce depot:
$ export P4PORT=public.perforce.com:1666
In order to follow along, you’ll need a Perforce depot to connect with.
We’ll be using the public depot at public.perforce.com for our examples,
but you can use any depot you have access to.
Run the git p4 clone command to import the Jam project from the Perforce server, supplying the depot and project path and the path into which you
want to import the project:
Migrating to Git
469$ git-p4 clone //guest/perforce_software/jam@all p4import
Importing from //guest/perforce_software/jam@all into p4import
Initialized empty Git repository in /private/tmp/p4import/.git/
Import destination: refs/remotes/p4/master
Importing revision 9957 (100%)
This particular project has only one branch, but if you have branches that
are configured with branch views (or just a set of directories), you can use the
--detect-branches flag to git p4 clone to import all the project’s branches as well. See “Branching” for a bit more detail on this.
At this point you’re almost done. If you go to the p4import directory and
run git log, you can see your imported work:
$ git log -2
commit e5da1c909e5db3036475419f6379f2c73710c4e6
Author: giles <giles@giles@perforce.com>
Date: Wed Feb 8 03:13:27 2012 -0800
Correction to line 355; change </UL> to </OL>.
[git-p4: depot-paths = "//public/jam/src/": change = 8068]
commit aa21359a0a135dda85c50a7f7cf249e4f7b8fd98
Author: kwirth <kwirth@perforce.com>
Date: Tue Jul 7 01:35:51 2009 -0800
Fix spelling error on Jam doc page (cummulative -> cumulative).
[git-p4: depot-paths = "//public/jam/src/": change = 7304]
You can see that git-p4 has left an identifier in each commit message. It’s
fine to keep that identifier there, in case you need to reference the Perforce
change number later. However, if you’d like to remove the identifier, now is the
time to do so – before you start doing work on the new repository. You can use
git filter-branch to remove the identifier strings en masse:
$ git filter-branch --msg-filter 'sed -e "/^\[git-p4:/d"'
Rewrite e5da1c909e5db3036475419f6379f2c73710c4e6 (125/125)
Ref 'refs/heads/master' was rewritten
CHAPTER 9: Git and Other Systems
470If you run git log, you can see that all the SHA-1 checksums for the commits have changed, but the git-p4 strings are no longer in the commit messages:
$ git log -2
commit b17341801ed838d97f7800a54a6f9b95750839b7
Author: giles <giles@giles@perforce.com>
Date: Wed Feb 8 03:13:27 2012 -0800
Correction to line 355; change </UL> to </OL>.
commit 3e68c2e26cd89cb983eb52c024ecdfba1d6b3fff
Author: kwirth <kwirth@perforce.com>
Date: Tue Jul 7 01:35:51 2009 -0800
Fix spelling error on Jam doc page (cummulative -> cumulative).
Your import is ready to push up to your new Git server.
TFS
If your team is converting their source control from TFVC to Git, you’ll want the
highest-fidelity conversion you can get. This means that, while we covered both
git-tfs and git-tf for the interop section, we’ll only be covering git-tfs for this
part, because git-tfs supports branches, and this is prohibitively difficult using
git-tf.
This is a one-way conversion. The resulting Git repository won’t be able
to connect with the original TFVC project.
The first thing to do is map usernames. TFVC is fairly liberal with what goes
into the author field for changesets, but Git wants a human-readable name and
email address. You can get this information from the tf command-line client,
like so:
PS> tf history $/myproject -recursive > AUTHORS_TMP
This grabs all of the changesets in the history of the project and put it in the
AUTHORS_TMP file that we will process to extract the data of the User column
(the 2nd one). Open the file and find at which characters start and end the column and replace, in the following command-line, the parameters 11-20 of the
cut command with the ones found:
Migrating to Git
471PS> cat AUTHORS_TMP | cut -b 11-20 | tail -n+3 | sort | uniq > AUTHORS
The cut command keeps only the characters between 11 and 20 from each
line. The tail command skips the first two lines, which are field headers and
ASCII-art underlines. The result of all of this is piped to sort and uniq to eliminate duplicates, and saved to a file named AUTHORS. The next step is manual; in
order for git-tfs to make effective use of this file, each line must be in this format:
DOMAIN\username = User Name <email@address.com>
The portion on the left is the “User” field from TFVC, and the portion on the
right side of the equals sign is the user name that will be used for Git commits.
Once you have this file, the next thing to do is make a full clone of the TFVC
project you’re interested in:
PS> git tfs clone --with-branches --authors=AUTHORS https://username.visualstudio.co
Next you’ll want to clean the git-tfs-id sections from the bottom of the
commit messages. The following command will do that:
PS> git filter-branch -f --msg-filter 'sed "s/^git-tfs-id:.*$//g"' '--' --all
That uses the sed command from the Git-bash environment to replace any
line starting with “git-tfs-id:” with emptiness, which Git will then ignore.
Once that’s all done, you’re ready to add a new remote, push all your
branches up, and have your team start working from Git.
A Custom Importer
If your system isn’t one of the above, you should look for an importer online –
quality importers are available for many other systems, including CVS, Clear
Case, Visual Source Safe, even a directory of archives. If none of these tools
works for you, you have a more obscure tool, or you otherwise need a more
custom importing process, you should use git fast-import. This command
reads simple instructions from stdin to write specific Git data. It’s much easier
to create Git objects this way than to run the raw Git commands or try to write
the raw objects (see Chapter 10 for more information). This way, you can write
an import script that reads the necessary information out of the system you’re
importing from and prints straightforward instructions to stdout. You can then
run this program and pipe its output through git fast-import.
CHAPTER 9: Git and Other Systems
472To quickly demonstrate, you’ll write a simple importer. Suppose you work in
current, you back up your project by occasionally copying the directory into a
time-stamped back_YYYY_MM_DD backup directory, and you want to import
this into Git. Your directory structure looks like this:
$ ls /opt/import_from
back_2014_01_02
back_2014_01_04
back_2014_01_14
back_2014_02_03
current
In order to import a Git directory, you need to review how Git stores its data.
As you may remember, Git is fundamentally a linked list of commit objects that
point to a snapshot of content. All you have to do is tell fast-import what the
content snapshots are, what commit data points to them, and the order they go
in. Your strategy will be to go through the snapshots one at a time and create
commits with the contents of each directory, linking each commit back to the
previous one.
As we did in “An Example Git-Enforced Policy”, we’ll write this in Ruby, because it’s what we generally work with and it tends to be easy to read. You can
write this example pretty easily in anything you’re familiar with – it just needs
to print the appropriate information to stdout. And, if you are running on Windows, this means you’ll need to take special care to not introduce carriage returns at the end your lines – git fast-import is very particular about just wanting
line feeds (LF) not the carriage return line feeds (CRLF) that Windows uses.
To begin, you’ll change into the target directory and identify every subdirectory, each of which is a snapshot that you want to import as a commit. You’ll
change into each subdirectory and print the commands necessary to export it.
Your basic main loop looks like this:
last_mark = nil
# loop through the directories
Dir.chdir(ARGV[0]) do
Dir.glob("*").each do |dir|
next if File.file?(dir)
# move into the target directory
Dir.chdir(dir) do
last_mark = print_export(dir, last_mark)
end
end
end
Migrating to Git
473You run print_export inside each directory, which takes the manifest and
mark of the previous snapshot and returns the manifest and mark of this one;
that way, you can link them properly. “Mark” is the fast-import term for an
identifier you give to a commit; as you create commits, you give each one a
mark that you can use to link to it from other commits. So, the first thing to do
in your print_export method is generate a mark from the directory name:
mark = convert_dir_to_mark(dir)
You’ll do this by creating an array of directories and using the index value as
the mark, because a mark must be an integer. Your method looks like this:
$marks = []
def convert_dir_to_mark(dir)
if !$marks.include?(dir)
$marks << dir
end
($marks.index(dir) + 1).to_s
end
Now that you have an integer representation of your commit, you need a
date for the commit metadata. Because the date is expressed in the name of
the directory, you’ll parse it out. The next line in your print_export file is:
date = convert_dir_to_date(dir)
where convert_dir_to_date is defined as:
def convert_dir_to_date(dir)
if dir == 'current'
return Time.now().to_i
else
dir = dir.gsub('back_', '')
(year, month, day) = dir.split('_')
return Time.local(year, month, day).to_i
end
end
That returns an integer value for the date of each directory. The last piece of
meta-information you need for each commit is the committer data, which you
hardcode in a global variable:
$author = 'John Doe <john@example.com>'
CHAPTER 9: Git and Other Systems
474Now you’re ready to begin printing out the commit data for your importer.
The initial information states that you’re defining a commit object and what
branch it’s on, followed by the mark you’ve generated, the committer information and commit message, and then the previous commit, if any. The code
looks like this:
# print the import information
puts 'commit refs/heads/master'
puts 'mark :' + mark
puts "committer #{$author} #{date} -0700"
export_data('imported from ' + dir)
puts 'from :' + last_mark if last_mark
You hardcode the time zone (-0700) because doing so is easy. If you’re importing from another system, you must specify the time zone as an offset. The
commit message must be expressed in a special format:
data (size)\n(contents)
The format consists of the word data, the size of the data to be read, a newline, and finally the data. Because you need to use the same format to specify
the file contents later, you create a helper method, export_data:
def export_data(string)
print "data #{string.size}\n#{string}"
end
All that’s left is to specify the file contents for each snapshot. This is easy,
because you have each one in a directory – you can print out the deleteall
command followed by the contents of each file in the directory. Git will then record each snapshot appropriately:
puts 'deleteall'
Dir.glob("**/*").each do |file|
next if !File.file?(file)
inline_data(file)
end
Note: Because many systems think of their revisions as changes from one
commit to another, fast-import can also take commands with each commit to
specify which files have been added, removed, or modified and what the new
contents are. You could calculate the differences between snapshots and provide only this data, but doing so is more complex – you may as well give Git all
the data and let it figure it out. If this is better suited to your data, check the
Migrating to Git
475fast-import man page for details about how to provide your data in this manner.
The format for listing the new file contents or specifying a modified file with
the new contents is as follows:
M 644 inline path/to/file
data (size)
(file contents)
Here, 644 is the mode (if you have executable files, you need to detect and
specify 755 instead), and inline says you’ll list the contents immediately after
this line. Your inline_data method looks like this:
def inline_data(file, code = 'M', mode = '644')
content = File.read(file)
puts "#{code} #{mode} inline #{file}"
export_data(content)
end
You reuse the export_data method you defined earlier, because it’s the
same as the way you specified your commit message data.
The last thing you need to do is to return the current mark so it can be
passed to the next iteration:
return mark
If you are running on Windows you’ll need to make sure that you add one
extra step. As mentioned before, Windows uses CRLF for new line characters while git fast-import expects only LF. To get around this problem
and make git fast-import happy, you need to tell ruby to use LF instead
of CRLF:
$stdout.binmode
That’s it. Here’s the script in its entirety:
#!/usr/bin/env ruby
$stdout.binmode
$author = "John Doe <john@example.com>"
$marks = []
def convert_dir_to_mark(dir)
if !$marks.include?(dir)
$marks << dir
end
CHAPTER 9: Git and Other Systems
476($marks.index(dir)+1).to_s
end
def convert_dir_to_date(dir)
if dir == 'current'
return Time.now().to_i
else
dir = dir.gsub('back_', '')
(year, month, day) = dir.split('_')
return Time.local(year, month, day).to_i
end
end
def export_data(string)
print "data #{string.size}\n#{string}"
end
def inline_data(file, code='M', mode='644')
content = File.read(file)
puts "#{code} #{mode} inline #{file}"
export_data(content)
end
def print_export(dir, last_mark)
date = convert_dir_to_date(dir)
mark = convert_dir_to_mark(dir)
puts 'commit refs/heads/master'
puts "mark :#{mark}"
puts "committer #{$author} #{date} -0700"
export_data("imported from #{dir}")
puts "from :#{last_mark}" if last_mark
puts 'deleteall'
Dir.glob("**/*").each do |file|
next if !File.file?(file)
inline_data(file)
end
mark
end
# Loop through the directories
last_mark = nil
Dir.chdir(ARGV[0]) do
Dir.glob("*").each do |dir|
next if File.file?(dir)
# move into the target directory
Dir.chdir(dir) do
last_mark = print_export(dir, last_mark)
Migrating to Git
477end
end
end
If you run this script, you’ll get content that looks something like this:
$ ruby import.rb /opt/import_from
commit refs/heads/master
mark :1
committer John Doe <john@example.com> 1388649600 -0700
data 29
imported from back_2014_01_02deleteall
M 644 inline README.md
data 28
# Hello
This is my readme.
commit refs/heads/master
mark :2
committer John Doe <john@example.com> 1388822400 -0700
data 29
imported from back_2014_01_04from :1
deleteall
M 644 inline main.rb
data 34
#!/bin/env ruby
puts "Hey there"
M 644 inline README.md
(...)
To run the importer, pipe this output through git fast-import while in
the Git directory you want to import into. You can create a new directory and
then run git init in it for a starting point, and then run your script:
$ git init
Initialized empty Git repository in /opt/import_to/.git/
$ ruby import.rb /opt/import_from | git fast-import
git-fast-import statistics:
---------------------------------------------------------------------
Alloc'd objects: 5000
Total objects: 13 ( 6 duplicates )
blobs : 5 ( 4 duplicates 3 deltas of 5
trees : 4 ( 1 duplicates 0 deltas of 4
commits: 4 ( 1 duplicates 0 deltas of 0
tags : 0 ( 0 duplicates 0 deltas of 0
Total branches: 1 ( 1 loads )
CHAPTER 9: Git and Other Systems
478marks: 1024 ( 5 unique )
atoms: 2
Memory total: 2344 KiB
pools: 2110 KiB
objects: 234 KiB
---------------------------------------------------------------------
pack_report: getpagesize() = 4096
pack_report: core.packedGitWindowSize = 1073741824
pack_report: core.packedGitLimit = 8589934592
pack_report: pack_used_ctr = 10
pack_report: pack_mmap_calls = 5
pack_report: pack_open_windows = 2 / 2
pack_report: pack_mapped = 1457 / 1457
---------------------------------------------------------------------
As you can see, when it completes successfully, it gives you a bunch of statistics about what it accomplished. In this case, you imported 13 objects total for 4
commits into 1 branch. Now, you can run git log to see your new history:
$ git log -2
commit 3caa046d4aac682a55867132ccdfbe0d3fdee498
Author: John Doe <john@example.com>
Date: Tue Jul 29 19:39:04 2014 -0700
imported from current
commit 4afc2b945d0d3c8cd00556fbe2e8224569dc9def
Author: John Doe <john@example.com>
Date: Mon Feb 3 01:00:00 2014 -0700
imported from back_2014_02_03
There you go – a nice, clean Git repository. It’s important to note that nothing is checked out – you don’t have any files in your working directory at first.
To get them, you must reset your branch to where master is now:
$ ls
$ git reset --hard master
HEAD is now at 3caa046 imported from current
$ ls
README.md main.rb
You can do a lot more with the fast-import tool – handle different modes,
binary data, multiple branches and merging, tags, progress indicators, and
Migrating to Git
479more. A number of examples of more complex scenarios are available in the
contrib/fast-import directory of the Git source code.
Summary
You should feel comfortable using Git as a client for other version-control systems, or importing nearly any existing repository into Git without losing data. In
the next chapter, we’ll cover the raw internals of Git so you can craft every single byte, if need be.
CHAPTER 9: Git and Other Systems
480Git Internals
You may have skipped to this chapter from a previous chapter, or you may have
gotten here after reading the rest of the book – in either case, this is where we’ll
go over the inner workings and implementation of Git. We found that learning
this information was fundamentally important to understanding how useful
and powerful Git is, but others have argued to us that it can be confusing and
unnecessarily complex for beginners. Thus, we’ve made this discussion the last
chapter in the book so you could read it early or later in your learning process.
We leave it up to you to decide.
Now that you’re here, let’s get started. First, if it isn’t yet clear, Git is fundamentally a content-addressable filesystem with a VCS user interface written on
top of it. You’ll learn more about what this means in a bit.
In the early days of Git (mostly pre 1.5), the user interface was much more
complex because it emphasized this filesystem rather than a polished VCS. In
the last few years, the UI has been refined until it’s as clean and easy to use as
any system out there; but often, the stereotype lingers about the early Git UI
that was complex and difficult to learn.
The content-addressable filesystem layer is amazingly cool, so we’ll cover
that first in this chapter; then, you’ll learn about the transport mechanisms and
the repository maintenance tasks that you may eventually have to deal with.
Plumbing and Porcelain
This book covers how to use Git with 30 or so verbs such as checkout, branch,
remote, and so on. But because Git was initially a toolkit for a VCS rather than a
full user-friendly VCS, it has a bunch of verbs that do low-level work and were
designed to be chained together UNIX style or called from scripts. These commands are generally referred to as “plumbing” commands, and the more userfriendly commands are called “porcelain” commands.
The book’s first nine chapters deal almost exclusively with porcelain commands. But in this chapter, you’ll be dealing mostly with the lower-level plumb-
481
10ing commands, because they give you access to the inner workings of Git, and
help demonstrate how and why Git does what it does. Many of these commands aren’t meant to be used manually on the command line, but rather to
be used as building blocks for new tools and custom scripts.
When you run git init in a new or existing directory, Git creates the .git
directory, which is where almost everything that Git stores and manipulates is
located. If you want to back up or clone your repository, copying this single directory elsewhere gives you nearly everything you need. This entire chapter basically deals with the stuff in this directory. Here’s what it looks like:
$ ls -F1
HEAD
config*
description
hooks/
info/
objects/
refs/
You may see some other files in there, but this is a fresh git init repository – it’s what you see by default. The description file is only used by the GitWeb program, so don’t worry about it. The config file contains your projectspecific configuration options, and the info directory keeps a global exclude
file for ignored patterns that you don’t want to track in a .gitignore file. The
hooks directory contains your client- or server-side hook scripts, which are discussed in detail in “Git Hooks”.
This leaves four important entries: the HEAD and (yet to be created) index
files, and the objects and refs directories. These are the core parts of Git. The
objects directory stores all the content for your database, the refs directory
stores pointers into commit objects in that data (branches), the HEAD file points
to the branch you currently have checked out, and the index file is where Git
stores your staging area information. You’ll now look at each of these sections
in detail to see how Git operates.
Git Objects
Git is a content-addressable filesystem. Great. What does that mean? It means
that at the core of Git is a simple key-value data store. You can insert any kind of
content into it, and it will give you back a key that you can use to retrieve the
content again at any time. To demonstrate, you can use the plumbing command hash-object, which takes some data, stores it in your .git directory,
CHAPTER 10: Git Internals
482and gives you back the key the data is stored as. First, you initialize a new Git
repository and verify that there is nothing in the objects directory:
$ git init test
Initialized empty Git repository in /tmp/test/.git/
$ cd test
$ find .git/objects
.git/objects
.git/objects/info
.git/objects/pack
$ find .git/objects -type f
Git has initialized the objects directory and created pack and info subdirectories in it, but there are no regular files. Now, store some text in your Git database:
$ echo 'test content' | git hash-object -w --stdin
d670460b4b4aece5915caf5c68d12f560a9fe3e4
The -w tells hash-object to store the object; otherwise, the command simply tells you what the key would be. --stdin tells the command to read the
content from stdin; if you don’t specify this, hash-object expects a file path at
the end. The output from the command is a 40-character checksum hash. This
is the SHA-1 hash – a checksum of the content you’re storing plus a header,
which you’ll learn about in a bit. Now you can see how Git has stored your data:
$ find .git/objects -type f
.git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4
You can see a file in the objects directory. This is how Git stores the content
initially – as a single file per piece of content, named with the SHA-1 checksum
of the content and its header. The subdirectory is named with the first 2 characters of the SHA-1, and the filename is the remaining 38 characters.
You can pull the content back out of Git with the cat-file command. This
command is sort of a Swiss army knife for inspecting Git objects. Passing -p to
it instructs the cat-file command to figure out the type of content and display it nicely for you:
Git Objects
483$ git cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4
test content
Now, you can add content to Git and pull it back out again. You can also do
this with content in files. For example, you can do some simple version control
on a file. First, create a new file and save its contents in your database:
$ echo 'version 1' > test.txt
$ git hash-object -w test.txt
83baae61804e65cc73a7201a7252750c76066a30
Then, write some new content to the file, and save it again:
$ echo 'version 2' > test.txt
$ git hash-object -w test.txt
1f7a7a472abf3dd9643fd615f6da379c4acb3e3a
Your database contains the two new versions of the file as well as the first
content you stored there:
$ find .git/objects -type f
.git/objects/1f/7a7a472abf3dd9643fd615f6da379c4acb3e3a
.git/objects/83/baae61804e65cc73a7201a7252750c76066a30
.git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4
Now you can revert the file back to the first version
$ git cat-file -p 83baae61804e65cc73a7201a7252750c76066a30 > test.txt
$ cat test.txt
version 1
or the second version:
$ git cat-file -p 1f7a7a472abf3dd9643fd615f6da379c4acb3e3a > test.txt
$ cat test.txt
version 2
But remembering the SHA-1 key for each version of your file isn’t practical;
plus, you aren’t storing the filename in your system – just the content. This obCHAPTER 10: Git Internals
484ject type is called a blob. You can have Git tell you the object type of any object
in Git, given its SHA-1 key, with cat-file -t:
$ git cat-file -t 1f7a7a472abf3dd9643fd615f6da379c4acb3e3a
blob
Tree Objects
The next type we’ll look at is the tree, which solves the problem of storing the
filename and also allows you to store a group of files together. Git stores content in a manner similar to a UNIX filesystem, but a bit simplified. All the content is stored as tree and blob objects, with trees corresponding to UNIX directory entries and blobs corresponding more or less to inodes or file contents. A
single tree object contains one or more tree entries, each of which contains a
SHA-1 pointer to a blob or subtree with its associated mode, type, and filename. For example, the most recent tree in a project may look something like
this:
$ git cat-file -p master^{tree}
100644 blob a906cb2a4a904a152e80877d4088654daad0c859 README
100644 blob 8f94139338f9404f26296befa88755fc2598c289 Rakefile
040000 tree 99f1a6d12cb4b6f19c8655fca46c3ecf317074e0 lib
The master^{tree} syntax specifies the tree object that is pointed to by
the last commit on your master branch. Notice that the lib subdirectory isn’t
a blob but a pointer to another tree:
$ git cat-file -p 99f1a6d12cb4b6f19c8655fca46c3ecf317074e0
100644 blob 47c6340d6459e05787f644c2447d2595f5d3a54b simplegit.rb
Conceptually, the data that Git is storing is something like this:
Git Objects
485FIGURE 10-1
Simple version of the
Git data model.
You can fairly easily create your own tree. Git normally creates a tree by taking the state of your staging area or index and writing a series of tree objects
from it. So, to create a tree object, you first have to set up an index by staging
some files. To create an index with a single entry – the first version of your
test.txt file – you can use the plumbing command update-index. You use
this command to artificially add the earlier version of the test.txt file to a
new staging area. You must pass it the --add option because the file doesn’t
yet exist in your staging area (you don’t even have a staging area set up yet) and
--cacheinfo because the file you’re adding isn’t in your directory but is in
your database. Then, you specify the mode, SHA-1, and filename:
$ git update-index --add --cacheinfo 100644 \
83baae61804e65cc73a7201a7252750c76066a30 test.txt
In this case, you’re specifying a mode of 100644, which means it’s a normal
file. Other options are 100755, which means it’s an executable file; and 120000,
which specifies a symbolic link. The mode is taken from normal UNIX modes
but is much less flexible – these three modes are the only ones that are valid for
files (blobs) in Git (although other modes are used for directories and submodules).
CHAPTER 10: Git Internals
486Now, you can use the write-tree command to write the staging area out to
a tree object. No -w option is needed – calling write-tree automatically creates a tree object from the state of the index if that tree doesn’t yet exist:
$ git write-tree
d8329fc1cc938780ffdd9f94e0d364e0ea74f579
$ git cat-file -p d8329fc1cc938780ffdd9f94e0d364e0ea74f579
100644 blob 83baae61804e65cc73a7201a7252750c76066a30 test.txt
You can also verify that this is a tree object:
$ git cat-file -t d8329fc1cc938780ffdd9f94e0d364e0ea74f579
tree
You’ll now create a new tree with the second version of test.txt and a new
file as well:
$ echo 'new file' > new.txt
$ git update-index test.txt
$ git update-index --add new.txt
Your staging area now has the new version of test.txt as well as the new
file new.txt. Write out that tree (recording the state of the staging area or index to a tree object) and see what it looks like:
$ git write-tree
0155eb4229851634a0f03eb265b69f5a2d56f341
$ git cat-file -p 0155eb4229851634a0f03eb265b69f5a2d56f341
100644 blob fa49b077972391ad58037050f2a75f74e3671e92 new.txt
100644 blob 1f7a7a472abf3dd9643fd615f6da379c4acb3e3a test.txt
Notice that this tree has both file entries and also that the test.txt SHA-1
is the “version 2” SHA-1 from earlier (1f7a7a). Just for fun, you’ll add the first
tree as a subdirectory into this one. You can read trees into your staging area by
calling read-tree. In this case, you can read an existing tree into your staging
area as a subtree by using the --prefix option to read-tree:
$ git read-tree --prefix=bak d8329fc1cc938780ffdd9f94e0d364e0ea74f579
$ git write-tree
3c4e9cd789d88d8d89c1073707c3585e41b0e614
Git Objects
487FIGURE 10-2
The content
structure of your
current Git data.
$ git cat-file -p 3c4e9cd789d88d8d89c1073707c3585e41b0e614
040000 tree d8329fc1cc938780ffdd9f94e0d364e0ea74f579 bak
100644 blob fa49b077972391ad58037050f2a75f74e3671e92 new.txt
100644 blob 1f7a7a472abf3dd9643fd615f6da379c4acb3e3a test.txt
If you created a working directory from the new tree you just wrote, you
would get the two files in the top level of the working directory and a subdirectory named bak that contained the first version of the test.txt file. You can
think of the data that Git contains for these structures as being like this:
Commit Objects
You have three trees that specify the different snapshots of your project that
you want to track, but the earlier problem remains: you must remember all
three SHA-1 values in order to recall the snapshots. You also don’t have any information about who saved the snapshots, when they were saved, or why they
were saved. This is the basic information that the commit object stores for you.
To create a commit object, you call commit-tree and specify a single tree
SHA-1 and which commit objects, if any, directly preceded it. Start with the first
tree you wrote:
CHAPTER 10: Git Internals
488$ echo 'first commit' | git commit-tree d8329f
fdf4fc3344e67ab068f836878b6c4951e3b15f3d
You will get a different hash value because of different creation time and author data. Replace commit and tag hashes with your own checksums further in
this chapter. Now you can look at your new commit object with cat-file:
$ git cat-file -p fdf4fc3
tree d8329fc1cc938780ffdd9f94e0d364e0ea74f579
author Scott Chacon <schacon@gmail.com> 1243040974 -0700
committer Scott Chacon <schacon@gmail.com> 1243040974 -0700
first commit
The format for a commit object is simple: it specifies the top-level tree for
the snapshot of the project at that point; the author/committer information
(which uses your user.name and user.email configuration settings and a
timestamp); a blank line, and then the commit message.
Next, you’ll write the other two commit objects, each referencing the commit that came directly before it:
$ echo 'second commit' | git commit-tree 0155eb -p fdf4fc3
cac0cab538b970a37ea1e769cbbde608743bc96d
$ echo 'third commit' | git commit-tree 3c4e9c -p cac0cab
1a410efbd13591db07496601ebc7a059dd55cfe9
Each of the three commit objects points to one of the three snapshot trees
you created. Oddly enough, you have a real Git history now that you can view
with the git log command, if you run it on the last commit SHA-1:
$ git log --stat 1a410e
commit 1a410efbd13591db07496601ebc7a059dd55cfe9
Author: Scott Chacon <schacon@gmail.com>
Date: Fri May 22 18:15:24 2009 -0700
third commit
bak/test.txt | 1 +
1 file changed, 1 insertion(+)
commit cac0cab538b970a37ea1e769cbbde608743bc96d
Author: Scott Chacon <schacon@gmail.com>
Git Objects
489Date: Fri May 22 18:14:29 2009 -0700
second commit
new.txt | 1 +
test.txt | 2 +-
2 files changed, 2 insertions(+), 1 deletion(-)
commit fdf4fc3344e67ab068f836878b6c4951e3b15f3d
Author: Scott Chacon <schacon@gmail.com>
Date: Fri May 22 18:09:34 2009 -0700
first commit
test.txt | 1 +
1 file changed, 1 insertion(+)
Amazing. You’ve just done the low-level operations to build up a Git history
without using any of the front end commands. This is essentially what Git does
when you run the git add and git commit commands – it stores blobs for the
files that have changed, updates the index, writes out trees, and writes commit
objects that reference the top-level trees and the commits that came immediately before them. These three main Git objects – the blob, the tree, and the
commit – are initially stored as separate files in your .git/objects directory.
Here are all the objects in the example directory now, commented with what
they store:
$ find .git/objects -type f
.git/objects/01/55eb4229851634a0f03eb265b69f5a2d56f341 # tree 2
.git/objects/1a/410efbd13591db07496601ebc7a059dd55cfe9 # commit 3
.git/objects/1f/7a7a472abf3dd9643fd615f6da379c4acb3e3a # test.txt v2
.git/objects/3c/4e9cd789d88d8d89c1073707c3585e41b0e614 # tree 3
.git/objects/83/baae61804e65cc73a7201a7252750c76066a30 # test.txt v1
.git/objects/ca/c0cab538b970a37ea1e769cbbde608743bc96d # commit 2
.git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4 # 'test content'
.git/objects/d8/329fc1cc938780ffdd9f94e0d364e0ea74f579 # tree 1
.git/objects/fa/49b077972391ad58037050f2a75f74e3671e92 # new.txt
.git/objects/fd/f4fc3344e67ab068f836878b6c4951e3b15f3d # commit 1
If you follow all the internal pointers, you get an object graph something like
this:
CHAPTER 10: Git Internals
490FIGURE 10-3
All the objects in
your Git directory.
Object Storage
We mentioned earlier that a header is stored with the content. Let’s take a minute to look at how Git stores its objects. You’ll see how to store a blob object –
in this case, the string “what is up, doc?” – interactively in the Ruby scripting
language.
You can start up interactive Ruby mode with the irb command:
$ irb
>> content = "what is up, doc?"
=> "what is up, doc?"
Git constructs a header that starts with the type of the object, in this case a
blob. Then, it adds a space followed by the size of the content and finally a null
byte:
>> header = "blob #{content.length}\0"
=> "blob 16\u0000"
Git Objects
491Git concatenates the header and the original content and then calculates
the SHA-1 checksum of that new content. You can calculate the SHA-1 value of a
string in Ruby by including the SHA1 digest library with the require command
and then calling Digest::SHA1.hexdigest() with the string:
>> store = header + content
=> "blob 16\u0000what is up, doc?"
>> require 'digest/sha1'
=> true
>> sha1 = Digest::SHA1.hexdigest(store)
=> "bd9dbf5aae1a3862dd1526723246b20206e5fc37"
Git compresses the new content with zlib, which you can do in Ruby with the
zlib library. First, you need to require the library and then run Zlib::Deflate.deflate() on the content:
>> require 'zlib'
=> true
>> zlib_content = Zlib::Deflate.deflate(store)
=> "x\x9CK\xCA\xC9OR04c(\xCFH,Q\xC8,V(-\xD0QH\xC9O\xB6\a\x00_\x1C\a\x9D"
Finally, you’ll write your zlib-deflated content to an object on disk. You’ll determine the path of the object you want to write out (the first two characters of
the SHA-1 value being the subdirectory name, and the last 38 characters being
the filename within that directory). In Ruby, you can use the FileUtils.mkdir_p() function to create the subdirectory if it doesn’t exist. Then,
open the file with File.open() and write out the previously zlib-compressed
content to the file with a write() call on the resulting file handle:
>> path = '.git/objects/' + sha1[0,2] + '/' + sha1[2,38]
=> ".git/objects/bd/9dbf5aae1a3862dd1526723246b20206e5fc37"
>> require 'fileutils'
=> true
>> FileUtils.mkdir_p(File.dirname(path))
=> ".git/objects/bd"
>> File.open(path, 'w') { |f| f.write zlib_content }
=> 32
That’s it – you’ve created a valid Git blob object. All Git objects are stored the
same way, just with different types – instead of the string blob, the header will
CHAPTER 10: Git Internals
492begin with commit or tree. Also, although the blob content can be nearly anything, the commit and tree content are very specifically formatted.
Git References
You can run something like git log 1a410e to look through your whole history, but you still have to remember that 1a410e is the last commit in order to
walk that history to find all those objects. You need a file in which you can store
the SHA-1 value under a simple name so you can use that pointer rather than
the raw SHA-1 value.
In Git, these are called “references” or “refs”; you can find the files that contain the SHA-1 values in the .git/refs directory. In the current project, this
directory contains no files, but it does contain a simple structure:
$ find .git/refs
.git/refs
.git/refs/heads
.git/refs/tags
$ find .git/refs -type f
To create a new reference that will help you remember where your latest
commit is, you can technically do something as simple as this:
$ echo "1a410efbd13591db07496601ebc7a059dd55cfe9" > .git/refs/heads/master
Now, you can use the head reference you just created instead of the SHA-1
value in your Git commands:
$ git log --pretty=oneline master
1a410efbd13591db07496601ebc7a059dd55cfe9 third commit
cac0cab538b970a37ea1e769cbbde608743bc96d second commit
fdf4fc3344e67ab068f836878b6c4951e3b15f3d first commit
You aren’t encouraged to directly edit the reference files. Git provides a safer
command to do this if you want to update a reference called update-ref:
$ git update-ref refs/heads/master 1a410efbd13591db07496601ebc7a059dd55cfe9
Git References
493FIGURE 10-4
Git directory objects
with branch head
references included.
That’s basically what a branch in Git is: a simple pointer or reference to the
head of a line of work. To create a branch back at the second commit, you can
do this:
$ git update-ref refs/heads/test cac0ca
Your branch will contain only work from that commit down:
$ git log --pretty=oneline test
cac0cab538b970a37ea1e769cbbde608743bc96d second commit
fdf4fc3344e67ab068f836878b6c4951e3b15f3d first commit
Now, your Git database conceptually looks something like this:
When you run commands like git branch (branchname), Git basically
runs that update-ref command to add the SHA-1 of the last commit of the
branch you’re on into whatever new reference you want to create.
The HEAD
The question now is, when you run git branch (branchname), how does Git
know the SHA-1 of the last commit? The answer is the HEAD file.
The HEAD file is a symbolic reference to the branch you’re currently on. By
symbolic reference, we mean that unlike a normal reference, it doesn’t generalCHAPTER 10: Git Internals
494ly contain a SHA-1 value but rather a pointer to another reference. If you look at
the file, you’ll normally see something like this:
$ cat .git/HEAD
ref: refs/heads/master
If you run git checkout test, Git updates the file to look like this:
$ cat .git/HEAD
ref: refs/heads/test
When you run git commit, it creates the commit object, specifying the parent of that commit object to be whatever SHA-1 value the reference in HEAD
points to.
You can also manually edit this file, but again a safer command exists to do
so: symbolic-ref. You can read the value of your HEAD via this command:
$ git symbolic-ref HEAD
refs/heads/master
You can also set the value of HEAD:
$ git symbolic-ref HEAD refs/heads/test
$ cat .git/HEAD
ref: refs/heads/test
You can’t set a symbolic reference outside of the refs style:
$ git symbolic-ref HEAD test
fatal: Refusing to point HEAD outside of refs/
Tags
We just finished discussing Git’s three main object types, but there is a fourth.
The tag object is very much like a commit object – it contains a tagger, a date, a
message, and a pointer. The main difference is that a tag object generally
points to a commit rather than a tree. It’s like a branch reference, but it never
moves – it always points to the same commit but gives it a friendlier name.
Git References
495As discussed in Chapter 2, there are two types of tags: annotated and lightweight. You can make a lightweight tag by running something like this:
$ git update-ref refs/tags/v1.0 cac0cab538b970a37ea1e769cbbde608743bc96d
That is all a lightweight tag is – a reference that never moves. An annotated
tag is more complex, however. If you create an annotated tag, Git creates a tag
object and then writes a reference to point to it rather than directly to the commit. You can see this by creating an annotated tag (-a specifies that it’s an annotated tag):
$ git tag -a v1.1 1a410efbd13591db07496601ebc7a059dd55cfe9 -m 'test tag'
Here’s the object SHA-1 value it created:
$ cat .git/refs/tags/v1.1
9585191f37f7b0fb9444f35a9bf50de191beadc2
Now, run the cat-file command on that SHA-1 value:
$ git cat-file -p 9585191f37f7b0fb9444f35a9bf50de191beadc2
object 1a410efbd13591db07496601ebc7a059dd55cfe9
type commit
tag v1.1
tagger Scott Chacon <schacon@gmail.com> Sat May 23 16:48:58 2009 -0700
test tag
Notice that the object entry points to the commit SHA-1 value that you tagged. Also notice that it doesn’t need to point to a commit; you can tag any Git
object. In the Git source code, for example, the maintainer has added their GPG
public key as a blob object and then tagged it. You can view the public key by
running this in a clone of the Git repository:
$ git cat-file blob junio-gpg-pub
The Linux kernel repository also has a non-commit-pointing tag object – the
first tag created points to the initial tree of the import of the source code.
CHAPTER 10: Git Internals
496Remotes
The third type of reference that you’ll see is a remote reference. If you add a
remote and push to it, Git stores the value you last pushed to that remote for
each branch in the refs/remotes directory. For instance, you can add a remote called origin and push your master branch to it:
$ git remote add origin git@github.com:schacon/simplegit-progit.git
$ git push origin master
Counting objects: 11, done.
Compressing objects: 100% (5/5), done.
Writing objects: 100% (7/7), 716 bytes, done.
Total 7 (delta 2), reused 4 (delta 1)
To git@github.com:schacon/simplegit-progit.git
a11bef0..ca82a6d master -> master
Then, you can see what the master branch on the origin remote was the
last time you communicated with the server, by checking the refs/remotes/
origin/master file:
$ cat .git/refs/remotes/origin/master
ca82a6dff817ec66f44342007202690a93763949
Remote references differ from branches (refs/heads references) mainly in
that they’re considered read-only. You can git checkout to one, but Git won’t
point HEAD at one, so you’ll never update it with a commit command. Git manages them as bookmarks to the last known state of where those branches were
on those servers.
Packfiles
Let’s go back to the objects database for your test Git repository. At this point,
you have 11 objects – 4 blobs, 3 trees, 3 commits, and 1 tag:
$ find .git/objects -type f
.git/objects/01/55eb4229851634a0f03eb265b69f5a2d56f341 # tree 2
.git/objects/1a/410efbd13591db07496601ebc7a059dd55cfe9 # commit 3
.git/objects/1f/7a7a472abf3dd9643fd615f6da379c4acb3e3a # test.txt v2
.git/objects/3c/4e9cd789d88d8d89c1073707c3585e41b0e614 # tree 3
.git/objects/83/baae61804e65cc73a7201a7252750c76066a30 # test.txt v1
.git/objects/95/85191f37f7b0fb9444f35a9bf50de191beadc2 # tag
Packfiles
497.git/objects/ca/c0cab538b970a37ea1e769cbbde608743bc96d # commit 2
.git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4 # 'test content'
.git/objects/d8/329fc1cc938780ffdd9f94e0d364e0ea74f579 # tree 1
.git/objects/fa/49b077972391ad58037050f2a75f74e3671e92 # new.txt
.git/objects/fd/f4fc3344e67ab068f836878b6c4951e3b15f3d # commit 1
Git compresses the contents of these files with zlib, and you’re not storing
much, so all these files collectively take up only 925 bytes. You’ll add some larger content to the repository to demonstrate an interesting feature of Git. To
demonstrate, we’ll add the repo.rb file from the Grit library – this is about a
22K source code file:
$ curl https://raw.githubusercontent.com/mojombo/grit/master/lib/grit/repo.rb > re
$ git checkout master
$ git add repo.rb
$ git commit -m 'added repo.rb'
[master 484a592] added repo.rb
3 files changed, 709 insertions(+), 2 deletions(-)
delete mode 100644 bak/test.txt
create mode 100644 repo.rb
rewrite test.txt (100%)
If you look at the resulting tree, you can see the SHA-1 value your repo.rb file
got for the blob object:
$ git cat-file -p master^{tree}
100644 blob fa49b077972391ad58037050f2a75f74e3671e92 new.txt
100644 blob 033b4468fa6b2a9547a70d88d1bbe8bf3f9ed0d5 repo.rb
100644 blob e3f094f522629ae358806b17daf78246c27c007b test.txt
You can then use git cat-file to see how big that object is:
$ git cat-file -s 033b4468fa6b2a9547a70d88d1bbe8bf3f9ed0d5
22044
Now, modify that file a little, and see what happens:
$ echo '# testing' >> repo.rb
$ git commit -am 'modified repo a bit'
[master 2431da6] modified repo.rb a bit
1 file changed, 1 insertion(+)
CHAPTER 10: Git Internals
498Check the tree created by that commit, and you see something interesting:
$ git cat-file -p master^{tree}
100644 blob fa49b077972391ad58037050f2a75f74e3671e92 new.txt
100644 blob b042a60ef7dff760008df33cee372b945b6e884e repo.rb
100644 blob e3f094f522629ae358806b17daf78246c27c007b test.txt
The blob is now a different blob, which means that although you added only
a single line to the end of a 400-line file, Git stored that new content as a completely new object:
$ git cat-file -s b042a60ef7dff760008df33cee372b945b6e884e
22054
You have two nearly identical 22K objects on your disk (each compressed to
approximately 7K). Wouldn’t it be nice if Git could store one of them in full but
then the second object only as the delta between it and the first?
It turns out that it can. The initial format in which Git saves objects on disk is
called a “loose” object format. However, occasionally Git packs up several of
these objects into a single binary file called a “packfile” in order to save space
and be more efficient. Git does this if you have too many loose objects around,
if you run the git gc command manually, or if you push to a remote server. To
see what happens, you can manually ask Git to pack up the objects by calling
the git gc command:
$ git gc
Counting objects: 18, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (14/14), done.
Writing objects: 100% (18/18), done.
Total 18 (delta 3), reused 0 (delta 0)
If you look in your objects directory, you’ll find that most of your objects are
gone, and a new pair of files has appeared:
$ find .git/objects -type f
.git/objects/bd/9dbf5aae1a3862dd1526723246b20206e5fc37
.git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4
.git/objects/info/packs
.git/objects/pack/pack-978e03944f5c581011e6998cd0e9e30000905586.idx
.git/objects/pack/pack-978e03944f5c581011e6998cd0e9e30000905586.pack
Packfiles
499The objects that remain are the blobs that aren’t pointed to by any commit –
in this case, the “what is up, doc?” example and the “test content” example
blobs you created earlier. Because you never added them to any commits,
they’re considered dangling and aren’t packed up in your new packfile.
The other files are your new packfile and an index. The packfile is a single file
containing the contents of all the objects that were removed from your filesystem. The index is a file that contains offsets into that packfile so you can quickly
seek to a specific object. What is cool is that although the objects on disk before
you ran the gc were collectively about 15K in size, the new packfile is only 7K.
You’ve cut your disk usage by half by packing your objects.
How does Git do this? When Git packs objects, it looks for files that are
named and sized similarly, and stores just the deltas from one version of the file
to the next. You can look into the packfile and see what Git did to save space.
The git verify-pack plumbing command allows you to see what was
packed up:
$ git verify-pack -v .git/objects/pack/pack-978e03944f5c581011e6998cd0e9e300009055
2431da676938450a4d72e260db3bf7b0f587bbc1 commit 223 155 12
69bcdaff5328278ab1c0812ce0e07fa7d26a96d7 commit 214 152 167
80d02664cb23ed55b226516648c7ad5d0a3deb90 commit 214 145 319
43168a18b7613d1281e5560855a83eb8fde3d687 commit 213 146 464
092917823486a802e94d727c820a9024e14a1fc2 commit 214 146 610
702470739ce72005e2edff522fde85d52a65df9b commit 165 118 756
d368d0ac0678cbe6cce505be58126d3526706e54 tag 130 122 874
fe879577cb8cffcdf25441725141e310dd7d239b tree 136 136 996
d8329fc1cc938780ffdd9f94e0d364e0ea74f579 tree 36 46 1132
deef2e1b793907545e50a2ea2ddb5ba6c58c4506 tree 136 136 1178
d982c7cb2c2a972ee391a85da481fc1f9127a01d tree 6 17 1314 1 \
deef2e1b793907545e50a2ea2ddb5ba6c58c4506
3c4e9cd789d88d8d89c1073707c3585e41b0e614 tree 8 19 1331 1 \
deef2e1b793907545e50a2ea2ddb5ba6c58c4506
0155eb4229851634a0f03eb265b69f5a2d56f341 tree 71 76 1350
83baae61804e65cc73a7201a7252750c76066a30 blob 10 19 1426
fa49b077972391ad58037050f2a75f74e3671e92 blob 9 18 1445
b042a60ef7dff760008df33cee372b945b6e884e blob 22054 5799 1463
033b4468fa6b2a9547a70d88d1bbe8bf3f9ed0d5 blob 9 20 7262 1 \
b042a60ef7dff760008df33cee372b945b6e884e
1f7a7a472abf3dd9643fd615f6da379c4acb3e3a blob 10 19 7282
non delta: 15 objects
chain length = 1: 3 objects
.git/objects/pack/pack-978e03944f5c581011e6998cd0e9e30000905586.pack: ok
Here, the 033b4 blob, which if you remember was the first version of your
repo.rb file, is referencing the b042a blob, which was the second version of the
file. The third column in the output is the size of the object in the pack, so you
CHAPTER 10: Git Internals
500can see that b042a takes up 22K of the file, but that 033b4 only takes up 9
bytes. What is also interesting is that the second version of the file is the one
that is stored intact, whereas the original version is stored as a delta – this is
because you’re most likely to need faster access to the most recent version of
the file.
The really nice thing about this is that it can be repacked at any time. Git will
occasionally repack your database automatically, always trying to save more
space, but you can also manually repack at any time by running git gc by
hand.
The Refspec
Throughout this book, we’ve used simple mappings from remote branches to
local references, but they can be more complex. Suppose you add a remote like
this:
$ git remote add origin https://github.com/schacon/simplegit-progit
It adds a section to your .git/config file, specifying the name of the remote (origin), the URL of the remote repository, and the refspec for fetching:
[remote "origin"]
url = https://github.com/schacon/simplegit-progit
fetch = +refs/heads/*:refs/remotes/origin/*
The format of the refspec is an optional +, followed by <src>:<dst>, where
<src> is the pattern for references on the remote side and <dst> is where
those references will be written locally. The + tells Git to update the reference
even if it isn’t a fast-forward.
In the default case that is automatically written by a git remote add command, Git fetches all the references under refs/heads/ on the server and
writes them to refs/remotes/origin/ locally. So, if there is a master branch
on the server, you can access the log of that branch locally via
$ git log origin/master
$ git log remotes/origin/master
$ git log refs/remotes/origin/master
They’re all equivalent, because Git expands each of them to refs/
remotes/origin/master.
The Refspec
501If you want Git instead to pull down only the master branch each time, and
not every other branch on the remote server, you can change the fetch line to
fetch = +refs/heads/master:refs/remotes/origin/master
This is just the default refspec for git fetch for that remote. If you want to
do something one time, you can specify the refspec on the command line, too.
To pull the master branch on the remote down to origin/mymaster locally,
you can run
$ git fetch origin master:refs/remotes/origin/mymaster
You can also specify multiple refspecs. On the command line, you can pull
down several branches like so:
$ git fetch origin master:refs/remotes/origin/mymaster \
topic:refs/remotes/origin/topic
From git@github.com:schacon/simplegit
! [rejected] master -> origin/mymaster (non fast forward)
* [new branch] topic -> origin/topic
In this case, the master branch pull was rejected because it wasn’t a fastforward reference. You can override that by specifying the + in front of the refspec.
You can also specify multiple refspecs for fetching in your configuration file.
If you want to always fetch the master and experiment branches, add two
lines:
[remote "origin"]
url = https://github.com/schacon/simplegit-progit
fetch = +refs/heads/master:refs/remotes/origin/master
fetch = +refs/heads/experiment:refs/remotes/origin/experiment
You can’t use partial globs in the pattern, so this would be invalid:
fetch = +refs/heads/qa*:refs/remotes/origin/qa*
However, you can use namespaces (or directories) to accomplish something
like that. If you have a QA team that pushes a series of branches, and you want
to get the master branch and any of the QA team’s branches but nothing else,
you can use a config section like this:
CHAPTER 10: Git Internals
502[remote "origin"]
url = https://github.com/schacon/simplegit-progit
fetch = +refs/heads/master:refs/remotes/origin/master
fetch = +refs/heads/qa/*:refs/remotes/origin/qa/*
If you have a complex workflow process that has a QA team pushing branches, developers pushing branches, and integration teams pushing and collaborating on remote branches, you can namespace them easily this way.
Pushing Refspecs
It’s nice that you can fetch namespaced references that way, but how does the
QA team get their branches into a qa/ namespace in the first place? You accomplish that by using refspecs to push.
If the QA team wants to push their master branch to qa/master on the remote server, they can run
$ git push origin master:refs/heads/qa/master
If they want Git to do that automatically each time they run git push origin, they can add a push value to their config file:
[remote "origin"]
url = https://github.com/schacon/simplegit-progit
fetch = +refs/heads/*:refs/remotes/origin/*
push = refs/heads/master:refs/heads/qa/master
Again, this will cause a git push origin to push the local master branch
to the remote qa/master branch by default.
Deleting References
You can also use the refspec to delete references from the remote server by running something like this:
$ git push origin :topic
Because the refspec is <src>:<dst>, by leaving off the <src> part, this basically says to make the topic branch on the remote nothing, which deletes it.
The Refspec
503Transfer Protocols
Git can transfer data between two repositories in two major ways: the “dumb”
protocol and the “smart” protocol. This section will quickly cover how these
two main protocols operate.
The Dumb Protocol
If you’re setting up a repository to be served read-only over HTTP, the dumb
protocol is likely what will be used. This protocol is called “dumb” because it
requires no Git-specific code on the server side during the transport process;
the fetch process is a series of HTTP GET requests, where the client can assume
the layout of the Git repository on the server.
The dumb protocol is fairly rarely used these days. It’s difficult to secure
or make private, so most Git hosts (both cloud-based and on-premises)
will refuse to use it. It’s generally advised to use the smart protocol,
which we describe a bit further on.
Let’s follow the http-fetch process for the simplegit library:
$ git clone http://server/simplegit-progit.git
The first thing this command does is pull down the info/refs file. This file
is written by the update-server-info command, which is why you need to
enable that as a post-receive hook in order for the HTTP transport to work
properly:
=> GET info/refs
ca82a6dff817ec66f44342007202690a93763949 refs/heads/master
Now you have a list of the remote references and SHA-1s. Next, you look for
what the HEAD reference is so you know what to check out when you’re finished:
=> GET HEAD
ref: refs/heads/master
You need to check out the master branch when you’ve completed the process. At this point, you’re ready to start the walking process. Because your startCHAPTER 10: Git Internals
504ing point is the ca82a6 commit object you saw in the info/refs file, you start
by fetching that:
=> GET objects/ca/82a6dff817ec66f44342007202690a93763949
(179 bytes of binary data)
You get an object back – that object is in loose format on the server, and you
fetched it over a static HTTP GET request. You can zlib-uncompress it, strip off
the header, and look at the commit content:
$ git cat-file -p ca82a6dff817ec66f44342007202690a93763949
tree cfda3bf379e4f8dba8717dee55aab78aef7f4daf
parent 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7
author Scott Chacon <schacon@gmail.com> 1205815931 -0700
committer Scott Chacon <schacon@gmail.com> 1240030591 -0700
changed the version number
Next, you have two more objects to retrieve – cfda3b, which is the tree of
content that the commit we just retrieved points to; and 085bb3, which is the
parent commit:
=> GET objects/08/5bb3bcb608e1e8451d4b2432f8ecbe6306e7e7
(179 bytes of data)
That gives you your next commit object. Grab the tree object:
=> GET objects/cf/da3bf379e4f8dba8717dee55aab78aef7f4daf
(404 - Not Found)
Oops – it looks like that tree object isn’t in loose format on the server, so you
get a 404 response back. There are a couple of reasons for this – the object
could be in an alternate repository, or it could be in a packfile in this repository.
Git checks for any listed alternates first:
=> GET objects/info/http-alternates
(empty file)
If this comes back with a list of alternate URLs, Git checks for loose files and
packfiles there – this is a nice mechanism for projects that are forks of one another to share objects on disk. However, because no alternates are listed in this
case, your object must be in a packfile. To see what packfiles are available on
this server, you need to get the objects/info/packs file, which contains a
listing of them (also generated by update-server-info):
Transfer Protocols
505=> GET objects/info/packs
P pack-816a9b2334da9953e530f27bcac22082a9f5b835.pack
There is only one packfile on the server, so your object is obviously in there,
but you’ll check the index file to make sure. This is also useful if you have multiple packfiles on the server, so you can see which packfile contains the object
you need:
=> GET objects/pack/pack-816a9b2334da9953e530f27bcac22082a9f5b835.idx
(4k of binary data)
Now that you have the packfile index, you can see if your object is in it – because the index lists the SHA-1s of the objects contained in the packfile and the
offsets to those objects. Your object is there, so go ahead and get the whole
packfile:
=> GET objects/pack/pack-816a9b2334da9953e530f27bcac22082a9f5b835.pack
(13k of binary data)
You have your tree object, so you continue walking your commits. They’re all
also within the packfile you just downloaded, so you don’t have to do any more
requests to your server. Git checks out a working copy of the master branch
that was pointed to by the HEAD reference you downloaded at the beginning.
The Smart Protocol
The dumb protocol is simple but a bit inefficient, and it can’t handle writing of
data from the client to the server. The smart protocol is a more common method of transferring data, but it requires a process on the remote end that is intelligent about Git – it can read local data, figure out what the client has and
needs, and generate a custom packfile for it. There are two sets of processes for
transferring data: a pair for uploading data and a pair for downloading data.
UPLOADING DATA
To upload data to a remote process, Git uses the send-pack and receivepack processes. The send-pack process runs on the client and connects to a
receive-pack process on the remote side.
SSH
For example, say you run git push origin master in your project, and
origin is defined as a URL that uses the SSH protocol. Git fires up the sendpack process, which initiates a connection over SSH to your server. It tries to
CHAPTER 10: Git Internals
506run a command on the remote server via an SSH call that looks something like
this:
$ ssh -x git@server "git-receive-pack 'simplegit-progit.git'"
00a5ca82a6dff817ec66f4437202690a93763949 refs/heads/master□report-status \
delete-refs side-band-64k quiet ofs-delta \
agent=git/2:2.1.1+github-607-gfba4028 delete-refs
0000
The git-receive-pack command immediately responds with one line for
each reference it currently has – in this case, just the master branch and its
SHA-1. The first line also has a list of the server’s capabilities (here, reportstatus, delete-refs, and some others, including the client identifier).
Each line starts with a 4-character hex value specifying how long the rest of
the line is. Your first line starts with 00a5, which is hexadecimal for 165, meaning that 165 bytes remain on that line. The next line is 0000, meaning the server
is done with its references listing.
Now that it knows the server’s state, your send-pack process determines
what commits it has that the server doesn’t. For each reference that this push
will update, the send-pack process tells the receive-pack process that information. For instance, if you’re updating the master branch and adding an experiment branch, the send-pack response may look something like this:
0076ca82a6dff817ec66f44342007202690a93763949 15027957951b64cf874c3557a0f3547bd83b3ff6 \
refs/heads/master report-status
006c0000000000000000000000000000000000000000 cdfdb42577e2506715f8cfeacdbabc092bf63e8d \
refs/heads/experiment
0000
Git sends a line for each reference you’re updating with the line’s length, the
old SHA-1, the new SHA-1, and the reference that is being updated. The first line
also has the client’s capabilities. The SHA-1 value of all ’0’s means that nothing
was there before – because you’re adding the experiment reference. If you were
deleting a reference, you would see the opposite: all ’0’s on the right side.
Next, the client sends a packfile of all the objects the server doesn’t have
yet. Finally, the server responds with a success (or failure) indication:
000eunpack ok
HTTP(S)
This process is mostly the same over HTTP, though the handshaking is a bit
different. The connection is initiated with this request:
Transfer Protocols
507=> GET http://server/simplegit-progit.git/info/refs?service=git-receive-pack
001f# service=git-receive-pack
00ab6c5f0e45abd7832bf23074a333f739977c9e8188 refs/heads/master□report-status \
delete-refs side-band-64k quiet ofs-delta \
agent=git/2:2.1.1~vmg-bitmaps-bugaloo-608-g116744e
0000
That’s the end of the first client-server exchange. The client then makes another request, this time a POST, with the data that send-pack provides.
=> POST http://server/simplegit-progit.git/git-receive-pack
The POST request includes the send-pack output and the packfile as its
payload. The server then indicates success or failure with its HTTP response.
DOWNLOADING DATA
When you download data, the fetch-pack and upload-pack processes are involved. The client initiates a fetch-pack process that connects to an uploadpack process on the remote side to negotiate what data will be transferred
down.
SSH
If you’re doing the fetch over SSH, fetch-pack runs something like this:
$ ssh -x git@server "git-upload-pack 'simplegit-progit.git'"
After fetch-pack connects, upload-pack sends back something like this:
00dfca82a6dff817ec66f44342007202690a93763949 HEAD□multi_ack thin-pack \
side-band side-band-64k ofs-delta shallow no-progress include-tag \
multi_ack_detailed symref=HEAD:refs/heads/master \
agent=git/2:2.1.1+github-607-gfba4028
003fe2409a098dc3e53539a9028a94b6224db9d6a6b6 refs/heads/master
0000
This is very similar to what receive-pack responds with, but the capabilities are different. In addition, it sends back what HEAD points to (symref=HEAD:refs/heads/master) so the client knows what to check out if this
is a clone.
At this point, the fetch-pack process looks at what objects it has and responds with the objects that it needs by sending “want” and then the SHA-1 it
wants. It sends all the objects it already has with “have” and then the SHA-1. At
CHAPTER 10: Git Internals
508the end of this list, it writes “done” to initiate the upload-pack process to begin sending the packfile of the data it needs:
003cwant ca82a6dff817ec66f44342007202690a93763949 ofs-delta
0032have 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7
0009done
0000
HTTP(S)
The handshake for a fetch operation takes two HTTP requests. The first is a
GET to the same endpoint used in the dumb protocol:
=> GET $GIT_URL/info/refs?service=git-upload-pack
001e# service=git-upload-pack
00e7ca82a6dff817ec66f44342007202690a93763949 HEAD□multi_ack thin-pack \
side-band side-band-64k ofs-delta shallow no-progress include-tag \
multi_ack_detailed no-done symref=HEAD:refs/heads/master \
agent=git/2:2.1.1+github-607-gfba4028
003fca82a6dff817ec66f44342007202690a93763949 refs/heads/master
0000
This is very similar to invoking git-upload-pack over an SSH connection,
but the second exchange is performed as a separate request:
=> POST $GIT_URL/git-upload-pack HTTP/1.0
0032want 0a53e9ddeaddad63ad106860237bbf53411d11a7
0032have 441b40d833fdfa93eb2908e52742248faf0ee993
0000
Again, this is the same format as above. The response to this request indicates success or failure, and includes the packfile.
Protocols Summary
This section contains a very basic overview of the transfer protocols. The protocol includes many other features, such as multi_ack or side-band capabilities, but covering them is outside the scope of this book. We’ve tried to give you
a sense of the general back-and-forth between client and server; if you need
more knowledge than this, you’ll probably want to take a look at the Git source
code.
Transfer Protocols
509Maintenance and Data Recovery
Occasionally, you may have to do some cleanup – make a repository more compact, clean up an imported repository, or recover lost work. This section will
cover some of these scenarios.
Maintenance
Occasionally, Git automatically runs a command called “auto gc”. Most of the
time, this command does nothing. However, if there are too many loose objects
(objects not in a packfile) or too many packfiles, Git launches a full-fledged git
gc command. The “gc” stands for garbage collect, and the command does a
number of things: it gathers up all the loose objects and places them in packfiles, it consolidates packfiles into one big packfile, and it removes objects that
aren’t reachable from any commit and are a few months old.
You can run auto gc manually as follows:
$ git gc --auto
Again, this generally does nothing. You must have around 7,000 loose objects or more than 50 packfiles for Git to fire up a real gc command. You can
modify these limits with the gc.auto and gc.autopacklimit config settings,
respectively.
The other thing gc will do is pack up your references into a single file. Suppose your repository contains the following branches and tags:
$ find .git/refs -type f
.git/refs/heads/experiment
.git/refs/heads/master
.git/refs/tags/v1.0
.git/refs/tags/v1.1
If you run git gc, you’ll no longer have these files in the refs directory. Git
will move them for the sake of efficiency into a file named .git/packed-refs
that looks like this:
$ cat .git/packed-refs
# pack-refs with: peeled fully-peeled
cac0cab538b970a37ea1e769cbbde608743bc96d refs/heads/experiment
ab1afef80fac8e34258ff41fc1b867c702daa24b refs/heads/master
CHAPTER 10: Git Internals
510cac0cab538b970a37ea1e769cbbde608743bc96d refs/tags/v1.0
9585191f37f7b0fb9444f35a9bf50de191beadc2 refs/tags/v1.1
^1a410efbd13591db07496601ebc7a059dd55cfe9
If you update a reference, Git doesn’t edit this file but instead writes a new
file to refs/heads. To get the appropriate SHA-1 for a given reference, Git
checks for that reference in the refs directory and then checks the packedrefs file as a fallback. However, if you can’t find a reference in the refs directory, it’s probably in your packed-refs file.
Notice the last line of the file, which begins with a ^. This means the tag directly above is an annotated tag and that line is the commit that the annotated
tag points to.
Data Recovery
At some point in your Git journey, you may accidentally lose a commit. Generally, this happens because you force-delete a branch that had work on it, and it
turns out you wanted the branch after all; or you hard-reset a branch, thus
abandoning commits that you wanted something from. Assuming this happens,
how can you get your commits back?
Here’s an example that hard-resets the master branch in your test repository
to an older commit and then recovers the lost commits. First, let’s review where
your repository is at this point:
$ git log --pretty=oneline
ab1afef80fac8e34258ff41fc1b867c702daa24b modified repo a bit
484a59275031909e19aadb7c92262719cfcdf19a added repo.rb
1a410efbd13591db07496601ebc7a059dd55cfe9 third commit
cac0cab538b970a37ea1e769cbbde608743bc96d second commit
fdf4fc3344e67ab068f836878b6c4951e3b15f3d first commit
Now, move the master branch back to the middle commit:
$ git reset --hard 1a410efbd13591db07496601ebc7a059dd55cfe9
HEAD is now at 1a410ef third commit
$ git log --pretty=oneline
1a410efbd13591db07496601ebc7a059dd55cfe9 third commit
cac0cab538b970a37ea1e769cbbde608743bc96d second commit
fdf4fc3344e67ab068f836878b6c4951e3b15f3d first commit
Maintenance and Data Recovery
511You’ve effectively lost the top two commits – you have no branch from which
those commits are reachable. You need to find the latest commit SHA-1 and
then add a branch that points to it. The trick is finding that latest commit SHA-1
– it’s not like you’ve memorized it, right?
Often, the quickest way is to use a tool called git reflog. As you’re working, Git silently records what your HEAD is every time you change it. Each time
you commit or change branches, the reflog is updated. The reflog is also updated by the git update-ref command, which is another reason to use it instead of just writing the SHA-1 value to your ref files, as we covered in “Git References”. You can see where you’ve been at any time by running git reflog:
$ git reflog
1a410ef HEAD@{0}: reset: moving to 1a410ef
ab1afef HEAD@{1}: commit: modified repo.rb a bit
484a592 HEAD@{2}: commit: added repo.rb
Here we can see the two commits that we have had checked out, however
there is not much information here. To see the same information in a much
more useful way, we can run git log -g, which will give you a normal log output for your reflog.
$ git log -g
commit 1a410efbd13591db07496601ebc7a059dd55cfe9
Reflog: HEAD@{0} (Scott Chacon <schacon@gmail.com>)
Reflog message: updating HEAD
Author: Scott Chacon <schacon@gmail.com>
Date: Fri May 22 18:22:37 2009 -0700
third commit
commit ab1afef80fac8e34258ff41fc1b867c702daa24b
Reflog: HEAD@{1} (Scott Chacon <schacon@gmail.com>)
Reflog message: updating HEAD
Author: Scott Chacon <schacon@gmail.com>
Date: Fri May 22 18:15:24 2009 -0700
modified repo.rb a bit
It looks like the bottom commit is the one you lost, so you can recover it by
creating a new branch at that commit. For example, you can start a branch
named recover-branch at that commit (ab1afef):
CHAPTER 10: Git Internals
512$ git branch recover-branch ab1afef
$ git log --pretty=oneline recover-branch
ab1afef80fac8e34258ff41fc1b867c702daa24b modified repo a bit
484a59275031909e19aadb7c92262719cfcdf19a added repo.rb
1a410efbd13591db07496601ebc7a059dd55cfe9 third commit
cac0cab538b970a37ea1e769cbbde608743bc96d second commit
fdf4fc3344e67ab068f836878b6c4951e3b15f3d first commit
Cool – now you have a branch named recover-branch that is where your
master branch used to be, making the first two commits reachable again. Next,
suppose your loss was for some reason not in the reflog – you can simulate that
by removing recover-branch and deleting the reflog. Now the first two commits aren’t reachable by anything:
$ git branch -D recover-branch
$ rm -Rf .git/logs/
Because the reflog data is kept in the .git/logs/ directory, you effectively
have no reflog. How can you recover that commit at this point? One way is to
use the git fsck utility, which checks your database for integrity. If you run it
with the --full option, it shows you all objects that aren’t pointed to by another object:
$ git fsck --full
Checking object directories: 100% (256/256), done.
Checking objects: 100% (18/18), done.
dangling blob d670460b4b4aece5915caf5c68d12f560a9fe3e4
dangling commit ab1afef80fac8e34258ff41fc1b867c702daa24b
dangling tree aea790b9a58f6cf6f2804eeac9f0abbe9631e4c9
dangling blob 7108f7ecb345ee9d0084193f147cdad4d2998293
In this case, you can see your missing commit after the string “dangling commit”. You can recover it the same way, by adding a branch that points to that
SHA-1.
Removing Objects
There are a lot of great things about Git, but one feature that can cause issues is
the fact that a git clone downloads the entire history of the project, including every version of every file. This is fine if the whole thing is source code, because Git is highly optimized to compress that data efficiently. However, if
Maintenance and Data Recovery
513someone at any point in the history of your project added a single huge file,
every clone for all time will be forced to download that large file, even if it was
removed from the project in the very next commit. Because it’s reachable from
the history, it will always be there.
This can be a huge problem when you’re converting Subversion or Perforce
repositories into Git. Because you don’t download the whole history in those
systems, this type of addition carries few consequences. If you did an import
from another system or otherwise find that your repository is much larger than
it should be, here is how you can find and remove large objects.
Be warned: this technique is destructive to your commit history. It rewrites every commit object since the earliest tree you have to modify to remove
a large file reference. If you do this immediately after an import, before anyone
has started to base work on the commit, you’re fine – otherwise, you have to
notify all contributors that they must rebase their work onto your new commits.
To demonstrate, you’ll add a large file into your test repository, remove it in
the next commit, find it, and remove it permanently from the repository. First,
add a large object to your history:
$ curl https://www.kernel.org/pub/software/scm/git/git-2.1.0.tar.gz > git.tgz
$ git add git.tgz
$ git commit -m 'add git tarball'
[master 7b30847] add git tarball
1 file changed, 0 insertions(+), 0 deletions(-)
create mode 100644 git.tgz
Oops – you didn’t want to add a huge tarball to your project. Better get rid of
it:
$ git rm git.tgz
rm 'git.tgz'
$ git commit -m 'oops - removed large tarball'
[master dadf725] oops - removed large tarball
1 file changed, 0 insertions(+), 0 deletions(-)
delete mode 100644 git.tgz
Now, gc your database and see how much space you’re using:
$ git gc
Counting objects: 17, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (13/13), done.
CHAPTER 10: Git Internals
514Writing objects: 100% (17/17), done.
Total 17 (delta 1), reused 10 (delta 0)
You can run the count-objects command to quickly see how much space
you’re using:
$ git count-objects -v
count: 7
size: 32
in-pack: 17
packs: 1
size-pack: 4868
prune-packable: 0
garbage: 0
size-garbage: 0
The size-pack entry is the size of your packfiles in kilobytes, so you’re using almost 5MB. Before the last commit, you were using closer to 2K – clearly,
removing the file from the previous commit didn’t remove it from your history.
Every time anyone clones this repository, they will have to clone all 5MB just to
get this tiny project, because you accidentally added a big file. Let’s get rid of it.
First you have to find it. In this case, you already know what file it is. But suppose you didn’t; how would you identify what file or files were taking up so
much space? If you run git gc, all the objects are in a packfile; you can identify
the big objects by running another plumbing command called git verifypack and sorting on the third field in the output, which is file size. You can also
pipe it through the tail command because you’re only interested in the last
few largest files:
$ git verify-pack -v .git/objects/pack/pack-29…69.idx \
| sort -k 3 -n \
| tail -3
dadf7258d699da2c8d89b09ef6670edb7d5f91b4 commit 229 159 12
033b4468fa6b2a9547a70d88d1bbe8bf3f9ed0d5 blob 22044 5792 4977696
82c99a3e86bb1267b236a4b6eff7868d97489af1 blob 4975916 4976258 1438
The big object is at the bottom: 5MB. To find out what file it is, you’ll use the
rev-list command, which you used briefly in “Enforcing a Specific CommitMessage Format”. If you pass --objects to rev-list, it lists all the commit
SHA-1s and also the blob SHA-1s with the file paths associated with them. You
can use this to find your blob’s name:
Maintenance and Data Recovery
515$ git rev-list --objects --all | grep 82c99a3
82c99a3e86bb1267b236a4b6eff7868d97489af1 git.tgz
Now, you need to remove this file from all trees in your past. You can easily
see what commits modified this file:
$ git log --oneline --branches -- git.tgz
dadf725 oops - removed large tarball
7b30847 add git tarball
You must rewrite all the commits downstream from 7b30847 to fully remove
this file from your Git history. To do so, you use filter-branch, which you
used in “Rewriting History”:
$ git filter-branch --index-filter \
'git rm --ignore-unmatch --cached git.tgz' -- 7b30847^..
Rewrite 7b30847d080183a1ab7d18fb202473b3096e9f34 (1/2)rm 'git.tgz'
Rewrite dadf7258d699da2c8d89b09ef6670edb7d5f91b4 (2/2)
Ref 'refs/heads/master' was rewritten
The --index-filter option is similar to the --tree-filter option used
in “Rewriting History”, except that instead of passing a command that modifies files checked out on disk, you’re modifying your staging area or index each
time.
Rather than remove a specific file with something like rm file, you have to
remove it with git rm --cached – you must remove it from the index, not
from disk. The reason to do it this way is speed – because Git doesn’t have to
check out each revision to disk before running your filter, the process can be
much, much faster. You can accomplish the same task with --tree-filter if
you want. The --ignore-unmatch option to git rm tells it not to error out if
the pattern you’re trying to remove isn’t there. Finally, you ask filter-branch
to rewrite your history only from the 7b30847 commit up, because you know
that is where this problem started. Otherwise, it will start from the beginning
and will unnecessarily take longer.
Your history no longer contains a reference to that file. However, your reflog
and a new set of refs that Git added when you did the filter-branch under .git/refs/original still do, so you have to remove them and then repack the database. You need to get rid of anything that has a pointer to those
old commits before you repack:
CHAPTER 10: Git Internals
516$ rm -Rf .git/refs/original
$ rm -Rf .git/logs/
$ git gc
Counting objects: 15, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (11/11), done.
Writing objects: 100% (15/15), done.
Total 15 (delta 1), reused 12 (delta 0)
Let’s see how much space you saved.
$ git count-objects -v
count: 11
size: 4904
in-pack: 15
packs: 1
size-pack: 8
prune-packable: 0
garbage: 0
size-garbage: 0
The packed repository size is down to 8K, which is much better than 5MB.
You can see from the size value that the big object is still in your loose objects,
so it’s not gone; but it won’t be transferred on a push or subsequent clone,
which is what is important. If you really wanted to, you could remove the object
completely by running git prune with the --expire option:
$ git prune --expire now
$ git count-objects -v
count: 0
size: 0
in-pack: 15
packs: 1
size-pack: 8
prune-packable: 0
garbage: 0
size-garbage: 0
Environment Variables
Git always runs inside a bash shell, and uses a number of shell environment
variables to determine how it behaves. Occasionally, it comes in handy to know
Environment Variables
517what these are, and how they can be used to make Git behave the way you
want it to. This isn’t an exhaustive list of all the environment variables Git pays
attention to, but we’ll cover the most useful.
Global Behavior
Some of Git’s general behavior as a computer program depends on environment variables.
GIT_EXEC_PATH determines where Git looks for its sub-programs (like gitcommit, git-diff, and others). You can check the current setting by running
git --exec-path.
HOME isn’t usually considered customizable (too many other things depend
on it), but it’s where Git looks for the global configuration file. If you want a truly
portable Git installation, complete with global configuration, you can override
HOME in the portable Git’s shell profile.
PREFIX is similar, but for the system-wide configuration. Git looks for this
file at $PREFIX/etc/gitconfig.
GIT_CONFIG_NOSYSTEM, if set, disables the use of the system-wide configuration file. This is useful if your system config is interfering with your commands, but you don’t have access to change or remove it.
GIT_PAGER controls the program used to display multi-page output on the
command line. If this is unset, PAGER will be used as a fallback.
GIT_EDITOR is the editor Git will launch when the user needs to edit some
text (a commit message, for example). If unset, EDITOR will be used.
Repository Locations
Git uses several environment variables to determine how it interfaces with the
current repository.
GIT_DIR is the location of the .git folder. If this isn’t specified, Git walks up
the directory tree until it gets to ~ or /, looking for a .git directory at every
step.
GIT_CEILING_DIRECTORIES controls the behavior of searching for a .git
directory. If you access directories that are slow to load (such as those on a tape
drive, or across a slow network connection), you may want to have Git stop trying earlier than it might otherwise, especially if Git is invoked when building
your shell prompt.
GIT_WORK_TREE is the location of the root of the working directory for a
non-bare repository. If not specified, the parent directory of $GIT_DIR is used.
GIT_INDEX_FILE is the path to the index file (non-bare repositories only).
CHAPTER 10: Git Internals
518GIT_OBJECT_DIRECTORY can be used to specify the location of the directory that usually resides at .git/objects.
GIT_ALTERNATE_OBJECT_DIRECTORIES is a colon-separated list (formatted like /dir/one:/dir/two:…) which tells Git where to check for objects if
they aren’t in GIT_OBJECT_DIRECTORY. If you happen to have a lot of projects
with large files that have the exact same contents, this can be used to avoid
storing too many copies of them.
Pathspecs
A “pathspec” refers to how you specify paths to things in Git, including the use
of wildcards. These are used in the .gitignore file, but also on the commandline (git add *.c).
GIT_GLOB_PATHSPECS and GIT_NOGLOB_PATHSPECS control the default
behavior of wildcards in pathspecs. If GIT_GLOB_PATHSPECS is set to 1, wildcard characters act as wildcards (which is the default); if GIT_NOGLOB_PATHSPECS is set to 1, wildcard characters only match themselves, meaning something like *.c would only match a file named “*.c”, rather than any file whose
name ends with .c. You can override this in individual cases by starting the
pathspec with :(glob) or :(literal), as in :(glob)*.c.
GIT_LITERAL_PATHSPECS disables both of the above behaviors; no wildcard characters will work, and the override prefixes are disabled as well.
GIT_ICASE_PATHSPECS sets all pathspecs to work in a case-insensitive
manner.
Committing
The final creation of a Git commit object is usually done by git-commit-tree,
which uses these environment variables as its primary source of information,
falling back to configuration values only if these aren’t present.
GIT_AUTHOR_NAME is the human-readable name in the “author” field.
GIT_AUTHOR_EMAIL is the email for the “author” field.
GIT_AUTHOR_DATE is the timestamp used for the “author” field.
GIT_COMMITTER_NAME sets the human name for the “committer” field.
GIT_COMMITTER_EMAIL is the email address for the “committer” field.
GIT_COMMITTER_DATE is used for the timestamp in the “committer” field.
EMAIL is the fallback email address in case the user.email configuration
value isn’t set. If this isn’t set, Git falls back to the system user and host names.
Environment Variables
519Networking
Git uses the curl library to do network operations over HTTP, so
GIT_CURL_VERBOSE tells Git to emit all the messages generated by that library.
This is similar to doing curl -v on the command line.
GIT_SSL_NO_VERIFY tells Git not to verify SSL certificates. This can sometimes be necessary if you’re using a self-signed certificate to serve Git repositories over HTTPS, or you’re in the middle of setting up a Git server but haven’t
installed a full certificate yet.
If the data rate of an HTTP operation is lower than
GIT_HTTP_LOW_SPEED_LIMIT bytes per second for longer than
GIT_HTTP_LOW_SPEED_TIME seconds, Git will abort that operation. These values override the http.lowSpeedLimit and http.lowSpeedTime configuration values.
GIT_HTTP_USER_AGENT sets the user-agent string used by Git when communicating over HTTP. The default is a value like git/2.0.0.
Diffing and Merging
GIT_DIFF_OPTS is a bit of a misnomer. The only valid values are -u<n> or --
unified=<n>, which controls the number of context lines shown in a git
diff command.
GIT_EXTERNAL_DIFF is used as an override for the diff.external configuration value. If it’s set, Git will invoke this program when git diff is invoked.
GIT_DIFF_PATH_COUNTER and GIT_DIFF_PATH_TOTAL are useful from inside the program specified by GIT_EXTERNAL_DIFF or diff.external. The
former represents which file in a series is being diffed (starting with 1), and the
latter is the total number of files in the batch.
GIT_MERGE_VERBOSITY controls the output for the recursive merge strategy. The allowed values are as follows:
• 0 outputs nothing, except possibly a single error message.
• 1 shows only conflicts.
• 2 also shows file changes.
• 3 shows when files are skipped because they haven’t changed.
• 4 shows all paths as they are processed.
• 5 and above show detailed debugging information.
The default value is 2.
CHAPTER 10: Git Internals
520Debugging
Want to really know what Git is up to? Git has a fairly complete set of traces embedded, and all you need to do is turn them on. The possible values of these
variables are as follows:
• “true”, “1”, or “2” – the trace category is written to stderr.
• An absolute path starting with / – the trace output will be written to that
file.
GIT_TRACE controls general traces, which don’t fit into any specific category. This includes the expansion of aliases, and delegation to other subprograms.
$ GIT_TRACE=true git lga
20:12:49.877982 git.c:554 trace: exec: 'git-lga'
20:12:49.878369 run-command.c:341 trace: run_command: 'git-lga'
20:12:49.879529 git.c:282 trace: alias expansion: lga => 'log' '--graph' '--pr
20:12:49.879885 git.c:349 trace: built-in: git 'log' '--graph' '--pretty=oneli
20:12:49.899217 run-command.c:341 trace: run_command: 'less'
20:12:49.899675 run-command.c:192 trace: exec: 'less'
GIT_TRACE_PACK_ACCESS controls tracing of packfile access. The first field
is the packfile being accessed, the second is the offset within that file:
$ GIT_TRACE_PACK_ACCESS=true git status
20:10:12.081397 sha1_file.c:2088 .git/objects/pack/pack-c3fa...291e.pack 12
20:10:12.081886 sha1_file.c:2088 .git/objects/pack/pack-c3fa...291e.pack 34662
20:10:12.082115 sha1_file.c:2088 .git/objects/pack/pack-c3fa...291e.pack 35175
# […]
20:10:12.087398 sha1_file.c:2088 .git/objects/pack/pack-e80e...e3d2.pack 56914983
20:10:12.087419 sha1_file.c:2088 .git/objects/pack/pack-e80e...e3d2.pack 14303666
On branch master
Your branch is up-to-date with 'origin/master'.
nothing to commit, working directory clean
GIT_TRACE_PACKET enables packet-level tracing for network operations.
$ GIT_TRACE_PACKET=true git ls-remote origin
20:15:14.867043 pkt-line.c:46 packet: git< # service=git-upload-pack
20:15:14.867071 pkt-line.c:46 packet: git< 0000
20:15:14.867079 pkt-line.c:46 packet: git< 97b8860c071898d9e162678ea1035a
20:15:14.867088 pkt-line.c:46 packet: git< 0f20ae29889d61f2e93ae00fd34f1c
Environment Variables
52120:15:14.867094 pkt-line.c:46 packet: git< 36dc827bc9d17f80ed4f
# […]
GIT_TRACE_PERFORMANCE controls logging of performance data. The output shows how long each particular git invocation takes.
$ GIT_TRACE_PERFORMANCE=true git gc
20:18:19.499676 trace.c:414 performance: 0.374835000 s: git command: '
20:18:19.845585 trace.c:414 performance: 0.343020000 s: git command: '
Counting objects: 170994, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (43413/43413), done.
Writing objects: 100% (170994/170994), done.
Total 170994 (delta 126176), reused 170524 (delta 125706)
20:18:23.567927 trace.c:414 performance: 3.715349000 s: git command: '
20:18:23.584728 trace.c:414 performance: 0.000910000 s: git command: '
20:18:23.605218 trace.c:414 performance: 0.017972000 s: git command: '
20:18:23.606342 trace.c:414 performance: 3.756312000 s: git command: '
Checking connectivity: 170994, done.
20:18:25.225424 trace.c:414 performance: 1.616423000 s: git command: '
20:18:25.232403 trace.c:414 performance: 0.001051000 s: git command: '
20:18:25.233159 trace.c:414 performance: 6.112217000 s: git command: '
GIT_TRACE_SETUP shows information about what Git is discovering about
the repository and environment it’s interacting with.
$ GIT_TRACE_SETUP=true git status
20:19:47.086765 trace.c:315 setup: git_dir: .git
20:19:47.087184 trace.c:316 setup: worktree: /Users/ben/src/git
20:19:47.087191 trace.c:317 setup: cwd: /Users/ben/src/git
20:19:47.087194 trace.c:318 setup: prefix: (null)
On branch master
Your branch is up-to-date with 'origin/master'.
nothing to commit, working directory clean
Miscellaneous
GIT_SSH, if specified, is a program that is invoked instead of ssh when Git tries
to connect to an SSH host. It is invoked like $GIT_SSH [username@]host [-p
<port>] <command>. Note that this isn’t the easiest way to customize how
ssh is invoked; it won’t support extra command-line parameters, so you’d have
to write a wrapper script and set GIT_SSH to point to it. It’s probably easier just
to use the ~/.ssh/config file for that.
CHAPTER 10: Git Internals
522GIT_ASKPASS is an override for the core.askpass configuration value. This
is the program invoked whenever Git needs to ask the user for credentials,
which can expect a text prompt as a command-line argument, and should return the answer on stdout. (See “Credential Storage” for more on this subsystem.)
GIT_NAMESPACE controls access to namespaced refs, and is equivalent to
the --namespace flag. This is mostly useful on the server side, where you may
want to store multiple forks of a single repository in one repository, only keeping the refs separate.
GIT_FLUSH can be used to force Git to use non-buffered I/O when writing incrementally to stdout. A value of 1 causes Git to flush more often, a value of 0
causes all output to be buffered. The default value (if this variable is not set) is
to choose an appropriate buffering scheme depending on the activity and the
output mode.
GIT_REFLOG_ACTION lets you specify the descriptive text written to the reflog. Here’s an example:
$ GIT_REFLOG_ACTION="my action" git commit --allow-empty -m 'my message'
[master 9e3d55a] my message
$ git reflog -1
9e3d55a HEAD@{0}: my action: my message
Summary
You should have a pretty good understanding of what Git does in the background and, to some degree, how it’s implemented. This chapter has covered a
number of plumbing commands – commands that are lower level and simpler
than the porcelain commands you’ve learned about in the rest of the book. Understanding how Git works at a lower level should make it easier to understand
why it’s doing what it’s doing and also to write your own tools and helping
scripts to make your specific workflow work for you.
Git as a content-addressable filesystem is a very powerful tool that you can
easily use as more than just a VCS. We hope you can use your newfound knowledge of Git internals to implement your own cool application of this technology
and feel more comfortable using Git in more advanced ways.
Summary
523Git in Other Environments
If you read through the whole book, you’ve learned a lot about how to use Git
at the command line. You can work with local files, connect your repository to
others over a network, and work effectively with others. But the story doesn’t
end there; Git is usually used as part of a larger ecosystem, and the terminal
isn’t always the best way to work with it. Now we’ll take a look at some of the
other kinds of environments where Git can be useful, and how other applications (including yours) work alongside Git.
Graphical Interfaces
Git’s native environment is in the terminal. New features show up there first,
and only at the command line is the full power of Git completely at your disposal. But plain text isn’t the best choice for all tasks; sometimes a visual representation is what you need, and some users are much more comfortable with a
point-and-click interface.
It’s important to note that different interfaces are tailored for different workflows. Some clients expose only a carefully curated subset of Git functionality,
in order to support a specific way of working that the author considers effective. When viewed in this light, none of these tools can be called “better” than
any of the others, they’re simply more fit for their intended purpose. Also note
that there’s nothing these graphical clients can do that the command-line client
can’t; the command-line is still where you’ll have the most power and control
when working with your repositories.
gitk and git-gui
When you install Git, you also get its visual tools, gitk and git-gui.
gitk is a graphical history viewer. Think of it like a powerful GUI shell over
git log and git grep. This is the tool to use when you’re trying to find something that happened in the past, or visualize your project’s history.
525
AFigure 1-1.
The gitk history
viewer.
Gitk is easiest to invoke from the command-line. Just cd into a Git repository, and type:
$ gitk [git log options]
Gitk accepts many command-line options, most of which are passed
through to the underlying git log action. Probably one of the most useful is
the --all flag, which tells gitk to show commits reachable from any ref, not
just HEAD. Gitk’s interface looks like this:
On the top is something that looks a bit like the output of git log --
graph; each dot represents a commit, the lines represent parent relationships,
and refs are shown as colored boxes. The yellow dot represents HEAD, and the
red dot represents changes that are yet to become a commit. At the bottom is a
view of the selected commit; the comments and patch on the left, and a summary view on the right. In between is a collection of controls used for searching
history.
git-gui, on the other hand, is primarily a tool for crafting commits. It, too,
is easiest to invoke from the command line:
526 Appendix A, Git in Other EnvironmentsFigure 1-2.
The git-gui commit
tool.
$ git gui
And it looks something like this:
On the left is the index; unstaged changes are on top, staged changes on the
bottom. You can move entire files between the two states by clicking on their
icons, or you can select a file for viewing by clicking on its name.
At top right is the diff view, which shows the changes for the currentlyselected file. You can stage individual hunks (or individual lines) by rightclicking in this area.
At the bottom right is the message and action area. Type your message into
the text box and click “Commit” to do something similar to git commit. You
can also choose to amend the last commit by choosing the “Amend” radio button, which will update the “Staged Changes” area with the contents of the last
commit. Then you can simply stage or unstage some changes, alter the commit
message, and click “Commit” again to replace the old commit with a new one.
gitk and git-gui are examples of task-oriented tools. Each of them is tailored for a specific purpose (viewing history and creating commits, respectively), and omit the features not necessary for that task.
Graphical Interfaces 527Figure 1-3.
GitHub for Mac.
Figure 1-4.
GitHub for Windows.
GitHub for Mac and Windows
GitHub has created two workflow-oriented Git clients: one for Windows, and
one for Mac. These clients are a good example of workflow-oriented tools –
rather than expose all of Git’s functionality, they instead focus on a curated set
of commonly-used features that work well together. They look like this:
528 Appendix A, Git in Other EnvironmentsThey are designed to look and work very much alike, so we’ll treat them like
a single product in this chapter. We won’t be doing a detailed rundown of these
tools (they have their own documentation), but a quick tour of the “changes”
view (which is where you’ll spend most of your time) is in order.
• On the left is the list of repositories the client is tracking; you can add a
repository (either by cloning or attaching locally) by clicking the “+” icon
at the top of this area.
• In the center is a commit-input area, which lets you input a commit message, and select which files should be included. (On Windows, the commit history is displayed directly below this; on Mac, it’s on a separate tab.)
• On the right is a diff view, which shows what’s changed in your working
directory, or which changes were included in the selected commit.
• The last thing to notice is the “Sync” button at the top-right, which is the
primary way you interact over the network.
You don’t need a GitHub account to use these tools. While they’re designed to highlight GitHub’s service and recommended workflow, they
will happily work with any repository, and do network operations with
any Git host.
INSTALLATION
GitHub for Windows can be downloaded from https://windows.github.com,
and GitHub for Mac from https://mac.github.com. When the applications are
first run, they walk you through all the first-time Git setup, such as configuring
your name and email address, and both set up sane defaults for many common
configuration options, such as credential caches and CRLF behavior.
Both are “evergreen” – updates are downloaded and installed in the background while the applications are open. This helpfully includes a bundled version of Git, which means you probably won’t have to worry about manually updating it again. On Windows, the client includes a shortcut to launch Powershell
with Posh-git, which we’ll talk more about later in this chapter.
The next step is to give the tool some repositories to work with. The client
shows you a list of the repositories you have access to on GitHub, and can clone
them in one step. If you already have a local repository, just drag its directory
from the Finder or Windows Explorer into the GitHub client window, and it will
be included in the list of repositories on the left.
Graphical Interfaces 529Figure 1-5.
“Create Branch”
button on Mac.
Figure 1-6.
Creating a branch
on Windows.
RECOMMENDED WORKFLOW
Once it’s installed and configured, you can use the GitHub client for many common Git tasks. The intended workflow for this tool is sometimes called the “GitHub Flow.” We cover this in more detail in “The GitHub Flow”, but the general
gist is that (a) you’ll be committing to a branch, and (b) you’ll be syncing up
with a remote repository fairly regularly.
Branch management is one of the areas where the two tools diverge. On
Mac, there’s a button at the top of the window for creating a new branch:
On Windows, this is done by typing the new branch’s name in the branchswitching widget:
Once your branch is created, making new commits is fairly straightforward.
Make some changes in your working directory, and when you switch to the GitHub client window, it will show you which files changed. Enter a commit message, select the files you’d like to include, and click the “Commit” button (ctrlenter or ⌘-enter).
The main way you interact with other repositories over the network is
through the “Sync” feature. Git internally has separate operations for pushing,
530 Appendix A, Git in Other Environmentsfetching, merging, and rebasing, but the GitHub clients collapse all of these into
one multi-step feature. Here’s what happens when you click the Sync button:
1. git pull --rebase. If this fails because of a merge conflict, fall back to
git pull --no-rebase.
2. git push.
This is the most common sequence of network commands when working in
this style, so squashing them into one command saves a lot of time.
SUMMARY
These tools are very well-suited for the workflow they’re designed for. Developers and non-developers alike can be collaborating on a project within minutes,
and many of the best practices for this kind of workflow are baked into the
tools. However, if your workflow is different, or you want more control over how
and when network operations are done, we recommend you use another client
or the command line.
Other GUIs
There are a number of other graphical Git clients, and they run the gamut from
specialized, single-purpose tools all the way to apps that try to expose everything Git can do. The official Git website has a curated list of the most popular
clients at http://git-scm.com/downloads/guis. A more comprehensive list is
available on the Git wiki site, at https://git.wiki.kernel.org/index.php/Interfaces,_frontends,_and_tools#Graphical_Interfaces.
Git in Visual Studio
Starting with Visual Studio 2013 Update 1, Visual Studio users have a Git client
built directly into their IDE. Visual Studio has had source-control integration
features for quite some time, but they were oriented towards centralized, filelocking systems, and Git was not a good match for this workflow. Visual Studio
2013’s Git support has been separated from this older feature, and the result is
a much better fit between Studio and Git.
To locate the feature, open a project that’s controlled by Git (or just git init an existing project), and select View > Team Explorer from the menu. You’ll
see the “Connect” view, which looks a bit like this:
Git in Visual Studio 531Figure 1-7.
Connecting to a Git
repository from
Team Explorer.
Visual Studio remembers all of the projects you’ve opened that are Gitcontrolled, and they’re available in the list at the bottom. If you don’t see the
one you want there, click the “Add” link and type in the path to the working directory. Double clicking on one of the local Git repositories leads you to the
Home view, which looks like Figure A-8. This is a hub for performing Git actions; when you’re writing code, you’ll probably spend most of your time in the
“Changes” view, but when it comes time to pull down changes made by your
teammates, you’ll use the “Unsynced Commits” and “Branches” views.
532 Appendix A, Git in Other EnvironmentsFigure 1-8.
The “Home” view
for a Git repository
in Visual Studio.
Visual Studio now has a powerful task-focused UI for Git. It includes a linear
history view, a diff viewer, remote commands, and many other capabilities. For
complete documentation of this feature (which doesn’t fit here), go to http://
msdn.microsoft.com/en-us/library/hh850437.aspx.
Git in Eclipse
Eclipse ships with a plugin called Egit, which provides a fairly-complete interface to Git operations. It’s accessed by switching to the Git Perspective (Window
> Open Perspective > Other…, and select “Git”).
Git in Eclipse 533Figure 1-9.
Eclipse’s EGit
environment.
EGit comes with plenty of great documentation, which you can find by going
to Help > Help Contents, and choosing the “EGit Documentation” node from
the contents listing.
Git in Bash
If you’re a Bash user, you can tap into some of your shell’s features to make
your experience with Git a lot friendlier. Git actually ships with plugins for several shells, but it’s not turned on by default.
First, you need to get a copy of the contrib/completion/gitcompletion.bash file out of the Git source code. Copy it somewhere handy,
like your home directory, and add this to your .bashrc:
. ~/git-completion.bash
Once that’s done, change your directory to a git repository, and type:
$ git chec<tab>
534 Appendix A, Git in Other EnvironmentsFigure 1-10.
Customized bash
prompt.
…and Bash will auto-complete to git checkout. This works with all of Git’s
subcommands, command-line parameters, and remotes and ref names where
appropriate.
It’s also useful to customize your prompt to show information about the current directory’s Git repository. This can be as simple or complex as you want,
but there are generally a few key pieces of information that most people want,
like the current branch, and the status of the working directory. To add these to
your prompt, just copy the contrib/completion/git-prompt.sh file from
Git’s source repository to your home directory, add something like this to
your .bashrc:
. ~/git-prompt.sh
export GIT_PS1_SHOWDIRTYSTATE=1
export PS1='\w$(__git_ps1 " (%s)")\$ '
The \w means print the current working directory, the \$ prints the $ part of
the prompt, and __git_ps1 " (%s)" calls the function provided by gitprompt.sh with a formatting argument. Now your bash prompt will look like
this when you’re anywhere inside a Git-controlled project:
Both of these scripts come with helpful documentation; take a look at the
contents of git-completion.bash and git-prompt.sh for more information.
Git in Zsh
Zsh also ships with a tab-completion library for Git. To use it, simply run autoload -Uz compinit && compinit in your .zshrc. Zsh’s interface is a bit
more powerful than Bash’s:
Git in Zsh 535$ git che<tab>
check-attr -- display gitattributes information
check-ref-format -- ensure that a reference name is well formed
checkout -- checkout branch or paths to working tree
checkout-index -- copy files from index to working directory
cherry -- find commits not merged upstream
cherry-pick -- apply changes introduced by some existing commits
Ambiguous tab-completions aren’t just listed; they have helpful descriptions, and you can graphically navigate the list by repeatedly hitting tab. This
works with Git commands, their arguments, and names of things inside the
repository (like refs and remotes), as well as filenames and all the other things
Zsh knows how to tab-complete.
Zsh ships with a framework for getting information from version control systems, called vcs_info. To include the branch name in the prompt on the right
side, add these lines to your ~/.zshrc file:
autoload -Uz vcs_info
precmd_vcs_info() { vcs_info }
precmd_functions+=( precmd_vcs_info )
setopt prompt_subst
RPROMPT=\$vcs_info_msg_0_
# PROMPT=\$vcs_info_msg_0_'%# '
zstyle ':vcs_info:git:*' formats '%b'
This results in a display of the current branch on the right-hand side of the
terminal window, whenever your shell is inside a Git repository. (The left side is
supported as well, of course; just uncomment the assignment to PROMPT.) It
looks a bit like this:
536 Appendix A, Git in Other EnvironmentsFigure 1-11.
Customized zsh
prompt.
Figure 1-12.
An example of an
oh-my-zsh theme.
For more information on vcs_info, check out its documentation in the
zshcontrib(1) manual page, or online at http://zsh.sourceforge.net/Doc/
Release/User-Contributions.html#Version-Control-Information.
Instead of vcs_info, you might prefer the prompt customization script that
ships with Git, called git-prompt.sh; see http://git-prompt.sh for details.
git-prompt.sh is compatible with both Bash and Zsh.
Zsh is powerful enough that there are entire frameworks dedicated to making it better. One of them is called “oh-my-zsh”, and it can be found at https://
github.com/robbyrussell/oh-my-zsh. oh-my-zsh’s plugin system comes with
powerful git tab-completion, and it has a variety of prompt “themes”, many of
which display version-control data. Figure A-12 is just one example of what can
be done with this system.
Git in Zsh 537Figure 1-13.
Powershell with
Posh-git.
Git in Powershell
The standard command-line terminal on Windows (cmd.exe) isn’t really capable of a customized Git experience, but if you’re using Powershell, you’re in
luck. A package called Posh-Git (https://github.com/dahlbyk/posh-git) provides powerful tab-completion facilities, as well as an enhanced prompt to help
you stay on top of your repository status. It looks like this:
If you’ve installed GitHub for Windows, Posh-Git is included by default, and
all you have to do is add these lines to your profile.ps1 (which is usually located in C:\Users\<username>\Documents\WindowsPowerShell):
. (Resolve-Path "$env:LOCALAPPDATA\GitHub\shell.ps1")
. $env:github_posh_git\profile.example.ps1
If you’re not a GitHub for Windows user, just download a Posh-Git release
from (https://github.com/dahlbyk/posh-git), and uncompress it to the WindowsPowershell directory. Then open a Powershell prompt as the administrator, and do this:
> Set-ExecutionPolicy RemoteSigned -Scope CurrentUser -Confirm
> cd ~\Documents\WindowsPowerShell\posh-git
> .\install.ps1
538 Appendix A, Git in Other EnvironmentsThis will add the proper line to your profile.ps1 file, and posh-git will be
active the next time you open your prompt.
Summary
You’ve learned how to harness Git’s power from inside the tools that you use
during your everyday work, and also how to access Git repositories from your
own programs.
Summary 539Embedding Git in your
Applications
If your application is for developers, chances are good that it could benefit from
integration with source control. Even non-developer applications, such as
document editors, could potentially benefit from version-control features, and
Git’s model works very well for many different scenarios.
If you need to integrate Git with your application, you have essentially three
choices: spawning a shell and using the Git command-line tool; Libgit2; and
JGit.
Command-line Git
One option is to spawn a shell process and use the Git command-line tool to do
the work. This has the benefit of being canonical, and all of Git’s features are
supported. This also happens to be fairly easy, as most runtime environments
have a relatively simple facility for invoking a process with command-line arguments. However, this approach does have some downsides.
One is that all the output is in plain text. This means that you’ll have to parse
Git’s occasionally-changing output format to read progress and result information, which can be inefficient and error-prone.
Another is the lack of error recovery. If a repository is corrupted somehow, or
the user has a malformed configuration value, Git will simply refuse to perform
many operations.
Yet another is process management. Git requires you to maintain a shell environment on a separate process, which can add unwanted complexity. Trying
to coordinate many of these processes (especially when potentially accessing
the same repository from several processes) can be quite a challenge.
541
BLibgit2
Another option at your disposal is to use Libgit2. Libgit2 is a dependency-free
implementation of Git, with a focus on having a nice API for use within other
programs. You can find it at http://libgit2.github.com.
First, let’s take a look at what the C API looks like. Here’s a whirlwind tour:
// Open a repository
git_repository *repo;
int error = git_repository_open(&repo, "/path/to/repository");
// Dereference HEAD to a commit
git_object *head_commit;
error = git_revparse_single(&head_commit, repo, "HEAD^{commit}");
git_commit *commit = (git_commit*)head_commit;
// Print some of the commit's properties
printf("%s", git_commit_message(commit));
const git_signature *author = git_commit_author(commit);
printf("%s <%s>\n", author->name, author->email);
const git_oid *tree_id = git_commit_tree_id(commit);
// Cleanup
git_commit_free(commit);
git_repository_free(repo);
The first couple of lines open a Git repository. The git_repository type
represents a handle to a repository with a cache in memory. This is the simplest
method, for when you know the exact path to a repository’s working directory
or .git folder. There’s also the git_repository_open_ext which includes
options for searching, git_clone and friends for making a local clone of a remote repository, and git_repository_init for creating an entirely new
repository.
The second chunk of code uses rev-parse syntax (see “Branch References”
for more on this) to get the commit that HEAD eventually points to. The type
returned is a git_object pointer, which represents something that exists in
the Git object database for a repository. git_object is actually a “parent” type
for several different kinds of objects; the memory layout for each of the “child”
types is the same as for git_object, so you can safely cast to the right one. In
this case, git_object_type(commit) would return GIT_OBJ_COMMIT, so it’s
safe to cast to a git_commit pointer.
The next chunk shows how to access the commit’s properties. The last line
here uses a git_oid type; this is Libgit2’s representation for a SHA-1 hash.
From this sample, a couple of patterns have started to emerge:
542 Appendix B, Embedding Git in your Applications• If you declare a pointer and pass a reference to it into a Libgit2 call, that
call will probably return an integer error code. A 0 value indicates success;
anything less is an error.
• If Libgit2 populates a pointer for you, you’re responsible for freeing it.
• If Libgit2 returns a const pointer from a call, you don’t have to free it, but
it will become invalid when the object it belongs to is freed.
• Writing C is a bit painful.
That last one means it isn’t very probable that you’ll be writing C when using
Libgit2. Fortunately, there are a number of language-specific bindings available
that make it fairly easy to work with Git repositories from your specific language
and environment. Let’s take a look at the above example written using the Ruby
bindings for Libgit2, which are named Rugged, and can be found at https://
github.com/libgit2/rugged.
repo = Rugged::Repository.new('path/to/repository')
commit = repo.head.target
puts commit.message
puts "#{commit.author[:name]} <#{commit.author[:email]}>"
tree = commit.tree
As you can see, the code is much less cluttered. Firstly, Rugged uses exceptions; it can raise things like ConfigError or ObjectError to signal error conditions. Secondly, there’s no explicit freeing of resources, since Ruby is garbagecollected. Let’s take a look at a slightly more complicated example: crafting a
commit from scratch
blob_id = repo.write("Blob contents", :blob)
index = repo.index
index.read_tree(repo.head.target.tree)
index.add(:path => 'newfile.txt', :oid => blob_id)
sig = {
:email => "bob@example.com",
:name => "Bob User",
:time => Time.now,
}
commit_id = Rugged::Commit.create(repo,
:tree => index.write_tree(repo),
:author => sig,
:committer => sig,
:message => "Add newfile.txt",
:parents => repo.empty? ? [] : [ repo.head.target ].compact,
:update_ref => 'HEAD',
Libgit2 543)
commit = repo.lookup(commit_id)
Create a new blob, which contains the contents of a new file.
Populate the index with the head commit’s tree, and add the new file at the
path newfile.txt.
This creates a new tree in the ODB, and uses it for the new commit.
We use the same signature for both the author and committer fields.
The commit message.
When creating a commit, you have to specify the new commit’s parents. This
uses the tip of HEAD for the single parent.
Rugged (and Libgit2) can optionally update a reference when making a commit.
The return value is the SHA-1 hash of a new commit object, which you can
then use to get a Commit object.
The Ruby code is nice and clean, but since Libgit2 is doing the heavy lifting,
this code will run pretty fast, too. If you’re not a rubyist, we touch on some other bindings in “Other Bindings”.
Advanced Functionality
Libgit2 has a couple of capabilities that are outside the scope of core Git. One
example is pluggability: Libgit2 allows you to provide custom “backends” for
several types of operation, so you can store things in a different way than stock
Git does. Libgit2 allows custom backends for configuration, ref storage, and the
object database, among other things.
Let’s take a look at how this works. The code below is borrowed from the set
of backend examples provided by the Libgit2 team (which can be found at
https://github.com/libgit2/libgit2-backends). Here’s how a custom backend
for the object database is set up:
git_odb *odb;
int error = git_odb_new(&odb);
git_odb_backend *my_backend;
error = git_odb_backend_mine(&my_backend, /*…*/);
544 Appendix B, Embedding Git in your Applicationserror = git_odb_add_backend(odb, my_backend, 1);
git_repository *repo;
error = git_repository_open(&repo, "some-path");
error = git_repository_set_odb(odb);
(Note that errors are captured, but not handled. We hope your code is better
than ours.)
Initialize an empty object database (ODB) “frontend,” which will act as a
container for the “backends” which are the ones doing the real work.
Initialize a custom ODB backend.
Add the backend to the frontend.
Open a repository, and set it to use our ODB to look up objects.
But what is this git_odb_backend_mine thing? Well, that’s the constructor
for your own ODB implementation, and you can do whatever you want in there,
so long as you fill in the git_odb_backend structure properly. Here’s what it
could look like:
typedef struct {
git_odb_backend parent;
// Some other stuff
void *custom_context;
} my_backend_struct;
int git_odb_backend_mine(git_odb_backend **backend_out, /*…*/)
{
my_backend_struct *backend;
backend = calloc(1, sizeof (my_backend_struct));
backend->custom_context = …;
backend->parent.read = &my_backend__read;
backend->parent.read_prefix = &my_backend__read_prefix;
backend->parent.read_header = &my_backend__read_header;
// …
*backend_out = (git_odb_backend *) backend;
return GIT_SUCCESS;
}
Libgit2 545The subtlest constraint here is that my_backend_struct’s first member
must be a git_odb_backend structure; this ensures that the memory layout is
what the Libgit2 code expects it to be. The rest of it is arbitrary; this structure
can be as large or small as you need it to be.
The initialization function allocates some memory for the structure, sets up
the custom context, and then fills in the members of the parent structure that
it supports. Take a look at the include/git2/sys/odb_backend.h file in the
Libgit2 source for a complete set of call signatures; your particular use case will
help determine which of these you’ll want to support.
Other Bindings
Libgit2 has bindings for many languages. Here we show a small example using
a few of the more complete bindings packages as of this writing; libraries exist
for many other languages, including C++, Go, Node.js, Erlang, and the JVM, all
in various stages of maturity. The official collection of bindings can be found by
browsing the repositories at https://github.com/libgit2. The code we’ll write
will return the commit message from the commit eventually pointed to by
HEAD (sort of like git log -1).
LIBGIT2SHARP
If you’re writing a .NET or Mono application, LibGit2Sharp (https://github.com/
libgit2/libgit2sharp) is what you’re looking for. The bindings are written in C#,
and great care has been taken to wrap the raw Libgit2 calls with native-feeling
CLR APIs. Here’s what our example program looks like:
new Repository(@"C:\path\to\repo").Head.Tip.Message;
For desktop Windows applications, there’s even a NuGet package that will
help you get started quickly.
OBJECTIVE-GIT
If your application is running on an Apple platform, you’re likely using
Objective-C as your implementation language. Objective-Git (https://
github.com/libgit2/objective-git) is the name of the Libgit2 bindings for that
environment. The example program looks like this:
GTRepository *repo =
[[GTRepository alloc] initWithURL:[NSURL fileURLWithPath: @"/path/to/repo"] erro
NSString *msg = [[[repo headReferenceWithError:NULL] resolvedTarget] message];
546 Appendix B, Embedding Git in your ApplicationsObjective-git is fully interoperable with Swift, so don’t fear if you’ve left
Objective-C behind.
PYGIT2
The bindings for Libgit2 in Python are called Pygit2, and can be found at http://
www.pygit2.org/. Our example program:
pygit2.Repository("/path/to/repo") # open repository
.head # get the current branch
.peel(pygit2.Commit) # walk down to the commit
.message # read the message
Further Reading
Of course, a full treatment of Libgit2’s capabilities is outside the scope of this
book. If you want more information on Libgit2 itself, there’s API documentation
at https://libgit2.github.com/libgit2, and a set of guides at https://
libgit2.github.com/docs. For the other bindings, check the bundled README
and tests; there are often small tutorials and pointers to further reading there.
JGit
If you want to use Git from within a Java program, there is a fully featured Git
library called JGit. JGit is a relatively full-featured implementation of Git written
natively in Java, and is widely used in the Java community. The JGit project is
under the Eclipse umbrella, and its home can be found at http://
www.eclipse.org/jgit.
Getting Set Up
There are a number of ways to connect your project with JGit and start writing
code against it. Probably the easiest is to use Maven – the integration is accomplished by adding the following snippet to the <dependencies> tag in your
pom.xml file:
<dependency>
<groupId>org.eclipse.jgit</groupId>
<artifactId>org.eclipse.jgit</artifactId>
<version>3.5.0.201409260305-r</version>
</dependency>
JGit 547The version will most likely have advanced by the time you read this; check
http://mvnrepository.com/artifact/org.eclipse.jgit/org.eclipse.jgit for updated repository information. Once this step is done, Maven will automatically acquire and use the JGit libraries that you’ll need.
If you would rather manage the binary dependencies yourself, pre-built JGit
binaries are available from http://www.eclipse.org/jgit/download. You can
build them into your project by running a command like this:
javac -cp .:org.eclipse.jgit-3.5.0.201409260305-r.jar App.java
java -cp .:org.eclipse.jgit-3.5.0.201409260305-r.jar App
Plumbing
JGit has two basic levels of API: plumbing and porcelain. The terminology for
these comes from Git itself, and JGit is divided into roughly the same kinds of
areas: porcelain APIs are a friendly front-end for common user-level actions
(the sorts of things a normal user would use the Git command-line tool for),
while the plumbing APIs are for interacting with low-level repository objects directly.
The starting point for most JGit sessions is the Repository class, and the
first thing you’ll want to do is create an instance of it. For a filesystem-based
repository (yes, JGit allows for other storage models), this is accomplished using FileRepositoryBuilder:
// Create a new repository
Repository newlyCreatedRepo = FileRepositoryBuilder.create(
new File("/tmp/new_repo/.git"));
newlyCreatedRepo.create();
// Open an existing repository
Repository existingRepo = new FileRepositoryBuilder()
.setGitDir(new File("my_repo/.git"))
.build();
The builder has a fluent API for providing all the things it needs to find a Git
repository, whether or not your program knows exactly where it’s located. It
can use environment variables (.readEnvironment()), start from a place in
the working directory and search (.setWorkTree(…).findGitDir()), or just
open a known .git directory as above.
Once you have a Repository instance, you can do all sorts of things with it.
Here’s a quick sampling:
548 Appendix B, Embedding Git in your Applications// Get a reference
Ref master = repo.getRef("master");
// Get the object the reference points to
ObjectId masterTip = master.getObjectId();
// Rev-parse
ObjectId obj = repo.resolve("HEAD^{tree}");
// Load raw object contents
ObjectLoader loader = repo.open(masterTip);
loader.copyTo(System.out);
// Create a branch
RefUpdate createBranch1 = repo.updateRef("refs/heads/branch1");
createBranch1.setNewObjectId(masterTip);
createBranch1.update();
// Delete a branch
RefUpdate deleteBranch1 = repo.updateRef("refs/heads/branch1");
deleteBranch1.setForceUpdate(true);
deleteBranch1.delete();
// Config
Config cfg = repo.getConfig();
String name = cfg.getString("user", null, "name");
There’s quite a bit going on here, so let’s go through it one section at a time.
The first line gets a pointer to the master reference. JGit automatically grabs
the actual master ref, which lives at refs/heads/master, and returns an object that lets you fetch information about the reference. You can get the name
(.getName()), and either the target object of a direct reference (.getObjectId()) or the reference pointed to by a symbolic ref (.getTarget()). Ref objects are also used to represent tag refs and objects, so you can ask if the tag is
“peeled,” meaning that it points to the final target of a (potentially long) string
of tag objects.
The second line gets the target of the master reference, which is returned as
an ObjectId instance. ObjectId represents the SHA-1 hash of an object, which
might or might not exist in Git’s object database. The third line is similar, but
shows how JGit handles the rev-parse syntax (for more on this, see “Branch
References”); you can pass any object specifier that Git understands, and JGit
will return either a valid ObjectId for that object, or null.
The next two lines show how to load the raw contents of an object. In this
example, we call ObjectLoader.copyTo() to stream the contents of the object directly to stdout, but ObjectLoader also has methods to read the type and
size of an object, as well as return it as a byte array. For large objects
JGit 549(where .isLarge() returns true), you can call .openStream() to get an
InputStream-like object that can read the raw object data without pulling it all
into memory at once.
The next few lines show what it takes to create a new branch. We create a
RefUpdate instance, configure some parameters, and call .update() to trigger
the change. Directly following this is the code to delete that same branch. Note
that .setForceUpdate(true) is required for this to work; otherwise the .delete() call will return REJECTED, and nothing will happen.
The last example shows how to fetch the user.name value from the Git configuration files. This Config instance uses the repository we opened earlier for
local configuration, but will automatically detect the global and system configuration files and read values from them as well.
This is only a small sampling of the full plumbing API; there are many more
methods and classes available. Also not shown here is the way JGit handles errors, which is through the use of exceptions. JGit APIs sometimes throw standard Java exceptions (such as IOException), but there are a host of JGitspecific exception types that are provided as well (such as NoRemoteRepositoryException, CorruptObjectException, and NoMergeBaseException).
Porcelain
The plumbing APIs are rather complete, but it can be cumbersome to string
them together to achieve common goals, like adding a file to the index, or making a new commit. JGit provides a higher-level set of APIs to help out with this,
and the entry point to these APIs is the Git class:
Repository repo;
// construct repo...
Git git = new Git(repo);
The Git class has a nice set of high-level builder-style methods that can be
used to construct some pretty complex behavior. Let’s take a look at an example – doing something like git ls-remote:
CredentialsProvider cp = new UsernamePasswordCredentialsProvider("username", "p4ssw0
Collection<Ref> remoteRefs = git.lsRemote()
.setCredentialsProvider(cp)
.setRemote("origin")
.setTags(true)
.setHeads(false)
.call();
for (Ref ref : remoteRefs) {
550 Appendix B, Embedding Git in your ApplicationsSystem.out.println(ref.getName() + " -> " + ref.getObjectId().name());
}
This is a common pattern with the Git class; the methods return a command
object that lets you chain method calls to set parameters, which are executed
when you call .call(). In this case, we’re asking the origin remote for tags,
but not heads. Also notice the use of a CredentialsProvider object for authentication.
Many other commands are available through the Git class, including but not
limited to add, blame, commit, clean, push, rebase, revert, and reset.
Further Reading
This is only a small sampling of JGit’s full capabilities. If you’re interested and
want to learn more, here’s where to look for information and inspiration:
• The official JGit API documentation is available online at http://download.eclipse.org/jgit/docs/latest/apidocs. These are standard Javadoc,
so your favorite JVM IDE will be able to install them locally, as well.
• The JGit Cookbook at https://github.com/centic9/jgit-cookbook has
many examples of how to do specific tasks with JGit.
• There are several good resources pointed out at http://stackoverflow.com/questions/6861881.
JGit 551Git Commands
Throughout the book we have introduced dozens of Git commands and have
tried hard to introduce them within something of a narrative, adding more
commands to the story slowly. However, this leaves us with examples of usage
of the commands somewhat scattered throughout the whole book.
In this appendix, we’ll go through all the Git commands we addressed
throughout the book, grouped roughly by what they’re used for. We’ll talk
about what each command very generally does and then point out where in the
book you can find us having used it.
Setup and Config
There are two commands that are used quite a lot, from the first invocations of
Git to common every day tweaking and referencing, the config and help commands.
git config
Git has a default way of doing hundreds of things. For a lot of these things, you
can tell Git to default to doing them a different way, or set your preferences.
This involves everything from telling Git what your name is to specific terminal
color preferences or what editor you use. There are several files this command
will read from and write to so you can set values globally or down to specific
repositories.
The git config command has been used in nearly every chapter of the
book.
In “First-Time Git Setup” we used it to specify our name, email address and
editor preference before we even got started using Git.
In “Git Aliases” we showed how you could use it to create shorthand commands that expand to long option sequences so you don’t have to type them
every time.
553
CIn “Rebasing” we used it to make --rebase the default when you run git
pull.
In “Credential Storage” we used it to set up a default store for your HTTP
passwords.
In “Keyword Expansion” we showed how to set up smudge and clean filters
on content coming in and out of Git.
Finally, basically the entirety of “Git Configuration” is dedicated to the
command.
git help
The git help command is used to show you all the documentation shipped
with Git about any command. While we’re giving a rough overview of most of
the more popular ones in this appendix, for a full listing of all of the possible
options and flags for every command, you can always run git help <command>.
We introduced the git help command in “Getting Help” and showed you
how to use it to find more information about the git shell in “Setting Up
the Server”.
Getting and Creating Projects
There are two ways to get a Git repository. One is to copy it from an existing
repository on the network or elsewhere and the other is to create a new one in
an existing directory.
git init
To take a directory and turn it into a new Git repository so you can start version
controlling it, you can simply run git init.
We first introduce this in “Getting a Git Repository”, where we show creating a brand new repository to start working with.
We talk briefly about how you can change the default branch from “master”
in “Remote Branches”.
We use this command to create an empty bare repository for a server in
“Putting the Bare Repository on a Server”.
Finally, we go through some of the details of what it actually does behind
the scenes in “Plumbing and Porcelain”.
554 Appendix C, Git Commandsgit clone
The git clone command is actually something of a wrapper around several
other commands. It creates a new directory, goes into it and runs git init to
make it an empty Git repository, adds a remote (git remote add) to the URL
that you pass it (by default named origin), runs a git fetch from that remote repository and then checks out the latest commit into your working directory with git checkout.
The git clone command is used in dozens of places throughout the book,
but we’ll just list a few interesting places.
It’s basically introduced and explained in “Cloning an Existing Repository”, where we go through a few examples.
In “Getting Git on a Server” we look at using the --bare option to create a
copy of a Git repository with no working directory.
In “Bundling” we use it to unbundle a bundled Git repository.
Finally, in “Cloning a Project with Submodules” we learn the --
recursive option to make cloning a repository with submodules a little simpler.
Though it’s used in many other places through the book, these are the ones
that are somewhat unique or where it is used in ways that are a little different.
Basic Snapshotting
For the basic workflow of staging content and committing it to your history,
there are only a few basic commands.
git add
The git add command adds content from the working directory into the staging area (or “index”) for the next commit. When the git commit command is
run, by default it only looks at this staging area, so git add is used to craft
what exactly you would like your next commit snapshot to look like.
This command is an incredibly important command in Git and is mentioned
or used dozens of times in this book. We’ll quickly cover some of the unique
uses that can be found.
We first introduce and explain git add in detail in “Tracking New Files”.
We mention how to use it to resolve merge conflicts in “Basic Merge Conflicts”.
We go over using it to interactively stage only specific parts of a modified file
in “Interactive Staging”.
Basic Snapshotting 555Finally, we emulate it at a low level in “Tree Objects”, so you can get an idea
of what it’s doing behind the scenes.
git status
The git status command will show you the different states of files in your
working directory and staging area. Which files are modified and unstaged and
which are staged but not yet committed. In its normal form, it also will show
you some basic hints on how to move files between these stages.
We first cover status in “Checking the Status of Your Files”, both in its basic and simplified forms. While we use it throughout the book, pretty much everything you can do with the git status command is covered there.
git diff
The git diff command is used when you want to see differences between
any two trees. This could be the difference between your working environment
and your staging area (git diff by itself), between your staging area and your
last commit (git diff --staged), or between two commits (git diff master branchB).
We first look at the basic uses of git diff in “Viewing Your Staged and
Unstaged Changes”, where we show how to see what changes are staged and
which are not yet staged.
We use it to look for possible whitespace issues before committing with the
--check option in “Commit Guidelines”.
We see how to check the differences between branches more effectively with
the git diff A...B syntax in “Determining What Is Introduced”.
We use it to filter out whitespace differences with -b and how to compare
different stages of conflicted files with --theirs, --ours and --base in “Advanced Merging”.
Finally, we use it to effectively compare submodule changes with --
submodule in “Starting with Submodules”.
git difftool
The git difftool command simply launches an external tool to show you
the difference between two trees in case you want to use something other than
the built in git diff command.
We only briefly mention this in “Viewing Your Staged and Unstaged
Changes”.
556 Appendix C, Git Commandsgit commit
The git commit command takes all the file contents that have been staged
with git add and records a new permanent snapshot in the database and then
moves the branch pointer on the current branch up to it.
We first cover the basics of committing in “Committing Your Changes”.
There we also demonstrate how to use the -a flag to skip the git add step in
daily workflows and how to use the -m flag to pass a commit message in on the
command line instead of firing up an editor.
In “Undoing Things” we cover using the --amend option to redo the most
recent commit.
In “Branches in a Nutshell”, we go into much more detail about what git
commit does and why it does it like that.
We looked at how to sign commits cryptographically with the -S flag in
“Signing Commits”.
Finally, we take a look at what the git commit command does in the background and how it’s actually implemented in “Commit Objects”.
git reset
The git reset command is primarily used to undo things, as you can possibly
tell by the verb. It moves around the HEAD pointer and optionally changes the
index or staging area and can also optionally change the working directory if
you use --hard. This final option makes it possible for this command to lose
your work if used incorrectly, so make sure you understand it before using it.
We first effectively cover the simplest use of git reset in “Unstaging a
Staged File”, where we use it to unstage a file we had run git add on.
We then cover it in quite some detail in “Reset Demystified”, which is entirely devoted to explaining this command.
We use git reset --hard to abort a merge in “Aborting a Merge”, where
we also use git merge --abort, which is a bit of a wrapper for the git reset command.
git rm
The git rm command is used to remove files from the staging area and working directory for Git. It is similar to git add in that it stages a removal of a file
for the next commit.
Basic Snapshotting 557We cover the git rm command in some detail in “Removing Files”, including recursively removing files and only removing files from the staging area but
leaving them in the working directory with --cached.
The only other differing use of git rm in the book is in “Removing Objects” where we briefly use and explain the --ignore-unmatch when running
git filter-branch, which simply makes it not error out when the file we are
trying to remove doesn’t exist. This can be useful for scripting purposes.
git mv
The git mv command is a thin convenience command to move a file and then
run git add on the new file and git rm on the old file.
We only briefly mention this command in “Moving Files”.
git clean
The git clean command is used to remove unwanted files from your working
directory. This could include removing temporary build artifacts or merge conflict files.
We cover many of the options and scenarios in which you might used the
clean command in “Cleaning your Working Directory”.
Branching and Merging
There are just a handful of commands that implement most of the branching
and merging functionality in Git.
git branch
The git branch command is actually something of a branch management
tool. It can list the branches you have, create a new branch, delete branches
and rename branches.
Most of Chapter 3 is dedicated to the branch command and it’s used
throughout the entire chapter. We first introduce it in “Creating a New
Branch” and we go through most of its other features (listing and deleting) in
“Branch Management”.
In “Tracking Branches” we use the git branch -u option to set up a
tracking branch.
Finally, we go through some of what it does in the background in “Git References”.
558 Appendix C, Git Commandsgit checkout
The git checkout command is used to switch branches and check content
out into your working directory.
We first encounter the command in “Switching Branches” along with the
git branch command.
We see how to use it to start tracking branches with the --track flag in
“Tracking Branches”.
We use it to reintroduce file conflicts with --conflict=diff3 in “Checking
Out Conflicts”.
We go into closer detail on its relationship with git reset in “Reset Demystified”.
Finally, we go into some implementation detail in “The HEAD”.
git merge
The git merge tool is used to merge one or more branches into the branch you
have checked out. It will then advance the current branch to the result of the
merge.
The git merge command was first introduced in “Basic Branching”.
Though it is used in various places in the book, there are very few variations of
the merge command — generally just git merge <branch> with the name of
the single branch you want to merge in.
We covered how to do a squashed merge (where Git merges the work but
pretends like it’s just a new commit without recording the history of the branch
you’re merging in) at the very end of “Forked Public Project”.
We went over a lot about the merge process and command, including the -
Xignore-space-change command and the --abort flag to abort a problem
merge in “Advanced Merging”.
We learned how to verify signatures before merging if your project is using
GPG signing in “Signing Commits”.
Finally, we learned about Subtree merging in “Subtree Merging”.
git mergetool
The git mergetool command simply launches an external merge helper in
case you have issues with a merge in Git.
We mention it quickly in “Basic Merge Conflicts” and go into detail on how
to implement your own external merge tool in “External Merge and Diff
Tools”.
Branching and Merging 559git log
The git log command is used to show the reachable recorded history of a
project from the most recent commit snapshot backwards. By default it will only show the history of the branch you’re currently on, but can be given different
or even multiple heads or branches from which to traverse. It is also often used
to show differences between two or more branches at the commit level.
This command is used in nearly every chapter of the book to demonstrate
the history of a project.
We introduce the command and cover it in some depth in “Viewing the
Commit History”. There we look at the -p and --stat option to get an idea of
what was introduced in each commit and the --pretty and --oneline options to view the history more concisely, along with some simple date and author filtering options.
In “Creating a New Branch” we use it with the --decorate option to easily
visualize where our branch pointers are located and we also use the --graph
option to see what divergent histories look like.
In “Private Small Team” and “Commit Ranges” we cover the branchA..branchB syntax to use the git log command to see what commits are
unique to a branch relative to another branch. In “Commit Ranges” we go
through this fairly extensively.
In “Merge Log” and “Triple Dot” we cover using the branchA...branchB
format and the --left-right syntax to see what is in one branch or the other
but not in both. In “Merge Log” we also look at how to use the --merge option
to help with merge conflict debugging as well as using the --cc option to look
at merge commit conflicts in your history.
In “RefLog Shortnames” we use the -g option to view the Git reflog
through this tool instead of doing branch traversal.
In “Searching” we look at using the -S and -L options to do fairly sophisticated searches for something that happened historically in the code such as
seeing the history of a function.
In “Signing Commits” we see how to use --show-signature to add a validation string to each commit in the git log output based on if it was validly
signed or not.
git stash
The git stash command is used to temporarily store uncommitted work in
order to clean out your working directory without having to commit unfinished
work on a branch.
This is basically entirely covered in “Stashing and Cleaning”.
560 Appendix C, Git Commandsgit tag
The git tag command is used to give a permanent bookmark to a specific
point in the code history. Generally this is used for things like releases.
This command is introduced and covered in detail in “Tagging” and we use
it in practice in “Tagging Your Releases”.
We also cover how to create a GPG signed tag with the -s flag and verify one
with the -v flag in “Signing Your Work”.
Sharing and Updating Projects
There are not very many commands in Git that access the network, nearly all of
the commands operate on the local database. When you are ready to share
your work or pull changes from elsewhere, there are a handful of commands
that deal with remote repositories.
git fetch
The git fetch command communicates with a remote repository and fetches
down all the information that is in that repository that is not in your current one
and stores it in your local database.
We first look at this command in “Fetching and Pulling from Your Remotes” and we continue to see examples of it use in “Remote Branches”.
We also use it in several of the examples in “Contributing to a Project”.
We use it to fetch a single specific reference that is outside of the default
space in “Pull Request Refs” and we see how to fetch from a bundle in “Bundling”.
We set up highly custom refspecs in order to make git fetch do something
a little different than the default in “The Refspec”.
git pull
The git pull command is basically a combination of the git fetch and git
merge commands, where Git will fetch from the remote you specify and then
immediately try to merge it into the branch you’re on.
We introduce it quickly in “Fetching and Pulling from Your Remotes” and
show how to see what it will merge if you run it in “Inspecting a Remote”.
We also see how to use it to help with rebasing difficulties in “Rebase When
You Rebase”.
Sharing and Updating Projects 561We show how to use it with a URL to pull in changes in a one-off fashion in
“Checking Out Remote Branches”.
Finally, we very quickly mention that you can use the --verifysignatures option to it in order to verify that commits you are pulling have
been GPG signed in “Signing Commits”.
git push
The git push command is used to communicate with another repository, calculate what your local database has that the remote one does not, and then
pushes the difference into the other repository. It requires write access to the
other repository and so normally is authenticated somehow.
We first look at the git push command in “Pushing to Your Remotes”.
Here we cover the basics of pushing a branch to a remote repository. In “Pushing” we go a little deeper into pushing specific branches and in “Tracking
Branches” we see how to set up tracking branches to automatically push to. In
“Deleting Remote Branches” we use the --delete flag to delete a branch on
the server with git push.
Throughout “Contributing to a Project” we see several examples of using
git push to share work on branches through multiple remotes.
We see how to use it to share tags that you have made with the --tags option in “Sharing Tags”.
In “Publishing Submodule Changes” we use the --recurse-submodules
option to check that all of our submodules work has been published before
pushing the superproject, which can be really helpful when using submodules.
In “Other Client Hooks” we talk briefly about the pre-push hook, which is
a script we can setup to run before a push completes to verify that it should be
allowed to push.
Finally, in “Pushing Refspecs” we look at pushing with a full refspec instead
of the general shortcuts that are normally used. This can help you be very specific about what work you wish to share.
git remote
The git remote command is a management tool for your record of remote repositories. It allows you to save long URLs as short handles, such as “origin” so
you don’t have to type them out all the time. You can have several of these and
the git remote command is used to add, change and delete them.
This command is covered in detail in “Working with Remotes”, including
listing, adding, removing and renaming them.
562 Appendix C, Git CommandsIt is used in nearly every subsequent chapter in the book too, but always in
the standard git remote add <name> <url> format.
git archive
The git archive command is used to create an archive file of a specific snapshot of the project.
We use git archive to create a tarball of a project for sharing in “Preparing a Release”.
git submodule
The git submodule command is used to manage external repositories within
a normal repositories. This could be for libraries or other types of shared resources. The submodule command has several sub-commands (add, update,
sync, etc) for managing these resources.
This command is only mentioned and entirely covered in “Submodules”.
Inspection and Comparison
git show
The git show command can show a Git object in a simple and human readable way. Normally you would use this to show the information about a tag or a
commit.
We first use it to show annotated tag information in “Annotated Tags”.
Later we use it quite a bit in “Revision Selection” to show the commits that
our various revision selections resolve to.
One of the more interesting things we do with git show is in “Manual File
Re-merging” to extract specific file contents of various stages during a merge
conflict.
git shortlog
The git shortlog command is used to summarize the output of git log. It
will take many of the same options that the git log command will but instead
of listing out all of the commits it will present a summary of the commits grouped by author.
We showed how to use it to create a nice changelog in “The Shortlog”.
Inspection and Comparison 563git describe
The git describe command is used to take anything that resolves to a commit and produces a string that is somewhat human-readable and will not
change. It’s a way to get a description of a commit that is as unambiguous as a
commit SHA-1 but more understandable.
We use git describe in “Generating a Build Number” and “Preparing a
Release” to get a string to name our release file after.
Debugging
Git has a couple of commands that are used to help debug an issue in your
code. This ranges from figuring out where something was introduced to figuring
out who introduced it.
git bisect
The git bisect tool is an incredibly helpful debugging tool used to find which
specific commit was the first one to introduce a bug or problem by doing an automatic binary search.
It is fully covered in “Binary Search” and is only mentioned in that section.
git blame
The git blame command annotates the lines of any file with which commit
was the last one to introduce a change to each line of the file and what person
authored that commit. This is helpful in order to find the person to ask for more
information about a specific section of your code.
It is covered in “File Annotation” and is only mentioned in that section.
git grep
The git grep command can help you find any string or regular expression in
any of the files in your source code, even older versions of your project.
It is covered in “Git Grep” and is only mentioned in that section.
564 Appendix C, Git CommandsPatching
A few commands in Git are centered around the concept of thinking of commits
in terms of the changes they introduce, as though the commit series is a series
of patches. These commands help you manage your branches in this manner.
git cherry-pick
The git cherry-pick command is used to take the change introduced in a
single Git commit and try to re-introduce it as a new commit on the branch
you’re currently on. This can be useful to only take one or two commits from a
branch individually rather than merging in the branch which takes all the
changes.
Cherry picking is described and demonstrated in “Rebasing and Cherry
Picking Workflows”.
git rebase
The git rebase command is basically an automated cherry-pick. It determines a series of commits and then cherry-picks them one by one in the same
order somewhere else.
Rebasing is covered in detail in “Rebasing”, including covering the collaborative issues involved with rebasing branches that are already public.
We use it in practice during an example of splitting your history into two separate repositories in “Replace”, using the --onto flag as well.
We go through running into a merge conflict during rebasing in “Rerere”.
We also use it in an interactive scripting mode with the -i option in “Changing Multiple Commit Messages”.
git revert
The git revert command is essentially a reverse git cherry-pick. It creates a new commit that applies the exact opposite of the change introduced in
the commit you’re targeting, essentially undoing or reverting it.
We use this in “Reverse the commit” to undo a merge commit